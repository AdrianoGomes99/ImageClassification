{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Random Forests \n",
    "## for (Fruits and Vegetables) Image Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Install necessary packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install tensorflow --user"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Import necessary packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import tensorflow\n",
    "from tensorflow import keras\n",
    "from keras.utils import array_to_img, img_to_array, load_img\n",
    "from datetime import datetime\n",
    "from sklearn.datasets import load_files\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score,confusion_matrix,classification_report\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#check versions of some packages\n",
    "print(np.__version__)\n",
    "print(pd.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Copy dataset from git repo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "!git clone https://github.com/Horea94/Fruit-Images-Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Set the path directory to the cloned test and train data.\n",
    "load_dataset() returns the filenames, integer classes and string classes that are stored in file directory.\n",
    "\n",
    "\n",
    "1.   names_train is a vector that contains the filepath of all images from the training set\n",
    "2.   names_test is a vector that contains the filepath of all images from the test set\n",
    "3.   intclass_train is a vector containing the int class values (1-131) of all images from the training set\n",
    "4.   intclass_test is a vector containing the int class values (1-131) of all images from the test set\n",
    "5.   stringclass_train is a vector containing the string label of class of all images from the training set\n",
    "6.   stringclass_test is a vector containing the string label of class of all images from the test set\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#recognise the directory of the notebook file\n",
    "base_dir = os.getcwd()\n",
    "base_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_dir = base_dir+'/Fruit-Images-Dataset/Training/'\n",
    "test_dir = base_dir+'/Fruit-Images-Dataset/Test/'\n",
    "\n",
    "def load_dataset(path):\n",
    "    data = load_files(path)\n",
    "    files = np.array(data['filenames'])\n",
    "    targets = np.array(data['target'])\n",
    "    target_labels = np.array(data['target_names'])\n",
    "    return files, targets, target_labels\n",
    "\n",
    "names_train, intclass_train, stringclass_train = load_dataset(train_dir)\n",
    "names_test, intclass_test, stringclass_test = load_dataset(test_dir)\n",
    "\n",
    "print('Loading complete!')\n",
    "print('Training set size : ',  names_train.shape[0])\n",
    "print('Testing set size : ', names_test.shape[0])\n",
    "print(stringclass_train)\n",
    "print(intclass_train.shape)\n",
    "print(stringclass_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(stringclass_train.shape)\n",
    "print(stringclass_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Show distribution of images to the different classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "(intclass, counts) = np.unique(intclass_train, return_counts=True)\n",
    "plt.bar(intclass, counts)\n",
    "plt.title('distribution of full training and test data')\n",
    "full_train_frequencies = np.asarray((intclass, counts)).T\n",
    "\n",
    "(intclass, counts) = np.unique(intclass_test, return_counts=True)\n",
    "plt.bar(intclass, counts)\n",
    "full_test_frequencies = np.asarray((intclass, counts)).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Datasets can be reduced for compiling: original size of the training dataset is 67692 images; original size of the test dataset is 22688 images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "i = 0\n",
    "while i < 20:\n",
    "  print('Name : ', names_train[i])\n",
    "  print('Intclass : ', intclass_train[i])\n",
    "  i+=1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print('Training set size : ',  names_train.shape[0])\n",
    "print('Testing set size : ', names_test.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Amount of different classes in the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "n_classes = len(np.unique(intclass_test))\n",
    "n_classes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Change name of image to actual pixel array.\n",
    "The _images_array are the inputs (100x100 pixels with 3 color channels).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def convert_image_to_array(files):\n",
    "    images_as_array=[]\n",
    "    for file in files:\n",
    "        # Convert to Numpy Array\n",
    "        images_as_array.append(img_to_array(load_img(file)))\n",
    "    return images_as_array\n",
    "\n",
    "train_images_array = np.array(convert_image_to_array(names_train))\n",
    "print('Training set shape : ', train_images_array.shape)\n",
    "\n",
    "test_images_array = np.array(convert_image_to_array(names_test))\n",
    "print('Test set shape : ', test_images_array.shape)\n",
    "\n",
    "print('1st training image shape ',train_images_array[0].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Pixel arrays of one image (100x100 pixels, 3 color channels)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print('1st training image as array',train_images_array[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Rescale pixel values from 0-255 range to 0-1.\n",
    "\n",
    "\n",
    "1.   train_images_array is an array containing the normalized pixel values of the train images.\n",
    "2.   test_images_array is an array containing the normalized pixel values of the test images.\n",
    "3.   valid_images_array is an array containing the normalized pixel values of the validation images.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_images_array = train_images_array.astype('float32')/255\n",
    "test_images_array = test_images_array.astype('float32')/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#split the training dataset ito trainset anbd testset (reduce computation power)\n",
    "new_train_images_array, new_test_images_array, new_train_intclass, new_test_intclass = train_test_split(train_images_array, intclass_train, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print('Training set size : ',  names_train.shape[0])\n",
    "print('Testing set size : ', names_test.shape[0])\n",
    "print('Training set LABELS size : ',intclass_train.shape)\n",
    "print('Testing set LABELS size : ',intclass_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "n_classes_train = len(np.unique(intclass_train))\n",
    "print('Number of classes in training: ',n_classes_train)\n",
    "n_classes_test = len(np.unique(intclass_test))\n",
    "print('Number of classes in testing: ',intclass_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print('New Training set size : ',  new_train_images_array.shape[0])\n",
    "print('New Testing set size : ', new_test_images_array.shape[0])\n",
    "print('New Training set LABELS size : ', new_train_intclass.shape)\n",
    "print('New Testing set LABELS size : ',new_test_intclass.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "n_classes_train = len(np.unique(new_train_intclass))\n",
    "print('Number of classes in new training: ',n_classes_train)\n",
    "n_classes_test = len(np.unique(new_test_intclass))\n",
    "print('Number of classes in new testing: ',n_classes_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Following the code in the link below\n",
    "\n",
    "https://www.analyticsvidhya.com/blog/2022/01/image-classification-using-machine-learning/\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Flattening the arrays\n",
    "shape of the arrays should be a vector of 30000 features\n",
    "in order to be undersantable by skleaarn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#sklearn expects i/p to be 2d array-model.fit(x_train,y_train)=>reshape to 2d array\n",
    "nsamples, nx, ny, nrgb = new_train_images_array.shape\n",
    "train_flat_images_array = new_train_images_array.reshape((nsamples,nx*ny*nrgb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#so,eventually,model.predict() should also be a 2d input\n",
    "nsamples, nx, ny, nrgb = new_test_images_array.shape\n",
    "test_flat_images_array = new_test_images_array.reshape((nsamples,nx*ny*nrgb))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#### 1st gridsearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Getting the current date and time\n",
    "dt1 = datetime.now()\n",
    "\n",
    "# getting the timestamp\n",
    "ts1 = datetime.timestamp(dt1)\n",
    "\n",
    "print(\"Date and time is:\", dt1)\n",
    "print(\"Timestamp is:\", ts1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#defining the Random Forest model from sklearn\n",
    "rf=RandomForestClassifier()\n",
    "\n",
    "#range of values for each of the parameters\n",
    "param_grid={\n",
    "    'n_estimators':[1,10, 20],\n",
    "    'criterion': ['gini', 'entropy'],\n",
    "    'max_depth':[10,50,100],\n",
    "    'max_features':['sqrt', 'log2'], \n",
    "    'min_impurity_decrease':[0.05,0.1,0.5],\n",
    "    'bootstrap':[False],\n",
    "    'random_state':[42],\n",
    "    'ccp_alpha':[0.05,0.1,0.5],\n",
    "}\n",
    "#applying 5-fold cross validation to choose hyperparameter\n",
    "rf_gs=GridSearchCV(estimator=rf, param_grid=param_grid, scoring='accuracy', cv=5, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#fiting the model to the \"new training\" dataset\n",
    "rf_gs.fit(train_flat_images_array,new_train_intclass)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Getting the current date and time\n",
    "dt2 = datetime.now()\n",
    "\n",
    "# getting the timestamp\n",
    "ts2 = datetime.timestamp(dt2)\n",
    "\n",
    "print(\"Date and time is:\", dt2)\n",
    "print(\"Timestamp is:\", ts2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# difference between dates in timedelta\n",
    "# time necessary to get the best model with this parameter options\n",
    "delta = dt2 - dt1\n",
    "print(f'Difference is {delta.seconds} seconds')\n",
    "print(f'Difference is {delta.seconds/60} minutes')\n",
    "print(f'Difference is {delta.seconds/3600} hours')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# parameters for the best model found in the grid search\n",
    "best_params = rf_gs.best_estimator_.get_params()\n",
    "best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# predictions for the \"new test\" dataset\n",
    "intclass_test_pred=rf_gs.best_estimator_.predict(test_flat_images_array)\n",
    "intclass_test_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# calculate accuracy on the \"new test\" dataset\n",
    "acc = accuracy_score(intclass_test_pred,new_test_intclass)\n",
    "acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(\"The predicted Data is :\")\n",
    "print(np.array(intclass_test_pred))\n",
    "print(\"The actual data is:\")\n",
    "print(np.array(new_test_intclass))\n",
    "print(f\"The model is {acc*100}% accurate (in the test set)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#extra metrics (precision, recall and f1-score)\n",
    "print(classification_report(intclass_test_pred,new_test_intclass))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Ploting the Consusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cm = confusion_matrix(intclass_test_pred,new_test_intclass)\n",
    "import pandas as pd\n",
    "df = pd.DataFrame(cm).replace(0, np.nan)\n",
    "import seaborn as sns\n",
    "plt.figure(figsize=[20,20])\n",
    "sns.heatmap(df, annot=True, fmt='g', cmap=\"Blues\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#### 2nd ieration of gridsearch for parameters\n",
    "repeat the same steps but changing te parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rf=RandomForestClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Getting the current date and time\n",
    "dt1 = datetime.now()\n",
    "\n",
    "# getting the timestamp\n",
    "ts1 = datetime.timestamp(dt1)\n",
    "\n",
    "print(\"Date and time is:\", dt1)\n",
    "print(\"Timestamp is:\", ts1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "param_grid={\n",
    "    'n_estimators':[10, 100],\n",
    "    'criterion': ['gini', 'entropy'],\n",
    "    'max_depth':[5,10,15],\n",
    "    'max_features':['log2', 'auto'],\n",
    "    'min_impurity_decrease':[0.0, 0.025, 0.05],\n",
    "    'bootstrap':[False],\n",
    "    'random_state':[42],\n",
    "    'ccp_alpha':[0.0, 0.025, 0.05],\n",
    "}\n",
    "#applying 5-fold cross validation to choose hyperparameter\n",
    "rf_gs2=GridSearchCV(estimator=rf, param_grid=param_grid, scoring='accuracy', cv=5, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "rf_gs2.fit(train_flat_images_array,new_train_intclass)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# Getting the current date and time\n",
    "dt2 = datetime.now()\n",
    "\n",
    "# getting the timestamp\n",
    "ts2 = datetime.timestamp(dt2)\n",
    "\n",
    "print(\"Date and time is:\", dt2)\n",
    "print(\"Timestamp is:\", ts2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# difference between dates in timedelta\n",
    "delta = dt2 - dt1\n",
    "print(f'Difference is {delta.seconds} seconds')\n",
    "print(f'Difference is {delta.seconds / 60} minutes')\n",
    "print(f'Difference is {delta.seconds / 3600} hours')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "best_params2 = rf_gs2.best_estimator_.get_params()\n",
    "best_params2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "intclass_test_pred2 = rf_gs2.best_estimator_.predict(test_flat_images_array)\n",
    "intclass_test_pred2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "acc2 = accuracy_score(intclass_test_pred2,new_test_intclass)\n",
    "acc2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(\"The predicted Data is :\")\n",
    "print(np.array(intclass_test_pred2))\n",
    "print(\"The actual data is:\")\n",
    "print(np.array(new_test_intclass))\n",
    "print(f\"The model is {acc2*100}% accurate (in the test set)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(classification_report(intclass_test_pred2,new_test_intclass))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cm2 = confusion_matrix(intclass_test_pred2,new_test_intclass)\n",
    "\n",
    "df2 = pd.DataFrame(cm2).replace(0, np.nan)\n",
    "\n",
    "plt.figure(figsize=[20,20])\n",
    "sns.heatmap(df2, annot=True, fmt='g', cmap=\"Blues\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Retraining a Random Forest\n",
    "with the best found parameters \n",
    "- with 5-fold cv on the \"new training\" dataset\n",
    "(evaluating the performance on the cv, on the \"new train\" set, on the \"new test\" set and on the original test set)\n",
    "- with the full \"new training\" dataset\n",
    "(evaluating the performance on the \"new train\" set, on the \"new test\" set and on the original test set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "final_rf = RandomForestClassifier( #best_params2\n",
    "    ,\n",
    "    random_state=42)\n",
    "cv_scores = cross_val_score(final_rf, train_flat_images_array,new_train_intclass, cv=5)\n",
    "cv_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(\"{0.2f}% accuracy with a standard deviation of {0.2f}%\".format (scores.mean()*100, scores.std()*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "6f0637b5e3693cbf0bb370cfb0f709ad6f2e756e19ee71e71e29fc0a1009401e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
