{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": [],
   "collapsed_sections": []
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "accelerator": "GPU"
 },
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "### 1. Import needed packages and clone the dataset"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are using numpy version: 1.20.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "fatal: destination path 'Fruit-Images-Dataset' already exists and is not an empty directory.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "\u001B[1;32m<ipython-input-32-9e454b2802cd>\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m     25\u001B[0m     \u001B[1;32mreturn\u001B[0m \u001B[0mfiles\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mtargets\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mtarget_labels\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     26\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 27\u001B[1;33m \u001B[0mnames_train\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mintclass_train\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mstringclass_train\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mload_dataset\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mtrain_dir\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     28\u001B[0m \u001B[0mnames_test\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mintclass_test\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mstringclass_test\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mload_dataset\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mtest_dir\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     29\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m<ipython-input-32-9e454b2802cd>\u001B[0m in \u001B[0;36mload_dataset\u001B[1;34m(path)\u001B[0m\n\u001B[0;32m     19\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     20\u001B[0m \u001B[1;32mdef\u001B[0m \u001B[0mload_dataset\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mpath\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 21\u001B[1;33m     \u001B[0mdata\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mload_files\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mpath\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     22\u001B[0m     \u001B[0mfiles\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mnp\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0marray\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mdata\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;34m'filenames'\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     23\u001B[0m     \u001B[0mtargets\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mnp\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0marray\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mdata\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;34m'target'\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001B[0m in \u001B[0;36minner_f\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m     61\u001B[0m             \u001B[0mextra_args\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mlen\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0margs\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;33m-\u001B[0m \u001B[0mlen\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mall_args\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     62\u001B[0m             \u001B[1;32mif\u001B[0m \u001B[0mextra_args\u001B[0m \u001B[1;33m<=\u001B[0m \u001B[1;36m0\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 63\u001B[1;33m                 \u001B[1;32mreturn\u001B[0m \u001B[0mf\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m*\u001B[0m\u001B[0margs\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     64\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     65\u001B[0m             \u001B[1;31m# extra_args > 0\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\datasets\\_base.py\u001B[0m in \u001B[0;36mload_files\u001B[1;34m(container_path, description, categories, load_content, shuffle, encoding, decode_error, random_state)\u001B[0m\n\u001B[0;32m    202\u001B[0m         \u001B[0mfolder_path\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mjoin\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mcontainer_path\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mfolder\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    203\u001B[0m         documents = [join(folder_path, d)\n\u001B[1;32m--> 204\u001B[1;33m                      for d in sorted(listdir(folder_path))]\n\u001B[0m\u001B[0;32m    205\u001B[0m         \u001B[0mtarget\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mextend\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mlen\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mdocuments\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;33m*\u001B[0m \u001B[1;33m[\u001B[0m\u001B[0mlabel\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    206\u001B[0m         \u001B[0mfilenames\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mextend\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mdocuments\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import random\n",
    "from sklearn.datasets import load_files\n",
    "from keras.utils import np_utils, array_to_img, img_to_array, load_img\n",
    "from tensorflow.keras.models import Sequential\n",
    "from keras.layers import Input, Dense, Dropout, Activation, Flatten, BatchNormalization\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "print('You are using numpy version:', np.__version__)\n",
    "\n",
    "!git clone https://github.com/Horea94/Fruit-Images-Dataset\n",
    "\n",
    "train_dir = 'C:/Users/crysi/Private Dokumente/Papers & wissenschaftl. Arbeiten/Master/Foundations of Machine Learning/First Project/Pycharm/Fruit-Images-Dataset/Training/'\n",
    "test_dir = 'C:/Users/crysi/Private Dokumente/Papers & wissenschaftl. Arbeiten/Master/Foundations of Machine Learning/First Project/Pycharm/Fruit-Images-Dataset/Test/'\n",
    "\n",
    "def load_dataset(path):\n",
    "    data = load_files(path)\n",
    "    files = np.array(data['filenames'])\n",
    "    targets = np.array(data['target'])\n",
    "    target_labels = np.array(data['target_names'])\n",
    "    return files, targets, target_labels\n",
    "\n",
    "names_train, intclass_train, stringclass_train = load_dataset(train_dir)\n",
    "names_test, intclass_test, stringclass_test = load_dataset(test_dir)\n",
    "\n",
    "n_classes = len(np.unique(intclass_test))\n",
    "\n",
    "train_hot_class = np_utils.to_categorical(intclass_train, n_classes)\n",
    "test_hot_class = np_utils.to_categorical(intclass_test, n_classes)\n",
    "\n",
    "def convert_image_to_array(files):\n",
    "    images_as_array=[]\n",
    "    for file in files:\n",
    "        # Convert to Numpy Array\n",
    "        images_as_array.append(img_to_array(load_img(file)))\n",
    "    return images_as_array\n",
    "\n",
    "train_images_array = np.array(convert_image_to_array(names_train))\n",
    "test_images_array = np.array(convert_image_to_array(names_test))\n",
    "\n",
    "train_images_array = train_images_array.astype('float32')/255\n",
    "test_images_array = test_images_array.astype('float32')/255\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "#split training into another training and test (to reduce computation resources/time)\n",
    "train_images_array, new_test_images_array, train_hot_class, new_test_hot_class = train_test_split(train_images_array, train_hot_class, test_size = 0.3, random_state = 42)\n",
    "\n",
    "train_images_array, valid_images_array, train_hot_class, valid_hot_class = train_test_split(train_images_array, train_hot_class, test_size = 0.2)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "outputs": [],
   "source": [
    "import csv\n",
    "import pandas as pd\n",
    "large_ANN = pd.read_excel('C:/Users/crysi/Private Dokumente/Papers & wissenschaftl. Arbeiten/Master/Foundations of Machine Learning/First Project/ImageClassification/grids.xlsx', header = 0, nrows = 36, sheet_name = 'large_ANN', usecols = range(0,9))\n",
    "small_ANN = pd.read_excel('C:/Users/crysi/Private Dokumente/Papers & wissenschaftl. Arbeiten/Master/Foundations of Machine Learning/First Project/ImageClassification/grids.xlsx', header = 0, nrows = 36, sheet_name = 'small_ANN', usecols = range(0,9))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [],
   "source": [
    "large_ANN.index =large_ANN.iloc[:,0]\n",
    "large_ANN = large_ANN.iloc[:,1:]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "outputs": [
    {
     "data": {
      "text/plain": "      Unnamed: 0  Unnamed: 1  train_acc  valid_acc  new_test_acc  test_acc  \\\n0    small_ANN_1           1      94.84      92.15         92.39     79.51   \n1    small_ANN_1           1      98.22      96.15         96.40     82.59   \n2    small_ANN_2           2      96.96      95.36         95.08     78.81   \n3    small_ANN_2           2      93.39      91.08         90.97     76.14   \n4    small_ANN_3           3      95.57      93.01         93.22     77.23   \n5    small_ANN_3           3      95.08      92.27         92.88     76.25   \n6    small_ANN_4           4      84.49      82.39         82.32     67.44   \n7    small_ANN_4           4      70.79      68.35         69.21     55.02   \n8    small_ANN_5           5      84.79      79.32         79.80     60.10   \n9    small_ANN_5           5      82.82      79.47         78.64     61.61   \n10   small_ANN_6           6      81.43      78.28         78.91     62.62   \n11   small_ANN_6           6      88.73      86.80         86.39     71.09   \n12   small_ANN_7           7      88.19      85.19         85.60     68.85   \n13   small_ANN_7           7      85.84      83.17         83.09     68.59   \n14   small_ANN_8           8      89.74      86.35         85.76     68.12   \n15   small_ANN_8           8      80.27      76.68         76.45     61.12   \n16   small_ANN_9           9      90.69      87.44         87.58     70.55   \n17   small_ANN_9           9      96.11      93.47         93.51     76.30   \n18  small_ANN_10          10      96.39      93.89         94.39     80.05   \n19  small_ANN_10          10      98.69      97.18         97.07     82.18   \n20  small_ANN_11          11      85.53      83.13         83.24     69.49   \n21  small_ANN_11          11      99.18      97.69         97.89     82.99   \n22  small_ANN_12          12      92.38      89.73         89.70     74.21   \n23  small_ANN_12          12      95.78      92.85         92.81     74.75   \n24  small_ANN_13          13      84.16      80.74         81.12     66.26   \n25  small_ANN_13          13      85.82      83.69         83.48     65.63   \n26  small_ANN_14          14      86.85      82.57         82.68     62.85   \n27  small_ANN_14          14      85.24      81.02         80.38     61.42   \n28  small_ANN_15          15      82.31      78.76         79.43     60.68   \n29  small_ANN_15          15      90.32      87.98         87.95     72.34   \n30  small_ANN_16          16      83.78      80.86         80.82     64.43   \n31  small_ANN_16          16      91.77      89.04         88.81     68.80   \n32  small_ANN_17          17      85.02      81.83         81.23     62.38   \n33  small_ANN_17          17      66.03      64.55         63.70     55.69   \n34  small_ANN_18          18      82.95      78.94         78.77     64.27   \n35  small_ANN_18          18      94.81      91.46         91.81     73.68   \n\n   activation  dropout              lossfunction  \n0        relu     0.00  categorical_crossentropy  \n1        relu     0.00  categorical_crossentropy  \n2        tanh     0.00  categorical_crossentropy  \n3        tanh     0.00  categorical_crossentropy  \n4     sigmoid     0.00  categorical_crossentropy  \n5     sigmoid     0.00  categorical_crossentropy  \n6        relu     0.50  categorical_crossentropy  \n7        relu     0.50  categorical_crossentropy  \n8        tanh     0.50  categorical_crossentropy  \n9        tanh     0.50  categorical_crossentropy  \n10    sigmoid     0.50  categorical_crossentropy  \n11    sigmoid     0.50  categorical_crossentropy  \n12       relu     0.25  categorical_crossentropy  \n13       relu     0.25  categorical_crossentropy  \n14       tanh     0.25  categorical_crossentropy  \n15       tanh     0.25  categorical_crossentropy  \n16    sigmoid     0.25  categorical_crossentropy  \n17    sigmoid     0.25  categorical_crossentropy  \n18       relu     0.00                   poisson  \n19       relu     0.00                   poisson  \n20       tanh     0.00                   poisson  \n21       tanh     0.00                   poisson  \n22    sigmoid     0.00                   poisson  \n23    sigmoid     0.00                   poisson  \n24       relu     0.50                   poisson  \n25       relu     0.50                   poisson  \n26       tanh     0.50                   poisson  \n27       tanh     0.50                   poisson  \n28    sigmoid     0.50                   poisson  \n29    sigmoid     0.50                   poisson  \n30       relu     0.25                   poisson  \n31       relu     0.25                   poisson  \n32       tanh     0.25                   poisson  \n33       tanh     0.25                   poisson  \n34    sigmoid     0.25                   poisson  \n35    sigmoid     0.25                   poisson  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Unnamed: 0</th>\n      <th>Unnamed: 1</th>\n      <th>train_acc</th>\n      <th>valid_acc</th>\n      <th>new_test_acc</th>\n      <th>test_acc</th>\n      <th>activation</th>\n      <th>dropout</th>\n      <th>lossfunction</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>small_ANN_1</td>\n      <td>1</td>\n      <td>94.84</td>\n      <td>92.15</td>\n      <td>92.39</td>\n      <td>79.51</td>\n      <td>relu</td>\n      <td>0.00</td>\n      <td>categorical_crossentropy</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>small_ANN_1</td>\n      <td>1</td>\n      <td>98.22</td>\n      <td>96.15</td>\n      <td>96.40</td>\n      <td>82.59</td>\n      <td>relu</td>\n      <td>0.00</td>\n      <td>categorical_crossentropy</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>small_ANN_2</td>\n      <td>2</td>\n      <td>96.96</td>\n      <td>95.36</td>\n      <td>95.08</td>\n      <td>78.81</td>\n      <td>tanh</td>\n      <td>0.00</td>\n      <td>categorical_crossentropy</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>small_ANN_2</td>\n      <td>2</td>\n      <td>93.39</td>\n      <td>91.08</td>\n      <td>90.97</td>\n      <td>76.14</td>\n      <td>tanh</td>\n      <td>0.00</td>\n      <td>categorical_crossentropy</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>small_ANN_3</td>\n      <td>3</td>\n      <td>95.57</td>\n      <td>93.01</td>\n      <td>93.22</td>\n      <td>77.23</td>\n      <td>sigmoid</td>\n      <td>0.00</td>\n      <td>categorical_crossentropy</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>small_ANN_3</td>\n      <td>3</td>\n      <td>95.08</td>\n      <td>92.27</td>\n      <td>92.88</td>\n      <td>76.25</td>\n      <td>sigmoid</td>\n      <td>0.00</td>\n      <td>categorical_crossentropy</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>small_ANN_4</td>\n      <td>4</td>\n      <td>84.49</td>\n      <td>82.39</td>\n      <td>82.32</td>\n      <td>67.44</td>\n      <td>relu</td>\n      <td>0.50</td>\n      <td>categorical_crossentropy</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>small_ANN_4</td>\n      <td>4</td>\n      <td>70.79</td>\n      <td>68.35</td>\n      <td>69.21</td>\n      <td>55.02</td>\n      <td>relu</td>\n      <td>0.50</td>\n      <td>categorical_crossentropy</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>small_ANN_5</td>\n      <td>5</td>\n      <td>84.79</td>\n      <td>79.32</td>\n      <td>79.80</td>\n      <td>60.10</td>\n      <td>tanh</td>\n      <td>0.50</td>\n      <td>categorical_crossentropy</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>small_ANN_5</td>\n      <td>5</td>\n      <td>82.82</td>\n      <td>79.47</td>\n      <td>78.64</td>\n      <td>61.61</td>\n      <td>tanh</td>\n      <td>0.50</td>\n      <td>categorical_crossentropy</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>small_ANN_6</td>\n      <td>6</td>\n      <td>81.43</td>\n      <td>78.28</td>\n      <td>78.91</td>\n      <td>62.62</td>\n      <td>sigmoid</td>\n      <td>0.50</td>\n      <td>categorical_crossentropy</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>small_ANN_6</td>\n      <td>6</td>\n      <td>88.73</td>\n      <td>86.80</td>\n      <td>86.39</td>\n      <td>71.09</td>\n      <td>sigmoid</td>\n      <td>0.50</td>\n      <td>categorical_crossentropy</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>small_ANN_7</td>\n      <td>7</td>\n      <td>88.19</td>\n      <td>85.19</td>\n      <td>85.60</td>\n      <td>68.85</td>\n      <td>relu</td>\n      <td>0.25</td>\n      <td>categorical_crossentropy</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>small_ANN_7</td>\n      <td>7</td>\n      <td>85.84</td>\n      <td>83.17</td>\n      <td>83.09</td>\n      <td>68.59</td>\n      <td>relu</td>\n      <td>0.25</td>\n      <td>categorical_crossentropy</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>small_ANN_8</td>\n      <td>8</td>\n      <td>89.74</td>\n      <td>86.35</td>\n      <td>85.76</td>\n      <td>68.12</td>\n      <td>tanh</td>\n      <td>0.25</td>\n      <td>categorical_crossentropy</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>small_ANN_8</td>\n      <td>8</td>\n      <td>80.27</td>\n      <td>76.68</td>\n      <td>76.45</td>\n      <td>61.12</td>\n      <td>tanh</td>\n      <td>0.25</td>\n      <td>categorical_crossentropy</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>small_ANN_9</td>\n      <td>9</td>\n      <td>90.69</td>\n      <td>87.44</td>\n      <td>87.58</td>\n      <td>70.55</td>\n      <td>sigmoid</td>\n      <td>0.25</td>\n      <td>categorical_crossentropy</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>small_ANN_9</td>\n      <td>9</td>\n      <td>96.11</td>\n      <td>93.47</td>\n      <td>93.51</td>\n      <td>76.30</td>\n      <td>sigmoid</td>\n      <td>0.25</td>\n      <td>categorical_crossentropy</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>small_ANN_10</td>\n      <td>10</td>\n      <td>96.39</td>\n      <td>93.89</td>\n      <td>94.39</td>\n      <td>80.05</td>\n      <td>relu</td>\n      <td>0.00</td>\n      <td>poisson</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>small_ANN_10</td>\n      <td>10</td>\n      <td>98.69</td>\n      <td>97.18</td>\n      <td>97.07</td>\n      <td>82.18</td>\n      <td>relu</td>\n      <td>0.00</td>\n      <td>poisson</td>\n    </tr>\n    <tr>\n      <th>20</th>\n      <td>small_ANN_11</td>\n      <td>11</td>\n      <td>85.53</td>\n      <td>83.13</td>\n      <td>83.24</td>\n      <td>69.49</td>\n      <td>tanh</td>\n      <td>0.00</td>\n      <td>poisson</td>\n    </tr>\n    <tr>\n      <th>21</th>\n      <td>small_ANN_11</td>\n      <td>11</td>\n      <td>99.18</td>\n      <td>97.69</td>\n      <td>97.89</td>\n      <td>82.99</td>\n      <td>tanh</td>\n      <td>0.00</td>\n      <td>poisson</td>\n    </tr>\n    <tr>\n      <th>22</th>\n      <td>small_ANN_12</td>\n      <td>12</td>\n      <td>92.38</td>\n      <td>89.73</td>\n      <td>89.70</td>\n      <td>74.21</td>\n      <td>sigmoid</td>\n      <td>0.00</td>\n      <td>poisson</td>\n    </tr>\n    <tr>\n      <th>23</th>\n      <td>small_ANN_12</td>\n      <td>12</td>\n      <td>95.78</td>\n      <td>92.85</td>\n      <td>92.81</td>\n      <td>74.75</td>\n      <td>sigmoid</td>\n      <td>0.00</td>\n      <td>poisson</td>\n    </tr>\n    <tr>\n      <th>24</th>\n      <td>small_ANN_13</td>\n      <td>13</td>\n      <td>84.16</td>\n      <td>80.74</td>\n      <td>81.12</td>\n      <td>66.26</td>\n      <td>relu</td>\n      <td>0.50</td>\n      <td>poisson</td>\n    </tr>\n    <tr>\n      <th>25</th>\n      <td>small_ANN_13</td>\n      <td>13</td>\n      <td>85.82</td>\n      <td>83.69</td>\n      <td>83.48</td>\n      <td>65.63</td>\n      <td>relu</td>\n      <td>0.50</td>\n      <td>poisson</td>\n    </tr>\n    <tr>\n      <th>26</th>\n      <td>small_ANN_14</td>\n      <td>14</td>\n      <td>86.85</td>\n      <td>82.57</td>\n      <td>82.68</td>\n      <td>62.85</td>\n      <td>tanh</td>\n      <td>0.50</td>\n      <td>poisson</td>\n    </tr>\n    <tr>\n      <th>27</th>\n      <td>small_ANN_14</td>\n      <td>14</td>\n      <td>85.24</td>\n      <td>81.02</td>\n      <td>80.38</td>\n      <td>61.42</td>\n      <td>tanh</td>\n      <td>0.50</td>\n      <td>poisson</td>\n    </tr>\n    <tr>\n      <th>28</th>\n      <td>small_ANN_15</td>\n      <td>15</td>\n      <td>82.31</td>\n      <td>78.76</td>\n      <td>79.43</td>\n      <td>60.68</td>\n      <td>sigmoid</td>\n      <td>0.50</td>\n      <td>poisson</td>\n    </tr>\n    <tr>\n      <th>29</th>\n      <td>small_ANN_15</td>\n      <td>15</td>\n      <td>90.32</td>\n      <td>87.98</td>\n      <td>87.95</td>\n      <td>72.34</td>\n      <td>sigmoid</td>\n      <td>0.50</td>\n      <td>poisson</td>\n    </tr>\n    <tr>\n      <th>30</th>\n      <td>small_ANN_16</td>\n      <td>16</td>\n      <td>83.78</td>\n      <td>80.86</td>\n      <td>80.82</td>\n      <td>64.43</td>\n      <td>relu</td>\n      <td>0.25</td>\n      <td>poisson</td>\n    </tr>\n    <tr>\n      <th>31</th>\n      <td>small_ANN_16</td>\n      <td>16</td>\n      <td>91.77</td>\n      <td>89.04</td>\n      <td>88.81</td>\n      <td>68.80</td>\n      <td>relu</td>\n      <td>0.25</td>\n      <td>poisson</td>\n    </tr>\n    <tr>\n      <th>32</th>\n      <td>small_ANN_17</td>\n      <td>17</td>\n      <td>85.02</td>\n      <td>81.83</td>\n      <td>81.23</td>\n      <td>62.38</td>\n      <td>tanh</td>\n      <td>0.25</td>\n      <td>poisson</td>\n    </tr>\n    <tr>\n      <th>33</th>\n      <td>small_ANN_17</td>\n      <td>17</td>\n      <td>66.03</td>\n      <td>64.55</td>\n      <td>63.70</td>\n      <td>55.69</td>\n      <td>tanh</td>\n      <td>0.25</td>\n      <td>poisson</td>\n    </tr>\n    <tr>\n      <th>34</th>\n      <td>small_ANN_18</td>\n      <td>18</td>\n      <td>82.95</td>\n      <td>78.94</td>\n      <td>78.77</td>\n      <td>64.27</td>\n      <td>sigmoid</td>\n      <td>0.25</td>\n      <td>poisson</td>\n    </tr>\n    <tr>\n      <th>35</th>\n      <td>small_ANN_18</td>\n      <td>18</td>\n      <td>94.81</td>\n      <td>91.46</td>\n      <td>91.81</td>\n      <td>73.68</td>\n      <td>sigmoid</td>\n      <td>0.25</td>\n      <td>poisson</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "small_ANN"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "outputs": [
    {
     "data": {
      "text/plain": "(63.0, 102.0)"
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": "<Figure size 437.6x360 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<Figure size 437.6x360 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "sns.set_theme(style=\"whitegrid\")\n",
    "\n",
    "cmap = sns.cubehelix_palette(n_colors=3, rot=-.2)#, as_cmap=True)\n",
    "l = sns.relplot(\n",
    "    data=large_ANN.sort_values('valid_acc'),\n",
    "    x=\"Unnamed: 1\", y=\"valid_acc\",\n",
    "    hue=\"dropout\", style = \"activation\", # size=\"mass\",\n",
    "    palette=cmap, sizes=(50, 200),\n",
    ")\n",
    "plt.ylim(63, 102)\n",
    "s = sns.relplot(\n",
    "    data=small_ANN.sort_values('valid_acc'),\n",
    "    x=\"Unnamed: 1\", y=\"valid_acc\",\n",
    "    hue=\"dropout\", style = \"activation\", # size=\"mass\",\n",
    "    palette=cmap, sizes=(50, 200),\n",
    ")\n",
    "\n",
    "(l.map(plt.axhline, y=np.mean(large_ANN['valid_acc']), ls='--', c='red').map(plt.axvline, x=9.5, ls='--', c='grey').set_axis_labels(\"Model\", \"Validation Accuracy\"))\n",
    "\n",
    "(s.map(plt.axhline, y=np.mean(small_ANN['valid_acc']), ls='--', c='red').map(plt.axvline, x=9.5, ls='--', c='grey').set_axis_labels(\"Model\", \"Validation Accuracy\"))\n",
    "\n",
    "plt.ylim(63, 102)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "outputs": [
    {
     "data": {
      "text/plain": "27    89.07\n24    91.06\n29    92.16\n17    92.51\n26    93.34\n9     93.93\n11    94.13\n25    94.28\n6     94.43\n28    95.88\n10    96.91\n8     97.00\n7     97.26\n35    97.32\n14    97.35\n12    97.74\n32    97.84\n15    98.02\n0     98.29\n33    98.29\n30    98.33\n31    98.34\n3     98.64\n13    98.71\n18    98.89\n34    99.11\n1     99.18\n23    99.21\n4     99.39\n16    99.51\n20    99.55\n2     99.56\n22    99.61\n5     99.75\n21    99.84\n19    99.91\nName: valid_acc, dtype: float64"
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "large_ANN.sort_values('valid_acc')['valid_acc']"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "def build_NeuralNetwork():\n",
    "\n",
    "    #input layer\n",
    "    model = Sequential()\n",
    "    model.add(Input(shape=(100,100,3)))\n",
    "    model.add(Flatten())\n",
    "\n",
    "    #hiddenlayer 1\n",
    "    model.add(Dense(5))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation(activation='relu'))\n",
    "\n",
    "    #hiddenlayer 2\n",
    "    model.add(Dense(50)) #900\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation(activation='relu'))\n",
    "    #model.add(Dropout(0.25))\n",
    "\n",
    "    #hiddenlayer 3\n",
    "    model.add(Dense(50)) #900\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation(activation='relu'))\n",
    "    #model.add(Dropout(0.25))\n",
    "\n",
    "    #hiddenlayer 4\n",
    "    #model.add(Dense(300)) #900\n",
    "    #model.add(BatchNormalization())\n",
    "    #model.add(Activation(activation='relu'))\n",
    "    #model.add(Dropout(0.25))\n",
    "\n",
    "    #output layer\n",
    "    model.add(Dense(131,activation=\"softmax\"))\n",
    "\n",
    "    model.compile(loss = 'poisson', optimizer = \"adam\", metrics = ['accuracy'])\n",
    "    print('Compiled!')\n",
    "\n",
    "    return model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compiled!\n",
      "Model built.\n",
      "Epoch 1/100\n",
      "1185/1185 - 8s - loss: 0.0280 - accuracy: 0.3019 - val_loss: 0.0212 - val_accuracy: 0.4538 - 8s/epoch - 6ms/step\n",
      "Epoch 2/100\n",
      "1185/1185 - 5s - loss: 0.0180 - accuracy: 0.5803 - val_loss: 0.0204 - val_accuracy: 0.4554 - 5s/epoch - 4ms/step\n",
      "Epoch 3/100\n",
      "1185/1185 - 5s - loss: 0.0153 - accuracy: 0.6806 - val_loss: 0.0156 - val_accuracy: 0.6460 - 5s/epoch - 4ms/step\n",
      "Epoch 4/100\n",
      "1185/1185 - 5s - loss: 0.0138 - accuracy: 0.7384 - val_loss: 0.0149 - val_accuracy: 0.6831 - 5s/epoch - 5ms/step\n",
      "Epoch 5/100\n",
      "1185/1185 - 5s - loss: 0.0131 - accuracy: 0.7664 - val_loss: 0.0114 - val_accuracy: 0.8557 - 5s/epoch - 4ms/step\n",
      "Epoch 6/100\n",
      "1185/1185 - 5s - loss: 0.0123 - accuracy: 0.7956 - val_loss: 0.0119 - val_accuracy: 0.8141 - 5s/epoch - 4ms/step\n",
      "Epoch 7/100\n",
      "1185/1185 - 5s - loss: 0.0121 - accuracy: 0.8074 - val_loss: 0.0136 - val_accuracy: 0.7293 - 5s/epoch - 4ms/step\n",
      "Epoch 8/100\n",
      "1185/1185 - 5s - loss: 0.0116 - accuracy: 0.8286 - val_loss: 0.0132 - val_accuracy: 0.7561 - 5s/epoch - 4ms/step\n",
      "Epoch 9/100\n",
      "1185/1185 - 5s - loss: 0.0115 - accuracy: 0.8276 - val_loss: 0.0160 - val_accuracy: 0.6571 - 5s/epoch - 4ms/step\n",
      "Epoch 10/100\n",
      "1185/1185 - 5s - loss: 0.0113 - accuracy: 0.8352 - val_loss: 0.0108 - val_accuracy: 0.8549 - 5s/epoch - 4ms/step\n",
      "Epoch 11/100\n",
      "1185/1185 - 5s - loss: 0.0111 - accuracy: 0.8453 - val_loss: 0.0098 - val_accuracy: 0.9102 - 5s/epoch - 4ms/step\n",
      "Epoch 12/100\n",
      "1185/1185 - 5s - loss: 0.0111 - accuracy: 0.8458 - val_loss: 0.0094 - val_accuracy: 0.9292 - 5s/epoch - 4ms/step\n",
      "Epoch 13/100\n",
      "1185/1185 - 5s - loss: 0.0110 - accuracy: 0.8488 - val_loss: 0.0132 - val_accuracy: 0.7475 - 5s/epoch - 4ms/step\n",
      "Epoch 14/100\n",
      "1185/1185 - 5s - loss: 0.0108 - accuracy: 0.8592 - val_loss: 0.0100 - val_accuracy: 0.9019 - 5s/epoch - 4ms/step\n",
      "Epoch 15/100\n",
      "1185/1185 - 5s - loss: 0.0108 - accuracy: 0.8596 - val_loss: 0.0221 - val_accuracy: 0.5307 - 5s/epoch - 4ms/step\n",
      "Epoch 16/100\n",
      "1185/1185 - 5s - loss: 0.0106 - accuracy: 0.8684 - val_loss: 0.0124 - val_accuracy: 0.7860 - 5s/epoch - 4ms/step\n",
      "Epoch 17/100\n",
      "1185/1185 - 5s - loss: 0.0106 - accuracy: 0.8702 - val_loss: 0.0111 - val_accuracy: 0.8445 - 5s/epoch - 4ms/step\n",
      "Epoch 18/100\n",
      "1185/1185 - 5s - loss: 0.0105 - accuracy: 0.8725 - val_loss: 0.0088 - val_accuracy: 0.9553 - 5s/epoch - 4ms/step\n",
      "Epoch 19/100\n",
      "1185/1185 - 5s - loss: 0.0104 - accuracy: 0.8769 - val_loss: 0.0091 - val_accuracy: 0.9389 - 5s/epoch - 4ms/step\n",
      "Epoch 20/100\n",
      "1185/1185 - 5s - loss: 0.0104 - accuracy: 0.8774 - val_loss: 0.0103 - val_accuracy: 0.8800 - 5s/epoch - 4ms/step\n",
      "Epoch 21/100\n",
      "1185/1185 - 5s - loss: 0.0104 - accuracy: 0.8783 - val_loss: 0.0092 - val_accuracy: 0.9346 - 5s/epoch - 4ms/step\n",
      "Epoch 22/100\n",
      "1185/1185 - 5s - loss: 0.0102 - accuracy: 0.8845 - val_loss: 0.0135 - val_accuracy: 0.7452 - 5s/epoch - 4ms/step\n",
      "Epoch 23/100\n",
      "1185/1185 - 5s - loss: 0.0102 - accuracy: 0.8864 - val_loss: 0.0101 - val_accuracy: 0.8890 - 5s/epoch - 4ms/step\n",
      "Epoch 24/100\n",
      "1185/1185 - 5s - loss: 0.0102 - accuracy: 0.8848 - val_loss: 0.0105 - val_accuracy: 0.8680 - 5s/epoch - 4ms/step\n",
      "Epoch 25/100\n",
      "1185/1185 - 5s - loss: 0.0102 - accuracy: 0.8870 - val_loss: 0.0090 - val_accuracy: 0.9470 - 5s/epoch - 4ms/step\n",
      "Epoch 26/100\n",
      "1185/1185 - 5s - loss: 0.0101 - accuracy: 0.8903 - val_loss: 0.0090 - val_accuracy: 0.9418 - 5s/epoch - 4ms/step\n",
      "Epoch 27/100\n",
      "1185/1185 - 5s - loss: 0.0102 - accuracy: 0.8862 - val_loss: 0.0099 - val_accuracy: 0.8976 - 5s/epoch - 4ms/step\n",
      "Epoch 28/100\n",
      "1185/1185 - 5s - loss: 0.0101 - accuracy: 0.8890 - val_loss: 0.0087 - val_accuracy: 0.9586 - 5s/epoch - 4ms/step\n",
      "Epoch 29/100\n",
      "1185/1185 - 5s - loss: 0.0101 - accuracy: 0.8899 - val_loss: 0.0086 - val_accuracy: 0.9611 - 5s/epoch - 4ms/step\n",
      "Epoch 30/100\n",
      "1185/1185 - 5s - loss: 0.0101 - accuracy: 0.8900 - val_loss: 0.0087 - val_accuracy: 0.9541 - 5s/epoch - 4ms/step\n",
      "Epoch 31/100\n",
      "1185/1185 - 5s - loss: 0.0100 - accuracy: 0.8971 - val_loss: 0.0096 - val_accuracy: 0.9116 - 5s/epoch - 4ms/step\n",
      "Epoch 32/100\n",
      "1185/1185 - 5s - loss: 0.0099 - accuracy: 0.9009 - val_loss: 0.0127 - val_accuracy: 0.7816 - 5s/epoch - 4ms/step\n",
      "Epoch 33/100\n",
      "1185/1185 - 5s - loss: 0.0099 - accuracy: 0.8985 - val_loss: 0.0087 - val_accuracy: 0.9596 - 5s/epoch - 4ms/step\n",
      "Epoch 34/100\n",
      "1185/1185 - 5s - loss: 0.0098 - accuracy: 0.9014 - val_loss: 0.0094 - val_accuracy: 0.9225 - 5s/epoch - 4ms/step\n",
      "Epoch 35/100\n",
      "1185/1185 - 5s - loss: 0.0099 - accuracy: 0.8983 - val_loss: 0.0111 - val_accuracy: 0.8350 - 5s/epoch - 4ms/step\n",
      "Epoch 36/100\n",
      "1185/1185 - 5s - loss: 0.0099 - accuracy: 0.9012 - val_loss: 0.0087 - val_accuracy: 0.9572 - 5s/epoch - 4ms/step\n",
      "Epoch 37/100\n",
      "1185/1185 - 5s - loss: 0.0098 - accuracy: 0.9049 - val_loss: 0.0140 - val_accuracy: 0.7313 - 5s/epoch - 4ms/step\n",
      "Epoch 38/100\n",
      "1185/1185 - 5s - loss: 0.0098 - accuracy: 0.9024 - val_loss: 0.0132 - val_accuracy: 0.7706 - 5s/epoch - 4ms/step\n",
      "Epoch 39/100\n",
      "1185/1185 - 5s - loss: 0.0097 - accuracy: 0.9079 - val_loss: 0.0086 - val_accuracy: 0.9635 - 5s/epoch - 4ms/step\n",
      "Epoch 40/100\n",
      "1185/1185 - 5s - loss: 0.0097 - accuracy: 0.9075 - val_loss: 0.0144 - val_accuracy: 0.7118 - 5s/epoch - 4ms/step\n",
      "Epoch 41/100\n",
      "1185/1185 - 5s - loss: 0.0098 - accuracy: 0.9056 - val_loss: 0.0111 - val_accuracy: 0.8532 - 5s/epoch - 4ms/step\n",
      "Epoch 42/100\n",
      "1185/1185 - 5s - loss: 0.0097 - accuracy: 0.9084 - val_loss: 0.0086 - val_accuracy: 0.9578 - 5s/epoch - 4ms/step\n",
      "Epoch 43/100\n",
      "1185/1185 - 5s - loss: 0.0097 - accuracy: 0.9091 - val_loss: 0.0089 - val_accuracy: 0.9498 - 5s/epoch - 4ms/step\n",
      "Epoch 44/100\n",
      "1185/1185 - 5s - loss: 0.0097 - accuracy: 0.9106 - val_loss: 0.0088 - val_accuracy: 0.9511 - 5s/epoch - 4ms/step\n",
      "Epoch 45/100\n",
      "1185/1185 - 5s - loss: 0.0096 - accuracy: 0.9125 - val_loss: 0.0132 - val_accuracy: 0.7554 - 5s/epoch - 4ms/step\n",
      "Epoch 46/100\n",
      "1185/1185 - 5s - loss: 0.0096 - accuracy: 0.9109 - val_loss: 0.0085 - val_accuracy: 0.9649 - 5s/epoch - 4ms/step\n",
      "Epoch 47/100\n",
      "1185/1185 - 5s - loss: 0.0096 - accuracy: 0.9098 - val_loss: 0.0103 - val_accuracy: 0.8838 - 5s/epoch - 4ms/step\n",
      "Epoch 48/100\n",
      "1185/1185 - 5s - loss: 0.0096 - accuracy: 0.9152 - val_loss: 0.0089 - val_accuracy: 0.9478 - 5s/epoch - 4ms/step\n",
      "Epoch 49/100\n",
      "1185/1185 - 5s - loss: 0.0096 - accuracy: 0.9115 - val_loss: 0.0100 - val_accuracy: 0.8954 - 5s/epoch - 4ms/step\n",
      "Epoch 50/100\n",
      "1185/1185 - 5s - loss: 0.0095 - accuracy: 0.9146 - val_loss: 0.0104 - val_accuracy: 0.8716 - 5s/epoch - 4ms/step\n",
      "Epoch 51/100\n",
      "1185/1185 - 5s - loss: 0.0095 - accuracy: 0.9191 - val_loss: 0.0100 - val_accuracy: 0.8944 - 5s/epoch - 4ms/step\n",
      "Epoch 52/100\n",
      "1185/1185 - 5s - loss: 0.0094 - accuracy: 0.9208 - val_loss: 0.0099 - val_accuracy: 0.9042 - 5s/epoch - 4ms/step\n",
      "Epoch 53/100\n",
      "1185/1185 - 5s - loss: 0.0095 - accuracy: 0.9181 - val_loss: 0.0102 - val_accuracy: 0.8820 - 5s/epoch - 4ms/step\n",
      "Epoch 54/100\n",
      "1185/1185 - 5s - loss: 0.0096 - accuracy: 0.9141 - val_loss: 0.0085 - val_accuracy: 0.9660 - 5s/epoch - 4ms/step\n",
      "Epoch 55/100\n",
      "1185/1185 - 5s - loss: 0.0095 - accuracy: 0.9176 - val_loss: 0.0108 - val_accuracy: 0.8603 - 5s/epoch - 4ms/step\n",
      "Epoch 56/100\n",
      "1185/1185 - 5s - loss: 0.0095 - accuracy: 0.9179 - val_loss: 0.0097 - val_accuracy: 0.9032 - 5s/epoch - 4ms/step\n",
      "Epoch 57/100\n",
      "1185/1185 - 6s - loss: 0.0094 - accuracy: 0.9187 - val_loss: 0.0116 - val_accuracy: 0.8323 - 6s/epoch - 5ms/step\n",
      "Epoch 58/100\n",
      "1185/1185 - 5s - loss: 0.0095 - accuracy: 0.9164 - val_loss: 0.0089 - val_accuracy: 0.9457 - 5s/epoch - 4ms/step\n",
      "Epoch 59/100\n",
      "1185/1185 - 5s - loss: 0.0095 - accuracy: 0.9177 - val_loss: 0.0087 - val_accuracy: 0.9577 - 5s/epoch - 4ms/step\n",
      "Epoch 60/100\n",
      "1185/1185 - 5s - loss: 0.0095 - accuracy: 0.9187 - val_loss: 0.0090 - val_accuracy: 0.9409 - 5s/epoch - 4ms/step\n",
      "Epoch 61/100\n",
      "1185/1185 - 5s - loss: 0.0094 - accuracy: 0.9234 - val_loss: 0.0086 - val_accuracy: 0.9534 - 5s/epoch - 4ms/step\n",
      "Epoch 62/100\n",
      "1185/1185 - 5s - loss: 0.0094 - accuracy: 0.9228 - val_loss: 0.0097 - val_accuracy: 0.9112 - 5s/epoch - 4ms/step\n",
      "Epoch 63/100\n",
      "1185/1185 - 5s - loss: 0.0094 - accuracy: 0.9210 - val_loss: 0.0090 - val_accuracy: 0.9386 - 5s/epoch - 4ms/step\n",
      "Epoch 64/100\n",
      "1185/1185 - 5s - loss: 0.0093 - accuracy: 0.9262 - val_loss: 0.0093 - val_accuracy: 0.9301 - 5s/epoch - 4ms/step\n",
      "Epoch 65/100\n",
      "1185/1185 - 5s - loss: 0.0093 - accuracy: 0.9268 - val_loss: 0.0088 - val_accuracy: 0.9500 - 5s/epoch - 4ms/step\n",
      "Epoch 66/100\n",
      "1185/1185 - 5s - loss: 0.0094 - accuracy: 0.9240 - val_loss: 0.0162 - val_accuracy: 0.6846 - 5s/epoch - 4ms/step\n",
      "Epoch 67/100\n",
      "1185/1185 - 5s - loss: 0.0094 - accuracy: 0.9206 - val_loss: 0.0087 - val_accuracy: 0.9557 - 5s/epoch - 4ms/step\n",
      "Epoch 68/100\n",
      "1185/1185 - 5s - loss: 0.0093 - accuracy: 0.9274 - val_loss: 0.0085 - val_accuracy: 0.9603 - 5s/epoch - 4ms/step\n",
      "Epoch 69/100\n",
      "1185/1185 - 5s - loss: 0.0094 - accuracy: 0.9241 - val_loss: 0.0096 - val_accuracy: 0.9091 - 5s/epoch - 4ms/step\n",
      "Epoch 70/100\n",
      "1185/1185 - 5s - loss: 0.0093 - accuracy: 0.9255 - val_loss: 0.0087 - val_accuracy: 0.9507 - 5s/epoch - 4ms/step\n",
      "Epoch 71/100\n",
      "1185/1185 - 5s - loss: 0.0093 - accuracy: 0.9272 - val_loss: 0.0090 - val_accuracy: 0.9433 - 5s/epoch - 4ms/step\n",
      "Epoch 72/100\n",
      "1185/1185 - 5s - loss: 0.0093 - accuracy: 0.9270 - val_loss: 0.0111 - val_accuracy: 0.8496 - 5s/epoch - 4ms/step\n",
      "Epoch 73/100\n",
      "1185/1185 - 5s - loss: 0.0093 - accuracy: 0.9257 - val_loss: 0.0087 - val_accuracy: 0.9538 - 5s/epoch - 4ms/step\n",
      "Epoch 74/100\n",
      "1185/1185 - 5s - loss: 0.0093 - accuracy: 0.9287 - val_loss: 0.0108 - val_accuracy: 0.8530 - 5s/epoch - 4ms/step\n",
      "Epoch 75/100\n",
      "1185/1185 - 5s - loss: 0.0092 - accuracy: 0.9304 - val_loss: 0.0090 - val_accuracy: 0.9408 - 5s/epoch - 4ms/step\n",
      "Epoch 76/100\n",
      "1185/1185 - 5s - loss: 0.0092 - accuracy: 0.9320 - val_loss: 0.0082 - val_accuracy: 0.9806 - 5s/epoch - 4ms/step\n",
      "Epoch 77/100\n",
      "1185/1185 - 5s - loss: 0.0092 - accuracy: 0.9306 - val_loss: 0.0127 - val_accuracy: 0.7783 - 5s/epoch - 4ms/step\n",
      "Epoch 78/100\n",
      "1185/1185 - 5s - loss: 0.0092 - accuracy: 0.9315 - val_loss: 0.0088 - val_accuracy: 0.9423 - 5s/epoch - 4ms/step\n",
      "Epoch 79/100\n",
      "1185/1185 - 5s - loss: 0.0092 - accuracy: 0.9334 - val_loss: 0.0087 - val_accuracy: 0.9497 - 5s/epoch - 4ms/step\n",
      "Epoch 80/100\n",
      "1185/1185 - 5s - loss: 0.0092 - accuracy: 0.9302 - val_loss: 0.0096 - val_accuracy: 0.9137 - 5s/epoch - 4ms/step\n",
      "Epoch 81/100\n",
      "1185/1185 - 5s - loss: 0.0092 - accuracy: 0.9316 - val_loss: 0.0091 - val_accuracy: 0.9369 - 5s/epoch - 4ms/step\n",
      "Epoch 82/100\n",
      "1185/1185 - 5s - loss: 0.0092 - accuracy: 0.9318 - val_loss: 0.0085 - val_accuracy: 0.9644 - 5s/epoch - 4ms/step\n",
      "Epoch 83/100\n",
      "1185/1185 - 5s - loss: 0.0091 - accuracy: 0.9364 - val_loss: 0.0085 - val_accuracy: 0.9613 - 5s/epoch - 4ms/step\n",
      "Epoch 84/100\n",
      "1185/1185 - 5s - loss: 0.0091 - accuracy: 0.9333 - val_loss: 0.0096 - val_accuracy: 0.9138 - 5s/epoch - 4ms/step\n",
      "Epoch 85/100\n",
      "1185/1185 - 5s - loss: 0.0091 - accuracy: 0.9371 - val_loss: 0.0120 - val_accuracy: 0.8057 - 5s/epoch - 4ms/step\n",
      "Epoch 86/100\n",
      "1185/1185 - 5s - loss: 0.0092 - accuracy: 0.9303 - val_loss: 0.0084 - val_accuracy: 0.9698 - 5s/epoch - 4ms/step\n",
      "Epoch 87/100\n",
      "1185/1185 - 5s - loss: 0.0092 - accuracy: 0.9326 - val_loss: 0.0102 - val_accuracy: 0.8833 - 5s/epoch - 4ms/step\n",
      "Epoch 88/100\n",
      "1185/1185 - 5s - loss: 0.0091 - accuracy: 0.9345 - val_loss: 0.0085 - val_accuracy: 0.9654 - 5s/epoch - 4ms/step\n",
      "Epoch 89/100\n",
      "1185/1185 - 5s - loss: 0.0091 - accuracy: 0.9354 - val_loss: 0.0081 - val_accuracy: 0.9804 - 5s/epoch - 4ms/step\n",
      "Epoch 90/100\n",
      "1185/1185 - 5s - loss: 0.0091 - accuracy: 0.9372 - val_loss: 0.0082 - val_accuracy: 0.9739 - 5s/epoch - 4ms/step\n",
      "Epoch 91/100\n",
      "1185/1185 - 5s - loss: 0.0091 - accuracy: 0.9342 - val_loss: 0.0083 - val_accuracy: 0.9717 - 5s/epoch - 4ms/step\n",
      "Epoch 92/100\n",
      "1185/1185 - 5s - loss: 0.0091 - accuracy: 0.9367 - val_loss: 0.0087 - val_accuracy: 0.9515 - 5s/epoch - 4ms/step\n",
      "Epoch 93/100\n",
      "1185/1185 - 5s - loss: 0.0091 - accuracy: 0.9337 - val_loss: 0.0099 - val_accuracy: 0.8974 - 5s/epoch - 4ms/step\n",
      "Epoch 94/100\n",
      "1185/1185 - 5s - loss: 0.0090 - accuracy: 0.9368 - val_loss: 0.0086 - val_accuracy: 0.9563 - 5s/epoch - 4ms/step\n",
      "Epoch 95/100\n",
      "1185/1185 - 5s - loss: 0.0091 - accuracy: 0.9367 - val_loss: 0.0092 - val_accuracy: 0.9330 - 5s/epoch - 4ms/step\n",
      "Epoch 96/100\n",
      "1185/1185 - 5s - loss: 0.0090 - accuracy: 0.9384 - val_loss: 0.0094 - val_accuracy: 0.9203 - 5s/epoch - 4ms/step\n",
      "Epoch 97/100\n",
      "1185/1185 - 5s - loss: 0.0091 - accuracy: 0.9362 - val_loss: 0.0086 - val_accuracy: 0.9562 - 5s/epoch - 4ms/step\n",
      "Epoch 98/100\n",
      "1185/1185 - 5s - loss: 0.0090 - accuracy: 0.9406 - val_loss: 0.0094 - val_accuracy: 0.9205 - 5s/epoch - 4ms/step\n",
      "Epoch 99/100\n",
      "1185/1185 - 5s - loss: 0.0090 - accuracy: 0.9387 - val_loss: 0.0082 - val_accuracy: 0.9764 - 5s/epoch - 4ms/step\n",
      "Epoch 100/100\n",
      "1185/1185 - 5s - loss: 0.0090 - accuracy: 0.9408 - val_loss: 0.0083 - val_accuracy: 0.9718 - 5s/epoch - 4ms/step\n",
      "Restored model, train accuracy: 98.69%\n",
      "Restored model, valid accuracy: 97.18%\n",
      "Restored model, new_test accuracy: 97.07%\n",
      "Restored model, test accuracy: 82.18%\n"
     ]
    }
   ],
   "source": [
    "network = build_NeuralNetwork()\n",
    "print('Model built.')\n",
    "modelname = 'ann1'\n",
    "checkpointer = ModelCheckpoint(filepath = modelname+'.hdf5', verbose = 0, save_best_only = True)\n",
    "\n",
    "history = network.fit(train_images_array, train_hot_class,\n",
    "    batch_size = 32, #32\n",
    "    epochs = 100, #15\n",
    "    validation_data = (valid_images_array, valid_hot_class),\n",
    "    verbose = 2,\n",
    "    callbacks=[checkpointer],\n",
    "    shuffle = True)\n",
    "\n",
    "network.save('model_'+modelname+'.h5')\n",
    "\n",
    "train_loss, train_acc = network.evaluate(train_images_array, train_hot_class, verbose=0)\n",
    "print('Restored model, train accuracy: {:5.2f}%'.format(100 * train_acc))\n",
    "valid_loss, valid_acc = network.evaluate(valid_images_array, valid_hot_class, verbose=0)\n",
    "print('Restored model, valid accuracy: {:5.2f}%'.format(100 * valid_acc))\n",
    "new_test_loss, new_test_acc = network.evaluate(new_test_images_array, new_test_hot_class, verbose=0)\n",
    "print('Restored model, new_test accuracy: {:5.2f}%'.format(100 * new_test_acc))\n",
    "test_loss, test_acc = network.evaluate(test_images_array, test_hot_class, verbose=0)\n",
    "print('Restored model, test accuracy: {:5.2f}%'.format(100 * test_acc))\n",
    "np.save(modelname+'_history.npy',history.history)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "def build_NeuralNetwork():\n",
    "\n",
    "    #input layer\n",
    "    model = Sequential()\n",
    "    model.add(Input(shape=(100,100,3)))\n",
    "    model.add(Flatten())\n",
    "\n",
    "    #hiddenlayer 1\n",
    "    model.add(Dense(5))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation(activation='tanh'))\n",
    "\n",
    "    #hiddenlayer 2\n",
    "    model.add(Dense(50)) #900\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation(activation='tanh'))\n",
    "    #model.add(Dropout(0.25))\n",
    "\n",
    "    #hiddenlayer 3\n",
    "    model.add(Dense(50)) #900\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation(activation='tanh'))\n",
    "    #model.add(Dropout(0.25))\n",
    "\n",
    "    #hiddenlayer 4\n",
    "    #model.add(Dense(300)) #900\n",
    "    #model.add(BatchNormalization())\n",
    "    #model.add(Activation(activation='relu'))\n",
    "    #model.add(Dropout(0.25))\n",
    "\n",
    "    #output layer\n",
    "    model.add(Dense(131,activation=\"softmax\"))\n",
    "\n",
    "    model.compile(loss = 'poisson', optimizer = \"adam\", metrics = ['accuracy'])\n",
    "    print('Compiled!')\n",
    "\n",
    "    return model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compiled!\n",
      "Model built.\n",
      "Epoch 1/100\n",
      "1185/1185 - 12s - loss: 0.0271 - accuracy: 0.4046 - val_loss: 0.0180 - val_accuracy: 0.6877 - 12s/epoch - 10ms/step\n",
      "Epoch 2/100\n",
      "1185/1185 - 6s - loss: 0.0171 - accuracy: 0.6622 - val_loss: 0.0152 - val_accuracy: 0.7370 - 6s/epoch - 5ms/step\n",
      "Epoch 3/100\n",
      "1185/1185 - 5s - loss: 0.0148 - accuracy: 0.7235 - val_loss: 0.0141 - val_accuracy: 0.7480 - 5s/epoch - 4ms/step\n",
      "Epoch 4/100\n",
      "1185/1185 - 5s - loss: 0.0137 - accuracy: 0.7540 - val_loss: 0.0172 - val_accuracy: 0.5936 - 5s/epoch - 4ms/step\n",
      "Epoch 5/100\n",
      "1185/1185 - 5s - loss: 0.0131 - accuracy: 0.7803 - val_loss: 0.0108 - val_accuracy: 0.8903 - 5s/epoch - 4ms/step\n",
      "Epoch 6/100\n",
      "1185/1185 - 5s - loss: 0.0127 - accuracy: 0.7927 - val_loss: 0.0117 - val_accuracy: 0.8355 - 5s/epoch - 4ms/step\n",
      "Epoch 7/100\n",
      "1185/1185 - 5s - loss: 0.0122 - accuracy: 0.8077 - val_loss: 0.0118 - val_accuracy: 0.8242 - 5s/epoch - 4ms/step\n",
      "Epoch 8/100\n",
      "1185/1185 - 5s - loss: 0.0120 - accuracy: 0.8153 - val_loss: 0.0146 - val_accuracy: 0.6867 - 5s/epoch - 4ms/step\n",
      "Epoch 9/100\n",
      "1185/1185 - 5s - loss: 0.0119 - accuracy: 0.8233 - val_loss: 0.0101 - val_accuracy: 0.9055 - 5s/epoch - 4ms/step\n",
      "Epoch 10/100\n",
      "1185/1185 - 5s - loss: 0.0116 - accuracy: 0.8307 - val_loss: 0.0167 - val_accuracy: 0.6053 - 5s/epoch - 4ms/step\n",
      "Epoch 11/100\n",
      "1185/1185 - 5s - loss: 0.0115 - accuracy: 0.8337 - val_loss: 0.0099 - val_accuracy: 0.9180 - 5s/epoch - 4ms/step\n",
      "Epoch 12/100\n",
      "1185/1185 - 5s - loss: 0.0114 - accuracy: 0.8387 - val_loss: 0.0172 - val_accuracy: 0.5887 - 5s/epoch - 4ms/step\n",
      "Epoch 13/100\n",
      "1185/1185 - 5s - loss: 0.0114 - accuracy: 0.8402 - val_loss: 0.0154 - val_accuracy: 0.6647 - 5s/epoch - 4ms/step\n",
      "Epoch 14/100\n",
      "1185/1185 - 5s - loss: 0.0112 - accuracy: 0.8481 - val_loss: 0.0110 - val_accuracy: 0.8535 - 5s/epoch - 4ms/step\n",
      "Epoch 15/100\n",
      "1185/1185 - 5s - loss: 0.0111 - accuracy: 0.8541 - val_loss: 0.0102 - val_accuracy: 0.8969 - 5s/epoch - 4ms/step\n",
      "Epoch 16/100\n",
      "1185/1185 - 5s - loss: 0.0110 - accuracy: 0.8537 - val_loss: 0.0159 - val_accuracy: 0.6501 - 5s/epoch - 4ms/step\n",
      "Epoch 17/100\n",
      "1185/1185 - 5s - loss: 0.0109 - accuracy: 0.8574 - val_loss: 0.0152 - val_accuracy: 0.6756 - 5s/epoch - 4ms/step\n",
      "Epoch 18/100\n",
      "1185/1185 - 5s - loss: 0.0108 - accuracy: 0.8634 - val_loss: 0.0101 - val_accuracy: 0.8913 - 5s/epoch - 4ms/step\n",
      "Epoch 19/100\n",
      "1185/1185 - 5s - loss: 0.0107 - accuracy: 0.8682 - val_loss: 0.0092 - val_accuracy: 0.9428 - 5s/epoch - 4ms/step\n",
      "Epoch 20/100\n",
      "1185/1185 - 5s - loss: 0.0107 - accuracy: 0.8677 - val_loss: 0.0104 - val_accuracy: 0.8854 - 5s/epoch - 4ms/step\n",
      "Epoch 21/100\n",
      "1185/1185 - 5s - loss: 0.0106 - accuracy: 0.8707 - val_loss: 0.0129 - val_accuracy: 0.7607 - 5s/epoch - 4ms/step\n",
      "Epoch 22/100\n",
      "1185/1185 - 5s - loss: 0.0105 - accuracy: 0.8735 - val_loss: 0.0091 - val_accuracy: 0.9422 - 5s/epoch - 4ms/step\n",
      "Epoch 23/100\n",
      "1185/1185 - 5s - loss: 0.0106 - accuracy: 0.8725 - val_loss: 0.0101 - val_accuracy: 0.8957 - 5s/epoch - 4ms/step\n",
      "Epoch 24/100\n",
      "1185/1185 - 5s - loss: 0.0105 - accuracy: 0.8746 - val_loss: 0.0091 - val_accuracy: 0.9411 - 5s/epoch - 4ms/step\n",
      "Epoch 25/100\n",
      "1185/1185 - 5s - loss: 0.0105 - accuracy: 0.8730 - val_loss: 0.0115 - val_accuracy: 0.8372 - 5s/epoch - 4ms/step\n",
      "Epoch 26/100\n",
      "1185/1185 - 5s - loss: 0.0104 - accuracy: 0.8822 - val_loss: 0.0106 - val_accuracy: 0.8730 - 5s/epoch - 4ms/step\n",
      "Epoch 27/100\n",
      "1185/1185 - 5s - loss: 0.0103 - accuracy: 0.8829 - val_loss: 0.0095 - val_accuracy: 0.9197 - 5s/epoch - 4ms/step\n",
      "Epoch 28/100\n",
      "1185/1185 - 5s - loss: 0.0103 - accuracy: 0.8803 - val_loss: 0.0088 - val_accuracy: 0.9536 - 5s/epoch - 4ms/step\n",
      "Epoch 29/100\n",
      "1185/1185 - 5s - loss: 0.0103 - accuracy: 0.8842 - val_loss: 0.0094 - val_accuracy: 0.9267 - 5s/epoch - 4ms/step\n",
      "Epoch 30/100\n",
      "1185/1185 - 5s - loss: 0.0102 - accuracy: 0.8897 - val_loss: 0.0108 - val_accuracy: 0.8531 - 5s/epoch - 4ms/step\n",
      "Epoch 31/100\n",
      "1185/1185 - 5s - loss: 0.0103 - accuracy: 0.8861 - val_loss: 0.0111 - val_accuracy: 0.8520 - 5s/epoch - 4ms/step\n",
      "Epoch 32/100\n",
      "1185/1185 - 5s - loss: 0.0102 - accuracy: 0.8890 - val_loss: 0.0090 - val_accuracy: 0.9471 - 5s/epoch - 4ms/step\n",
      "Epoch 33/100\n",
      "1185/1185 - 5s - loss: 0.0101 - accuracy: 0.8909 - val_loss: 0.0086 - val_accuracy: 0.9660 - 5s/epoch - 4ms/step\n",
      "Epoch 34/100\n",
      "1185/1185 - 5s - loss: 0.0102 - accuracy: 0.8928 - val_loss: 0.0089 - val_accuracy: 0.9514 - 5s/epoch - 4ms/step\n",
      "Epoch 35/100\n",
      "1185/1185 - 5s - loss: 0.0100 - accuracy: 0.8957 - val_loss: 0.0104 - val_accuracy: 0.8780 - 5s/epoch - 4ms/step\n",
      "Epoch 36/100\n",
      "1185/1185 - 5s - loss: 0.0100 - accuracy: 0.8946 - val_loss: 0.0122 - val_accuracy: 0.7986 - 5s/epoch - 4ms/step\n",
      "Epoch 37/100\n",
      "1185/1185 - 5s - loss: 0.0100 - accuracy: 0.8980 - val_loss: 0.0096 - val_accuracy: 0.9152 - 5s/epoch - 4ms/step\n",
      "Epoch 38/100\n",
      "1185/1185 - 5s - loss: 0.0101 - accuracy: 0.8933 - val_loss: 0.0104 - val_accuracy: 0.8797 - 5s/epoch - 4ms/step\n",
      "Epoch 39/100\n",
      "1185/1185 - 5s - loss: 0.0100 - accuracy: 0.8961 - val_loss: 0.0132 - val_accuracy: 0.7619 - 5s/epoch - 4ms/step\n",
      "Epoch 40/100\n",
      "1185/1185 - 5s - loss: 0.0100 - accuracy: 0.8980 - val_loss: 0.0086 - val_accuracy: 0.9617 - 5s/epoch - 4ms/step\n",
      "Epoch 41/100\n",
      "1185/1185 - 5s - loss: 0.0100 - accuracy: 0.8983 - val_loss: 0.0095 - val_accuracy: 0.9200 - 5s/epoch - 4ms/step\n",
      "Epoch 42/100\n",
      "1185/1185 - 5s - loss: 0.0100 - accuracy: 0.8971 - val_loss: 0.0117 - val_accuracy: 0.8286 - 5s/epoch - 4ms/step\n",
      "Epoch 43/100\n",
      "1185/1185 - 5s - loss: 0.0099 - accuracy: 0.8995 - val_loss: 0.0094 - val_accuracy: 0.9185 - 5s/epoch - 4ms/step\n",
      "Epoch 44/100\n",
      "1185/1185 - 5s - loss: 0.0100 - accuracy: 0.8984 - val_loss: 0.0092 - val_accuracy: 0.9368 - 5s/epoch - 4ms/step\n",
      "Epoch 45/100\n",
      "1185/1185 - 5s - loss: 0.0099 - accuracy: 0.9025 - val_loss: 0.0129 - val_accuracy: 0.7716 - 5s/epoch - 4ms/step\n",
      "Epoch 46/100\n",
      "1185/1185 - 5s - loss: 0.0098 - accuracy: 0.9060 - val_loss: 0.0110 - val_accuracy: 0.8503 - 5s/epoch - 4ms/step\n",
      "Epoch 47/100\n",
      "1185/1185 - 5s - loss: 0.0099 - accuracy: 0.9026 - val_loss: 0.0100 - val_accuracy: 0.8941 - 5s/epoch - 4ms/step\n",
      "Epoch 48/100\n",
      "1185/1185 - 5s - loss: 0.0099 - accuracy: 0.9022 - val_loss: 0.0100 - val_accuracy: 0.8943 - 5s/epoch - 4ms/step\n",
      "Epoch 49/100\n",
      "1185/1185 - 5s - loss: 0.0098 - accuracy: 0.9075 - val_loss: 0.0095 - val_accuracy: 0.9222 - 5s/epoch - 4ms/step\n",
      "Epoch 50/100\n",
      "1185/1185 - 5s - loss: 0.0097 - accuracy: 0.9092 - val_loss: 0.0086 - val_accuracy: 0.9662 - 5s/epoch - 4ms/step\n",
      "Epoch 51/100\n",
      "1185/1185 - 5s - loss: 0.0096 - accuracy: 0.9139 - val_loss: 0.0097 - val_accuracy: 0.9057 - 5s/epoch - 4ms/step\n",
      "Epoch 52/100\n",
      "1185/1185 - 5s - loss: 0.0098 - accuracy: 0.9060 - val_loss: 0.0098 - val_accuracy: 0.9062 - 5s/epoch - 4ms/step\n",
      "Epoch 53/100\n",
      "1185/1185 - 5s - loss: 0.0097 - accuracy: 0.9099 - val_loss: 0.0098 - val_accuracy: 0.9021 - 5s/epoch - 4ms/step\n",
      "Epoch 54/100\n",
      "1185/1185 - 5s - loss: 0.0096 - accuracy: 0.9133 - val_loss: 0.0104 - val_accuracy: 0.8777 - 5s/epoch - 4ms/step\n",
      "Epoch 55/100\n",
      "1185/1185 - 5s - loss: 0.0096 - accuracy: 0.9132 - val_loss: 0.0084 - val_accuracy: 0.9687 - 5s/epoch - 5ms/step\n",
      "Epoch 56/100\n",
      "1185/1185 - 5s - loss: 0.0096 - accuracy: 0.9142 - val_loss: 0.0091 - val_accuracy: 0.9322 - 5s/epoch - 4ms/step\n",
      "Epoch 57/100\n",
      "1185/1185 - 5s - loss: 0.0096 - accuracy: 0.9123 - val_loss: 0.0087 - val_accuracy: 0.9593 - 5s/epoch - 4ms/step\n",
      "Epoch 58/100\n",
      "1185/1185 - 5s - loss: 0.0097 - accuracy: 0.9103 - val_loss: 0.0089 - val_accuracy: 0.9466 - 5s/epoch - 4ms/step\n",
      "Epoch 59/100\n",
      "1185/1185 - 5s - loss: 0.0096 - accuracy: 0.9140 - val_loss: 0.0089 - val_accuracy: 0.9475 - 5s/epoch - 4ms/step\n",
      "Epoch 60/100\n",
      "1185/1185 - 5s - loss: 0.0096 - accuracy: 0.9141 - val_loss: 0.0087 - val_accuracy: 0.9580 - 5s/epoch - 4ms/step\n",
      "Epoch 61/100\n",
      "1185/1185 - 5s - loss: 0.0096 - accuracy: 0.9144 - val_loss: 0.0088 - val_accuracy: 0.9536 - 5s/epoch - 4ms/step\n",
      "Epoch 62/100\n",
      "1185/1185 - 5s - loss: 0.0096 - accuracy: 0.9122 - val_loss: 0.0106 - val_accuracy: 0.8602 - 5s/epoch - 4ms/step\n",
      "Epoch 63/100\n",
      "1185/1185 - 5s - loss: 0.0096 - accuracy: 0.9141 - val_loss: 0.0086 - val_accuracy: 0.9631 - 5s/epoch - 4ms/step\n",
      "Epoch 64/100\n",
      "1185/1185 - 5s - loss: 0.0095 - accuracy: 0.9197 - val_loss: 0.0085 - val_accuracy: 0.9682 - 5s/epoch - 4ms/step\n",
      "Epoch 65/100\n",
      "1185/1185 - 5s - loss: 0.0097 - accuracy: 0.9113 - val_loss: 0.0089 - val_accuracy: 0.9472 - 5s/epoch - 4ms/step\n",
      "Epoch 66/100\n",
      "1185/1185 - 5s - loss: 0.0096 - accuracy: 0.9153 - val_loss: 0.0137 - val_accuracy: 0.7414 - 5s/epoch - 4ms/step\n",
      "Epoch 67/100\n",
      "1185/1185 - 5s - loss: 0.0095 - accuracy: 0.9181 - val_loss: 0.0186 - val_accuracy: 0.5998 - 5s/epoch - 4ms/step\n",
      "Epoch 68/100\n",
      "1185/1185 - 5s - loss: 0.0095 - accuracy: 0.9196 - val_loss: 0.0101 - val_accuracy: 0.8975 - 5s/epoch - 4ms/step\n",
      "Epoch 69/100\n",
      "1185/1185 - 5s - loss: 0.0095 - accuracy: 0.9206 - val_loss: 0.0128 - val_accuracy: 0.7777 - 5s/epoch - 4ms/step\n",
      "Epoch 70/100\n",
      "1185/1185 - 5s - loss: 0.0095 - accuracy: 0.9194 - val_loss: 0.0086 - val_accuracy: 0.9598 - 5s/epoch - 4ms/step\n",
      "Epoch 71/100\n",
      "1185/1185 - 5s - loss: 0.0094 - accuracy: 0.9214 - val_loss: 0.0106 - val_accuracy: 0.8679 - 5s/epoch - 4ms/step\n",
      "Epoch 72/100\n",
      "1185/1185 - 5s - loss: 0.0094 - accuracy: 0.9216 - val_loss: 0.0085 - val_accuracy: 0.9650 - 5s/epoch - 4ms/step\n",
      "Epoch 73/100\n",
      "1185/1185 - 5s - loss: 0.0094 - accuracy: 0.9241 - val_loss: 0.0086 - val_accuracy: 0.9626 - 5s/epoch - 4ms/step\n",
      "Epoch 74/100\n",
      "1185/1185 - 5s - loss: 0.0094 - accuracy: 0.9217 - val_loss: 0.0099 - val_accuracy: 0.9036 - 5s/epoch - 4ms/step\n",
      "Epoch 75/100\n",
      "1185/1185 - 5s - loss: 0.0094 - accuracy: 0.9226 - val_loss: 0.0092 - val_accuracy: 0.9339 - 5s/epoch - 4ms/step\n",
      "Epoch 76/100\n",
      "1185/1185 - 5s - loss: 0.0093 - accuracy: 0.9253 - val_loss: 0.0097 - val_accuracy: 0.9038 - 5s/epoch - 4ms/step\n",
      "Epoch 77/100\n",
      "1185/1185 - 5s - loss: 0.0094 - accuracy: 0.9217 - val_loss: 0.0100 - val_accuracy: 0.8945 - 5s/epoch - 4ms/step\n",
      "Epoch 78/100\n",
      "1185/1185 - 5s - loss: 0.0094 - accuracy: 0.9229 - val_loss: 0.0085 - val_accuracy: 0.9615 - 5s/epoch - 4ms/step\n",
      "Epoch 79/100\n",
      "1185/1185 - 5s - loss: 0.0093 - accuracy: 0.9252 - val_loss: 0.0086 - val_accuracy: 0.9638 - 5s/epoch - 4ms/step\n",
      "Epoch 80/100\n",
      "1185/1185 - 5s - loss: 0.0092 - accuracy: 0.9304 - val_loss: 0.0084 - val_accuracy: 0.9686 - 5s/epoch - 4ms/step\n",
      "Epoch 81/100\n",
      "1185/1185 - 5s - loss: 0.0094 - accuracy: 0.9219 - val_loss: 0.0087 - val_accuracy: 0.9552 - 5s/epoch - 4ms/step\n",
      "Epoch 82/100\n",
      "1185/1185 - 5s - loss: 0.0093 - accuracy: 0.9279 - val_loss: 0.0094 - val_accuracy: 0.9218 - 5s/epoch - 4ms/step\n",
      "Epoch 83/100\n",
      "1185/1185 - 5s - loss: 0.0094 - accuracy: 0.9232 - val_loss: 0.0083 - val_accuracy: 0.9719 - 5s/epoch - 4ms/step\n",
      "Epoch 84/100\n",
      "1185/1185 - 5s - loss: 0.0092 - accuracy: 0.9303 - val_loss: 0.0089 - val_accuracy: 0.9445 - 5s/epoch - 4ms/step\n",
      "Epoch 85/100\n",
      "1185/1185 - 5s - loss: 0.0093 - accuracy: 0.9257 - val_loss: 0.0088 - val_accuracy: 0.9498 - 5s/epoch - 4ms/step\n",
      "Epoch 86/100\n",
      "1185/1185 - 5s - loss: 0.0093 - accuracy: 0.9283 - val_loss: 0.0087 - val_accuracy: 0.9559 - 5s/epoch - 4ms/step\n",
      "Epoch 87/100\n",
      "1185/1185 - 5s - loss: 0.0093 - accuracy: 0.9257 - val_loss: 0.0099 - val_accuracy: 0.8989 - 5s/epoch - 4ms/step\n",
      "Epoch 88/100\n",
      "1185/1185 - 5s - loss: 0.0092 - accuracy: 0.9303 - val_loss: 0.0085 - val_accuracy: 0.9670 - 5s/epoch - 4ms/step\n",
      "Epoch 89/100\n",
      "1185/1185 - 5s - loss: 0.0092 - accuracy: 0.9324 - val_loss: 0.0084 - val_accuracy: 0.9736 - 5s/epoch - 4ms/step\n",
      "Epoch 90/100\n",
      "1185/1185 - 5s - loss: 0.0093 - accuracy: 0.9262 - val_loss: 0.0123 - val_accuracy: 0.8091 - 5s/epoch - 4ms/step\n",
      "Epoch 91/100\n",
      "1185/1185 - 5s - loss: 0.0092 - accuracy: 0.9306 - val_loss: 0.0088 - val_accuracy: 0.9510 - 5s/epoch - 4ms/step\n",
      "Epoch 92/100\n",
      "1185/1185 - 5s - loss: 0.0093 - accuracy: 0.9261 - val_loss: 0.0087 - val_accuracy: 0.9576 - 5s/epoch - 4ms/step\n",
      "Epoch 93/100\n",
      "1185/1185 - 5s - loss: 0.0092 - accuracy: 0.9299 - val_loss: 0.0093 - val_accuracy: 0.9270 - 5s/epoch - 4ms/step\n",
      "Epoch 94/100\n",
      "1185/1185 - 5s - loss: 0.0093 - accuracy: 0.9263 - val_loss: 0.0092 - val_accuracy: 0.9292 - 5s/epoch - 4ms/step\n",
      "Epoch 95/100\n",
      "1185/1185 - 5s - loss: 0.0093 - accuracy: 0.9307 - val_loss: 0.0108 - val_accuracy: 0.8657 - 5s/epoch - 4ms/step\n",
      "Epoch 96/100\n",
      "1185/1185 - 5s - loss: 0.0091 - accuracy: 0.9361 - val_loss: 0.0094 - val_accuracy: 0.9249 - 5s/epoch - 4ms/step\n",
      "Epoch 97/100\n",
      "1185/1185 - 5s - loss: 0.0092 - accuracy: 0.9291 - val_loss: 0.0083 - val_accuracy: 0.9745 - 5s/epoch - 4ms/step\n",
      "Epoch 98/100\n",
      "1185/1185 - 5s - loss: 0.0092 - accuracy: 0.9315 - val_loss: 0.0095 - val_accuracy: 0.9205 - 5s/epoch - 4ms/step\n",
      "Epoch 99/100\n",
      "1185/1185 - 5s - loss: 0.0092 - accuracy: 0.9309 - val_loss: 0.0091 - val_accuracy: 0.9380 - 5s/epoch - 4ms/step\n",
      "Epoch 100/100\n",
      "1185/1185 - 5s - loss: 0.0092 - accuracy: 0.9305 - val_loss: 0.0083 - val_accuracy: 0.9769 - 5s/epoch - 4ms/step\n",
      "Restored model, train accuracy: 99.18%\n",
      "Restored model, valid accuracy: 97.69%\n",
      "Restored model, new_test accuracy: 97.89%\n",
      "Restored model, test accuracy: 82.99%\n"
     ]
    }
   ],
   "source": [
    "network = build_NeuralNetwork()\n",
    "print('Model built.')\n",
    "modelname = 'ann1'\n",
    "checkpointer = ModelCheckpoint(filepath = modelname+'.hdf5', verbose = 0, save_best_only = True)\n",
    "\n",
    "history = network.fit(train_images_array, train_hot_class,\n",
    "    batch_size = 32, #32\n",
    "    epochs = 100, #15\n",
    "    validation_data = (valid_images_array, valid_hot_class),\n",
    "    verbose = 2,\n",
    "    callbacks=[checkpointer],\n",
    "    shuffle = True)\n",
    "\n",
    "network.save('model_'+modelname+'.h5')\n",
    "\n",
    "train_loss, train_acc = network.evaluate(train_images_array, train_hot_class, verbose=0)\n",
    "print('Restored model, train accuracy: {:5.2f}%'.format(100 * train_acc))\n",
    "valid_loss, valid_acc = network.evaluate(valid_images_array, valid_hot_class, verbose=0)\n",
    "print('Restored model, valid accuracy: {:5.2f}%'.format(100 * valid_acc))\n",
    "new_test_loss, new_test_acc = network.evaluate(new_test_images_array, new_test_hot_class, verbose=0)\n",
    "print('Restored model, new_test accuracy: {:5.2f}%'.format(100 * new_test_acc))\n",
    "test_loss, test_acc = network.evaluate(test_images_array, test_hot_class, verbose=0)\n",
    "print('Restored model, test accuracy: {:5.2f}%'.format(100 * test_acc))\n",
    "np.save(modelname+'_history.npy',history.history)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "def build_NeuralNetwork():\n",
    "\n",
    "    #input layer\n",
    "    model = Sequential()\n",
    "    model.add(Input(shape=(100,100,3)))\n",
    "    model.add(Flatten())\n",
    "\n",
    "    #hiddenlayer 1\n",
    "    model.add(Dense(5))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation(activation='sigmoid'))\n",
    "\n",
    "    #hiddenlayer 2\n",
    "    model.add(Dense(50)) #900\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation(activation='sigmoid'))\n",
    "    #model.add(Dropout(0.25))\n",
    "\n",
    "    #hiddenlayer 3\n",
    "    model.add(Dense(50)) #900\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation(activation='sigmoid'))\n",
    "    #model.add(Dropout(0.25))\n",
    "\n",
    "    #hiddenlayer 4\n",
    "    #model.add(Dense(300)) #900\n",
    "    #model.add(BatchNormalization())\n",
    "    #model.add(Activation(activation='relu'))\n",
    "    #model.add(Dropout(0.25))\n",
    "\n",
    "    #output layer\n",
    "    model.add(Dense(131,activation=\"softmax\"))\n",
    "\n",
    "    model.compile(loss = 'poisson', optimizer = \"adam\", metrics = ['accuracy'])\n",
    "    print('Compiled!')\n",
    "\n",
    "    return model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compiled!\n",
      "Model built.\n",
      "Epoch 1/100\n",
      "1185/1185 - 7s - loss: 0.0352 - accuracy: 0.2484 - val_loss: 0.0278 - val_accuracy: 0.3692 - 7s/epoch - 6ms/step\n",
      "Epoch 2/100\n",
      "1185/1185 - 5s - loss: 0.0230 - accuracy: 0.5646 - val_loss: 0.0196 - val_accuracy: 0.6869 - 5s/epoch - 4ms/step\n",
      "Epoch 3/100\n",
      "1185/1185 - 5s - loss: 0.0178 - accuracy: 0.7031 - val_loss: 0.0182 - val_accuracy: 0.5931 - 5s/epoch - 4ms/step\n",
      "Epoch 4/100\n",
      "1185/1185 - 5s - loss: 0.0153 - accuracy: 0.7574 - val_loss: 0.0143 - val_accuracy: 0.7809 - 5s/epoch - 4ms/step\n",
      "Epoch 5/100\n",
      "1185/1185 - 5s - loss: 0.0140 - accuracy: 0.7848 - val_loss: 0.0150 - val_accuracy: 0.6973 - 5s/epoch - 4ms/step\n",
      "Epoch 6/100\n",
      "1185/1185 - 5s - loss: 0.0132 - accuracy: 0.8020 - val_loss: 0.0162 - val_accuracy: 0.6263 - 5s/epoch - 4ms/step\n",
      "Epoch 7/100\n",
      "1185/1185 - 5s - loss: 0.0126 - accuracy: 0.8202 - val_loss: 0.0159 - val_accuracy: 0.6347 - 5s/epoch - 4ms/step\n",
      "Epoch 8/100\n",
      "1185/1185 - 5s - loss: 0.0123 - accuracy: 0.8244 - val_loss: 0.0111 - val_accuracy: 0.8833 - 5s/epoch - 4ms/step\n",
      "Epoch 9/100\n",
      "1185/1185 - 5s - loss: 0.0120 - accuracy: 0.8323 - val_loss: 0.0113 - val_accuracy: 0.8665 - 5s/epoch - 4ms/step\n",
      "Epoch 10/100\n",
      "1185/1185 - 5s - loss: 0.0118 - accuracy: 0.8350 - val_loss: 0.0131 - val_accuracy: 0.7577 - 5s/epoch - 4ms/step\n",
      "Epoch 11/100\n",
      "1185/1185 - 5s - loss: 0.0115 - accuracy: 0.8451 - val_loss: 0.0120 - val_accuracy: 0.8182 - 5s/epoch - 4ms/step\n",
      "Epoch 12/100\n",
      "1185/1185 - 5s - loss: 0.0114 - accuracy: 0.8483 - val_loss: 0.0119 - val_accuracy: 0.8239 - 5s/epoch - 4ms/step\n",
      "Epoch 13/100\n",
      "1185/1185 - 5s - loss: 0.0113 - accuracy: 0.8522 - val_loss: 0.0112 - val_accuracy: 0.8486 - 5s/epoch - 4ms/step\n",
      "Epoch 14/100\n",
      "1185/1185 - 5s - loss: 0.0111 - accuracy: 0.8597 - val_loss: 0.0110 - val_accuracy: 0.8640 - 5s/epoch - 4ms/step\n",
      "Epoch 15/100\n",
      "1185/1185 - 5s - loss: 0.0111 - accuracy: 0.8553 - val_loss: 0.0114 - val_accuracy: 0.8445 - 5s/epoch - 4ms/step\n",
      "Epoch 16/100\n",
      "1185/1185 - 5s - loss: 0.0110 - accuracy: 0.8623 - val_loss: 0.0120 - val_accuracy: 0.8156 - 5s/epoch - 4ms/step\n",
      "Epoch 17/100\n",
      "1185/1185 - 5s - loss: 0.0108 - accuracy: 0.8658 - val_loss: 0.0127 - val_accuracy: 0.7697 - 5s/epoch - 4ms/step\n",
      "Epoch 18/100\n",
      "1185/1185 - 5s - loss: 0.0108 - accuracy: 0.8696 - val_loss: 0.0100 - val_accuracy: 0.9075 - 5s/epoch - 4ms/step\n",
      "Epoch 19/100\n",
      "1185/1185 - 5s - loss: 0.0108 - accuracy: 0.8656 - val_loss: 0.0128 - val_accuracy: 0.7688 - 5s/epoch - 4ms/step\n",
      "Epoch 20/100\n",
      "1185/1185 - 5s - loss: 0.0106 - accuracy: 0.8751 - val_loss: 0.0139 - val_accuracy: 0.7239 - 5s/epoch - 4ms/step\n",
      "Epoch 21/100\n",
      "1185/1185 - 5s - loss: 0.0106 - accuracy: 0.8762 - val_loss: 0.0108 - val_accuracy: 0.8689 - 5s/epoch - 4ms/step\n",
      "Epoch 22/100\n",
      "1185/1185 - 5s - loss: 0.0105 - accuracy: 0.8812 - val_loss: 0.0222 - val_accuracy: 0.4867 - 5s/epoch - 4ms/step\n",
      "Epoch 23/100\n",
      "1185/1185 - 5s - loss: 0.0106 - accuracy: 0.8744 - val_loss: 0.0099 - val_accuracy: 0.9079 - 5s/epoch - 4ms/step\n",
      "Epoch 24/100\n",
      "1185/1185 - 5s - loss: 0.0105 - accuracy: 0.8768 - val_loss: 0.0132 - val_accuracy: 0.7615 - 5s/epoch - 4ms/step\n",
      "Epoch 25/100\n",
      "1185/1185 - 5s - loss: 0.0104 - accuracy: 0.8806 - val_loss: 0.0111 - val_accuracy: 0.8511 - 5s/epoch - 4ms/step\n",
      "Epoch 26/100\n",
      "1185/1185 - 5s - loss: 0.0104 - accuracy: 0.8840 - val_loss: 0.0103 - val_accuracy: 0.8840 - 5s/epoch - 4ms/step\n",
      "Epoch 27/100\n",
      "1185/1185 - 5s - loss: 0.0104 - accuracy: 0.8829 - val_loss: 0.0121 - val_accuracy: 0.8038 - 5s/epoch - 4ms/step\n",
      "Epoch 28/100\n",
      "1185/1185 - 5s - loss: 0.0103 - accuracy: 0.8844 - val_loss: 0.0165 - val_accuracy: 0.6299 - 5s/epoch - 4ms/step\n",
      "Epoch 29/100\n",
      "1185/1185 - 5s - loss: 0.0103 - accuracy: 0.8886 - val_loss: 0.0129 - val_accuracy: 0.7667 - 5s/epoch - 4ms/step\n",
      "Epoch 30/100\n",
      "1185/1185 - 5s - loss: 0.0103 - accuracy: 0.8848 - val_loss: 0.0103 - val_accuracy: 0.8858 - 5s/epoch - 4ms/step\n",
      "Epoch 31/100\n",
      "1185/1185 - 5s - loss: 0.0103 - accuracy: 0.8877 - val_loss: 0.0108 - val_accuracy: 0.8621 - 5s/epoch - 4ms/step\n",
      "Epoch 32/100\n",
      "1185/1185 - 5s - loss: 0.0101 - accuracy: 0.8932 - val_loss: 0.0111 - val_accuracy: 0.8462 - 5s/epoch - 4ms/step\n",
      "Epoch 33/100\n",
      "1185/1185 - 6s - loss: 0.0102 - accuracy: 0.8893 - val_loss: 0.0115 - val_accuracy: 0.8280 - 6s/epoch - 5ms/step\n",
      "Epoch 34/100\n",
      "1185/1185 - 5s - loss: 0.0102 - accuracy: 0.8875 - val_loss: 0.0088 - val_accuracy: 0.9597 - 5s/epoch - 4ms/step\n",
      "Epoch 35/100\n",
      "1185/1185 - 5s - loss: 0.0100 - accuracy: 0.8988 - val_loss: 0.0091 - val_accuracy: 0.9409 - 5s/epoch - 4ms/step\n",
      "Epoch 36/100\n",
      "1185/1185 - 5s - loss: 0.0100 - accuracy: 0.8974 - val_loss: 0.0163 - val_accuracy: 0.6445 - 5s/epoch - 4ms/step\n",
      "Epoch 37/100\n",
      "1185/1185 - 5s - loss: 0.0101 - accuracy: 0.8970 - val_loss: 0.0120 - val_accuracy: 0.8051 - 5s/epoch - 4ms/step\n",
      "Epoch 38/100\n",
      "1185/1185 - 5s - loss: 0.0100 - accuracy: 0.8974 - val_loss: 0.0132 - val_accuracy: 0.7629 - 5s/epoch - 4ms/step\n",
      "Epoch 39/100\n",
      "1185/1185 - 5s - loss: 0.0100 - accuracy: 0.9004 - val_loss: 0.0104 - val_accuracy: 0.8752 - 5s/epoch - 4ms/step\n",
      "Epoch 40/100\n",
      "1185/1185 - 5s - loss: 0.0099 - accuracy: 0.9035 - val_loss: 0.0108 - val_accuracy: 0.8551 - 5s/epoch - 4ms/step\n",
      "Epoch 41/100\n",
      "1185/1185 - 5s - loss: 0.0099 - accuracy: 0.8995 - val_loss: 0.0096 - val_accuracy: 0.9179 - 5s/epoch - 4ms/step\n",
      "Epoch 42/100\n",
      "1185/1185 - 5s - loss: 0.0099 - accuracy: 0.8997 - val_loss: 0.0101 - val_accuracy: 0.8893 - 5s/epoch - 4ms/step\n",
      "Epoch 43/100\n",
      "1185/1185 - 5s - loss: 0.0099 - accuracy: 0.9009 - val_loss: 0.0099 - val_accuracy: 0.9023 - 5s/epoch - 4ms/step\n",
      "Epoch 44/100\n",
      "1185/1185 - 5s - loss: 0.0099 - accuracy: 0.9006 - val_loss: 0.0192 - val_accuracy: 0.5833 - 5s/epoch - 4ms/step\n",
      "Epoch 45/100\n",
      "1185/1185 - 5s - loss: 0.0097 - accuracy: 0.9091 - val_loss: 0.0099 - val_accuracy: 0.9057 - 5s/epoch - 4ms/step\n",
      "Epoch 46/100\n",
      "1185/1185 - 5s - loss: 0.0099 - accuracy: 0.9031 - val_loss: 0.0102 - val_accuracy: 0.8868 - 5s/epoch - 4ms/step\n",
      "Epoch 47/100\n",
      "1185/1185 - 5s - loss: 0.0098 - accuracy: 0.9087 - val_loss: 0.0089 - val_accuracy: 0.9491 - 5s/epoch - 4ms/step\n",
      "Epoch 48/100\n",
      "1185/1185 - 5s - loss: 0.0097 - accuracy: 0.9106 - val_loss: 0.0117 - val_accuracy: 0.8264 - 5s/epoch - 4ms/step\n",
      "Epoch 49/100\n",
      "1185/1185 - 5s - loss: 0.0098 - accuracy: 0.9051 - val_loss: 0.0102 - val_accuracy: 0.8893 - 5s/epoch - 4ms/step\n",
      "Epoch 50/100\n",
      "1185/1185 - 5s - loss: 0.0098 - accuracy: 0.9070 - val_loss: 0.0111 - val_accuracy: 0.8527 - 5s/epoch - 4ms/step\n",
      "Epoch 51/100\n",
      "1185/1185 - 5s - loss: 0.0098 - accuracy: 0.9062 - val_loss: 0.0139 - val_accuracy: 0.7380 - 5s/epoch - 4ms/step\n",
      "Epoch 52/100\n",
      "1185/1185 - 5s - loss: 0.0097 - accuracy: 0.9111 - val_loss: 0.0100 - val_accuracy: 0.8973 - 5s/epoch - 4ms/step\n",
      "Epoch 53/100\n",
      "1185/1185 - 6s - loss: 0.0098 - accuracy: 0.9047 - val_loss: 0.0087 - val_accuracy: 0.9610 - 6s/epoch - 5ms/step\n",
      "Epoch 54/100\n",
      "1185/1185 - 5s - loss: 0.0097 - accuracy: 0.9092 - val_loss: 0.0166 - val_accuracy: 0.6482 - 5s/epoch - 4ms/step\n",
      "Epoch 55/100\n",
      "1185/1185 - 5s - loss: 0.0096 - accuracy: 0.9169 - val_loss: 0.0094 - val_accuracy: 0.9311 - 5s/epoch - 4ms/step\n",
      "Epoch 56/100\n",
      "1185/1185 - 5s - loss: 0.0097 - accuracy: 0.9106 - val_loss: 0.0098 - val_accuracy: 0.9088 - 5s/epoch - 4ms/step\n",
      "Epoch 57/100\n",
      "1185/1185 - 5s - loss: 0.0096 - accuracy: 0.9151 - val_loss: 0.0088 - val_accuracy: 0.9565 - 5s/epoch - 4ms/step\n",
      "Epoch 58/100\n",
      "1185/1185 - 5s - loss: 0.0096 - accuracy: 0.9131 - val_loss: 0.0100 - val_accuracy: 0.8948 - 5s/epoch - 4ms/step\n",
      "Epoch 59/100\n",
      "1185/1185 - 5s - loss: 0.0096 - accuracy: 0.9118 - val_loss: 0.0112 - val_accuracy: 0.8438 - 5s/epoch - 5ms/step\n",
      "Epoch 60/100\n",
      "1185/1185 - 5s - loss: 0.0096 - accuracy: 0.9167 - val_loss: 0.0100 - val_accuracy: 0.9012 - 5s/epoch - 4ms/step\n",
      "Epoch 61/100\n",
      "1185/1185 - 5s - loss: 0.0096 - accuracy: 0.9147 - val_loss: 0.0106 - val_accuracy: 0.8716 - 5s/epoch - 4ms/step\n",
      "Epoch 62/100\n",
      "1185/1185 - 5s - loss: 0.0095 - accuracy: 0.9185 - val_loss: 0.0108 - val_accuracy: 0.8660 - 5s/epoch - 4ms/step\n",
      "Epoch 63/100\n",
      "1185/1185 - 5s - loss: 0.0095 - accuracy: 0.9181 - val_loss: 0.0107 - val_accuracy: 0.8673 - 5s/epoch - 4ms/step\n",
      "Epoch 64/100\n",
      "1185/1185 - 5s - loss: 0.0095 - accuracy: 0.9200 - val_loss: 0.0094 - val_accuracy: 0.9287 - 5s/epoch - 4ms/step\n",
      "Epoch 65/100\n",
      "1185/1185 - 5s - loss: 0.0095 - accuracy: 0.9204 - val_loss: 0.0095 - val_accuracy: 0.9210 - 5s/epoch - 4ms/step\n",
      "Epoch 66/100\n",
      "1185/1185 - 5s - loss: 0.0095 - accuracy: 0.9190 - val_loss: 0.0092 - val_accuracy: 0.9380 - 5s/epoch - 4ms/step\n",
      "Epoch 67/100\n",
      "1185/1185 - 5s - loss: 0.0096 - accuracy: 0.9151 - val_loss: 0.0104 - val_accuracy: 0.8795 - 5s/epoch - 4ms/step\n",
      "Epoch 68/100\n",
      "1185/1185 - 5s - loss: 0.0096 - accuracy: 0.9165 - val_loss: 0.0098 - val_accuracy: 0.9077 - 5s/epoch - 4ms/step\n",
      "Epoch 69/100\n",
      "1185/1185 - 5s - loss: 0.0095 - accuracy: 0.9163 - val_loss: 0.0091 - val_accuracy: 0.9368 - 5s/epoch - 4ms/step\n",
      "Epoch 70/100\n",
      "1185/1185 - 5s - loss: 0.0095 - accuracy: 0.9200 - val_loss: 0.0122 - val_accuracy: 0.8081 - 5s/epoch - 4ms/step\n",
      "Epoch 71/100\n",
      "1185/1185 - 5s - loss: 0.0095 - accuracy: 0.9202 - val_loss: 0.0091 - val_accuracy: 0.9390 - 5s/epoch - 4ms/step\n",
      "Epoch 72/100\n",
      "1185/1185 - 5s - loss: 0.0094 - accuracy: 0.9231 - val_loss: 0.0097 - val_accuracy: 0.9119 - 5s/epoch - 4ms/step\n",
      "Epoch 73/100\n",
      "1185/1185 - 5s - loss: 0.0094 - accuracy: 0.9230 - val_loss: 0.0095 - val_accuracy: 0.9212 - 5s/epoch - 4ms/step\n",
      "Epoch 74/100\n",
      "1185/1185 - 5s - loss: 0.0095 - accuracy: 0.9175 - val_loss: 0.0155 - val_accuracy: 0.7049 - 5s/epoch - 4ms/step\n",
      "Epoch 75/100\n",
      "1185/1185 - 5s - loss: 0.0094 - accuracy: 0.9250 - val_loss: 0.0089 - val_accuracy: 0.9473 - 5s/epoch - 4ms/step\n",
      "Epoch 76/100\n",
      "1185/1185 - 5s - loss: 0.0094 - accuracy: 0.9233 - val_loss: 0.0126 - val_accuracy: 0.7951 - 5s/epoch - 4ms/step\n",
      "Epoch 77/100\n",
      "1185/1185 - 5s - loss: 0.0093 - accuracy: 0.9275 - val_loss: 0.0101 - val_accuracy: 0.8926 - 5s/epoch - 4ms/step\n",
      "Epoch 78/100\n",
      "1185/1185 - 5s - loss: 0.0095 - accuracy: 0.9191 - val_loss: 0.0155 - val_accuracy: 0.6992 - 5s/epoch - 4ms/step\n",
      "Epoch 79/100\n",
      "1185/1185 - 6s - loss: 0.0093 - accuracy: 0.9284 - val_loss: 0.0098 - val_accuracy: 0.9098 - 6s/epoch - 5ms/step\n",
      "Epoch 80/100\n",
      "1185/1185 - 6s - loss: 0.0094 - accuracy: 0.9226 - val_loss: 0.0103 - val_accuracy: 0.8834 - 6s/epoch - 5ms/step\n",
      "Epoch 81/100\n",
      "1185/1185 - 5s - loss: 0.0094 - accuracy: 0.9220 - val_loss: 0.0111 - val_accuracy: 0.8409 - 5s/epoch - 4ms/step\n",
      "Epoch 82/100\n",
      "1185/1185 - 5s - loss: 0.0094 - accuracy: 0.9241 - val_loss: 0.0106 - val_accuracy: 0.8735 - 5s/epoch - 4ms/step\n",
      "Epoch 83/100\n",
      "1185/1185 - 5s - loss: 0.0093 - accuracy: 0.9271 - val_loss: 0.0090 - val_accuracy: 0.9432 - 5s/epoch - 4ms/step\n",
      "Epoch 84/100\n",
      "1185/1185 - 5s - loss: 0.0094 - accuracy: 0.9235 - val_loss: 0.0134 - val_accuracy: 0.7744 - 5s/epoch - 4ms/step\n",
      "Epoch 85/100\n",
      "1185/1185 - 5s - loss: 0.0093 - accuracy: 0.9294 - val_loss: 0.0141 - val_accuracy: 0.7614 - 5s/epoch - 4ms/step\n",
      "Epoch 86/100\n",
      "1185/1185 - 5s - loss: 0.0093 - accuracy: 0.9254 - val_loss: 0.0087 - val_accuracy: 0.9556 - 5s/epoch - 4ms/step\n",
      "Epoch 87/100\n",
      "1185/1185 - 5s - loss: 0.0092 - accuracy: 0.9324 - val_loss: 0.0094 - val_accuracy: 0.9277 - 5s/epoch - 4ms/step\n",
      "Epoch 88/100\n",
      "1185/1185 - 5s - loss: 0.0093 - accuracy: 0.9276 - val_loss: 0.0097 - val_accuracy: 0.9084 - 5s/epoch - 4ms/step\n",
      "Epoch 89/100\n",
      "1185/1185 - 5s - loss: 0.0093 - accuracy: 0.9294 - val_loss: 0.0113 - val_accuracy: 0.8339 - 5s/epoch - 4ms/step\n",
      "Epoch 90/100\n",
      "1185/1185 - 5s - loss: 0.0092 - accuracy: 0.9297 - val_loss: 0.0131 - val_accuracy: 0.7738 - 5s/epoch - 4ms/step\n",
      "Epoch 91/100\n",
      "1185/1185 - 5s - loss: 0.0092 - accuracy: 0.9291 - val_loss: 0.0115 - val_accuracy: 0.8294 - 5s/epoch - 4ms/step\n",
      "Epoch 92/100\n",
      "1185/1185 - 5s - loss: 0.0092 - accuracy: 0.9310 - val_loss: 0.0102 - val_accuracy: 0.8869 - 5s/epoch - 4ms/step\n",
      "Epoch 93/100\n",
      "1185/1185 - 5s - loss: 0.0093 - accuracy: 0.9257 - val_loss: 0.0085 - val_accuracy: 0.9702 - 5s/epoch - 4ms/step\n",
      "Epoch 94/100\n",
      "1185/1185 - 5s - loss: 0.0093 - accuracy: 0.9270 - val_loss: 0.0091 - val_accuracy: 0.9367 - 5s/epoch - 4ms/step\n",
      "Epoch 95/100\n",
      "1185/1185 - 5s - loss: 0.0092 - accuracy: 0.9332 - val_loss: 0.0103 - val_accuracy: 0.8857 - 5s/epoch - 4ms/step\n",
      "Epoch 96/100\n",
      "1185/1185 - 5s - loss: 0.0092 - accuracy: 0.9310 - val_loss: 0.0087 - val_accuracy: 0.9558 - 5s/epoch - 4ms/step\n",
      "Epoch 97/100\n",
      "1185/1185 - 5s - loss: 0.0092 - accuracy: 0.9334 - val_loss: 0.0090 - val_accuracy: 0.9441 - 5s/epoch - 4ms/step\n",
      "Epoch 98/100\n",
      "1185/1185 - 5s - loss: 0.0093 - accuracy: 0.9283 - val_loss: 0.0092 - val_accuracy: 0.9389 - 5s/epoch - 4ms/step\n",
      "Epoch 99/100\n",
      "1185/1185 - 5s - loss: 0.0092 - accuracy: 0.9323 - val_loss: 0.0098 - val_accuracy: 0.9090 - 5s/epoch - 4ms/step\n",
      "Epoch 100/100\n",
      "1185/1185 - 5s - loss: 0.0092 - accuracy: 0.9333 - val_loss: 0.0093 - val_accuracy: 0.9285 - 5s/epoch - 4ms/step\n",
      "Restored model, train accuracy: 95.78%\n",
      "Restored model, valid accuracy: 92.85%\n",
      "Restored model, new_test accuracy: 92.81%\n",
      "Restored model, test accuracy: 74.75%\n"
     ]
    }
   ],
   "source": [
    "network = build_NeuralNetwork()\n",
    "print('Model built.')\n",
    "modelname = 'ann1'\n",
    "checkpointer = ModelCheckpoint(filepath = modelname+'.hdf5', verbose = 0, save_best_only = True)\n",
    "\n",
    "history = network.fit(train_images_array, train_hot_class,\n",
    "    batch_size = 32, #32\n",
    "    epochs = 100, #15\n",
    "    validation_data = (valid_images_array, valid_hot_class),\n",
    "    verbose = 2,\n",
    "    callbacks=[checkpointer],\n",
    "    shuffle = True)\n",
    "\n",
    "network.save('model_'+modelname+'.h5')\n",
    "\n",
    "train_loss, train_acc = network.evaluate(train_images_array, train_hot_class, verbose=0)\n",
    "print('Restored model, train accuracy: {:5.2f}%'.format(100 * train_acc))\n",
    "valid_loss, valid_acc = network.evaluate(valid_images_array, valid_hot_class, verbose=0)\n",
    "print('Restored model, valid accuracy: {:5.2f}%'.format(100 * valid_acc))\n",
    "new_test_loss, new_test_acc = network.evaluate(new_test_images_array, new_test_hot_class, verbose=0)\n",
    "print('Restored model, new_test accuracy: {:5.2f}%'.format(100 * new_test_acc))\n",
    "test_loss, test_acc = network.evaluate(test_images_array, test_hot_class, verbose=0)\n",
    "print('Restored model, test accuracy: {:5.2f}%'.format(100 * test_acc))\n",
    "np.save(modelname+'_history.npy',history.history)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "def build_NeuralNetwork():\n",
    "\n",
    "    #input layer\n",
    "    model = Sequential()\n",
    "    model.add(Input(shape=(100,100,3)))\n",
    "    model.add(Flatten())\n",
    "\n",
    "    #hiddenlayer 1\n",
    "    model.add(Dense(5))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation(activation='relu'))\n",
    "\n",
    "    #hiddenlayer 2\n",
    "    model.add(Dense(50)) #900\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation(activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "\n",
    "    #hiddenlayer 3\n",
    "    model.add(Dense(50)) #900\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation(activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "\n",
    "    #hiddenlayer 4\n",
    "    #model.add(Dense(300)) #900\n",
    "    #model.add(BatchNormalization())\n",
    "    #model.add(Activation(activation='relu'))\n",
    "    #model.add(Dropout(0.25))\n",
    "\n",
    "    #output layer\n",
    "    model.add(Dense(131,activation=\"softmax\"))\n",
    "\n",
    "    model.compile(loss = 'poisson', optimizer = \"adam\", metrics = ['accuracy'])\n",
    "    print('Compiled!')\n",
    "\n",
    "    return model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compiled!\n",
      "Model built.\n",
      "Epoch 1/100\n",
      "1185/1185 - 23s - loss: 0.0385 - accuracy: 0.0737 - val_loss: 0.0305 - val_accuracy: 0.2366 - 23s/epoch - 20ms/step\n",
      "Epoch 2/100\n",
      "1185/1185 - 6s - loss: 0.0307 - accuracy: 0.1724 - val_loss: 0.0261 - val_accuracy: 0.3130 - 6s/epoch - 5ms/step\n",
      "Epoch 3/100\n",
      "1185/1185 - 6s - loss: 0.0279 - accuracy: 0.2353 - val_loss: 0.0223 - val_accuracy: 0.4367 - 6s/epoch - 5ms/step\n",
      "Epoch 4/100\n",
      "1185/1185 - 6s - loss: 0.0264 - accuracy: 0.2777 - val_loss: 0.0210 - val_accuracy: 0.4658 - 6s/epoch - 5ms/step\n",
      "Epoch 5/100\n",
      "1185/1185 - 6s - loss: 0.0254 - accuracy: 0.3069 - val_loss: 0.0202 - val_accuracy: 0.5123 - 6s/epoch - 5ms/step\n",
      "Epoch 6/100\n",
      "1185/1185 - 6s - loss: 0.0247 - accuracy: 0.3309 - val_loss: 0.0194 - val_accuracy: 0.5083 - 6s/epoch - 5ms/step\n",
      "Epoch 7/100\n",
      "1185/1185 - 6s - loss: 0.0242 - accuracy: 0.3451 - val_loss: 0.0172 - val_accuracy: 0.6838 - 6s/epoch - 5ms/step\n",
      "Epoch 8/100\n",
      "1185/1185 - 5s - loss: 0.0238 - accuracy: 0.3576 - val_loss: 0.0215 - val_accuracy: 0.3919 - 5s/epoch - 5ms/step\n",
      "Epoch 9/100\n",
      "1185/1185 - 5s - loss: 0.0235 - accuracy: 0.3691 - val_loss: 0.0181 - val_accuracy: 0.5706 - 5s/epoch - 5ms/step\n",
      "Epoch 10/100\n",
      "1185/1185 - 6s - loss: 0.0231 - accuracy: 0.3780 - val_loss: 0.0159 - val_accuracy: 0.7339 - 6s/epoch - 5ms/step\n",
      "Epoch 11/100\n",
      "1185/1185 - 6s - loss: 0.0229 - accuracy: 0.3874 - val_loss: 0.0163 - val_accuracy: 0.6689 - 6s/epoch - 5ms/step\n",
      "Epoch 12/100\n",
      "1185/1185 - 6s - loss: 0.0227 - accuracy: 0.3936 - val_loss: 0.0164 - val_accuracy: 0.6798 - 6s/epoch - 5ms/step\n",
      "Epoch 13/100\n",
      "1185/1185 - 6s - loss: 0.0225 - accuracy: 0.3990 - val_loss: 0.0165 - val_accuracy: 0.6462 - 6s/epoch - 5ms/step\n",
      "Epoch 14/100\n",
      "1185/1185 - 5s - loss: 0.0224 - accuracy: 0.4070 - val_loss: 0.0170 - val_accuracy: 0.6313 - 5s/epoch - 5ms/step\n",
      "Epoch 15/100\n",
      "1185/1185 - 6s - loss: 0.0222 - accuracy: 0.4112 - val_loss: 0.0153 - val_accuracy: 0.7329 - 6s/epoch - 5ms/step\n",
      "Epoch 16/100\n",
      "1185/1185 - 5s - loss: 0.0221 - accuracy: 0.4175 - val_loss: 0.0160 - val_accuracy: 0.6936 - 5s/epoch - 5ms/step\n",
      "Epoch 17/100\n",
      "1185/1185 - 6s - loss: 0.0219 - accuracy: 0.4168 - val_loss: 0.0141 - val_accuracy: 0.8042 - 6s/epoch - 5ms/step\n",
      "Epoch 18/100\n",
      "1185/1185 - 5s - loss: 0.0219 - accuracy: 0.4270 - val_loss: 0.0149 - val_accuracy: 0.7509 - 5s/epoch - 5ms/step\n",
      "Epoch 19/100\n",
      "1185/1185 - 5s - loss: 0.0217 - accuracy: 0.4296 - val_loss: 0.0156 - val_accuracy: 0.6809 - 5s/epoch - 4ms/step\n",
      "Epoch 20/100\n",
      "1185/1185 - 5s - loss: 0.0217 - accuracy: 0.4350 - val_loss: 0.0150 - val_accuracy: 0.7386 - 5s/epoch - 4ms/step\n",
      "Epoch 21/100\n",
      "1185/1185 - 5s - loss: 0.0215 - accuracy: 0.4327 - val_loss: 0.0167 - val_accuracy: 0.6150 - 5s/epoch - 4ms/step\n",
      "Epoch 22/100\n",
      "1185/1185 - 5s - loss: 0.0214 - accuracy: 0.4379 - val_loss: 0.0150 - val_accuracy: 0.7082 - 5s/epoch - 4ms/step\n",
      "Epoch 23/100\n",
      "1185/1185 - 5s - loss: 0.0214 - accuracy: 0.4373 - val_loss: 0.0149 - val_accuracy: 0.7299 - 5s/epoch - 4ms/step\n",
      "Epoch 24/100\n",
      "1185/1185 - 5s - loss: 0.0213 - accuracy: 0.4436 - val_loss: 0.0146 - val_accuracy: 0.7517 - 5s/epoch - 4ms/step\n",
      "Epoch 25/100\n",
      "1185/1185 - 5s - loss: 0.0212 - accuracy: 0.4497 - val_loss: 0.0158 - val_accuracy: 0.6617 - 5s/epoch - 4ms/step\n",
      "Epoch 26/100\n",
      "1185/1185 - 5s - loss: 0.0210 - accuracy: 0.4581 - val_loss: 0.0157 - val_accuracy: 0.6742 - 5s/epoch - 4ms/step\n",
      "Epoch 27/100\n",
      "1185/1185 - 5s - loss: 0.0211 - accuracy: 0.4562 - val_loss: 0.0163 - val_accuracy: 0.6480 - 5s/epoch - 4ms/step\n",
      "Epoch 28/100\n",
      "1185/1185 - 5s - loss: 0.0211 - accuracy: 0.4527 - val_loss: 0.0154 - val_accuracy: 0.6925 - 5s/epoch - 4ms/step\n",
      "Epoch 29/100\n",
      "1185/1185 - 5s - loss: 0.0209 - accuracy: 0.4632 - val_loss: 0.0147 - val_accuracy: 0.7362 - 5s/epoch - 4ms/step\n",
      "Epoch 30/100\n",
      "1185/1185 - 5s - loss: 0.0209 - accuracy: 0.4611 - val_loss: 0.0147 - val_accuracy: 0.7456 - 5s/epoch - 5ms/step\n",
      "Epoch 31/100\n",
      "1185/1185 - 5s - loss: 0.0208 - accuracy: 0.4647 - val_loss: 0.0136 - val_accuracy: 0.7915 - 5s/epoch - 5ms/step\n",
      "Epoch 32/100\n",
      "1185/1185 - 5s - loss: 0.0208 - accuracy: 0.4643 - val_loss: 0.0160 - val_accuracy: 0.6554 - 5s/epoch - 4ms/step\n",
      "Epoch 33/100\n",
      "1185/1185 - 5s - loss: 0.0206 - accuracy: 0.4666 - val_loss: 0.0145 - val_accuracy: 0.7490 - 5s/epoch - 4ms/step\n",
      "Epoch 34/100\n",
      "1185/1185 - 5s - loss: 0.0207 - accuracy: 0.4695 - val_loss: 0.0136 - val_accuracy: 0.7876 - 5s/epoch - 4ms/step\n",
      "Epoch 35/100\n",
      "1185/1185 - 5s - loss: 0.0206 - accuracy: 0.4725 - val_loss: 0.0133 - val_accuracy: 0.8042 - 5s/epoch - 5ms/step\n",
      "Epoch 36/100\n",
      "1185/1185 - 5s - loss: 0.0204 - accuracy: 0.4791 - val_loss: 0.0140 - val_accuracy: 0.7819 - 5s/epoch - 4ms/step\n",
      "Epoch 37/100\n",
      "1185/1185 - 5s - loss: 0.0203 - accuracy: 0.4835 - val_loss: 0.0130 - val_accuracy: 0.8415 - 5s/epoch - 5ms/step\n",
      "Epoch 38/100\n",
      "1185/1185 - 5s - loss: 0.0203 - accuracy: 0.4834 - val_loss: 0.0135 - val_accuracy: 0.8085 - 5s/epoch - 4ms/step\n",
      "Epoch 39/100\n",
      "1185/1185 - 5s - loss: 0.0203 - accuracy: 0.4815 - val_loss: 0.0132 - val_accuracy: 0.8058 - 5s/epoch - 4ms/step\n",
      "Epoch 40/100\n",
      "1185/1185 - 5s - loss: 0.0202 - accuracy: 0.4894 - val_loss: 0.0137 - val_accuracy: 0.7990 - 5s/epoch - 4ms/step\n",
      "Epoch 41/100\n",
      "1185/1185 - 5s - loss: 0.0202 - accuracy: 0.4870 - val_loss: 0.0137 - val_accuracy: 0.7921 - 5s/epoch - 4ms/step\n",
      "Epoch 42/100\n",
      "1185/1185 - 5s - loss: 0.0201 - accuracy: 0.4862 - val_loss: 0.0125 - val_accuracy: 0.8585 - 5s/epoch - 4ms/step\n",
      "Epoch 43/100\n",
      "1185/1185 - 5s - loss: 0.0201 - accuracy: 0.4939 - val_loss: 0.0126 - val_accuracy: 0.8715 - 5s/epoch - 4ms/step\n",
      "Epoch 44/100\n",
      "1185/1185 - 5s - loss: 0.0201 - accuracy: 0.4890 - val_loss: 0.0164 - val_accuracy: 0.6231 - 5s/epoch - 4ms/step\n",
      "Epoch 45/100\n",
      "1185/1185 - 5s - loss: 0.0202 - accuracy: 0.4899 - val_loss: 0.0135 - val_accuracy: 0.8020 - 5s/epoch - 4ms/step\n",
      "Epoch 46/100\n",
      "1185/1185 - 5s - loss: 0.0199 - accuracy: 0.4984 - val_loss: 0.0144 - val_accuracy: 0.7312 - 5s/epoch - 5ms/step\n",
      "Epoch 47/100\n",
      "1185/1185 - 6s - loss: 0.0199 - accuracy: 0.5014 - val_loss: 0.0150 - val_accuracy: 0.6909 - 6s/epoch - 5ms/step\n",
      "Epoch 48/100\n",
      "1185/1185 - 5s - loss: 0.0200 - accuracy: 0.4999 - val_loss: 0.0126 - val_accuracy: 0.8539 - 5s/epoch - 4ms/step\n",
      "Epoch 49/100\n",
      "1185/1185 - 5s - loss: 0.0199 - accuracy: 0.4983 - val_loss: 0.0186 - val_accuracy: 0.5638 - 5s/epoch - 5ms/step\n",
      "Epoch 50/100\n",
      "1185/1185 - 6s - loss: 0.0199 - accuracy: 0.5000 - val_loss: 0.0127 - val_accuracy: 0.8484 - 6s/epoch - 5ms/step\n",
      "Epoch 51/100\n",
      "1185/1185 - 6s - loss: 0.0198 - accuracy: 0.5036 - val_loss: 0.0132 - val_accuracy: 0.8133 - 6s/epoch - 5ms/step\n",
      "Epoch 52/100\n",
      "1185/1185 - 5s - loss: 0.0198 - accuracy: 0.5055 - val_loss: 0.0147 - val_accuracy: 0.7320 - 5s/epoch - 5ms/step\n",
      "Epoch 53/100\n",
      "1185/1185 - 5s - loss: 0.0198 - accuracy: 0.5081 - val_loss: 0.0131 - val_accuracy: 0.8138 - 5s/epoch - 4ms/step\n",
      "Epoch 54/100\n",
      "1185/1185 - 5s - loss: 0.0197 - accuracy: 0.5110 - val_loss: 0.0171 - val_accuracy: 0.5713 - 5s/epoch - 4ms/step\n",
      "Epoch 55/100\n",
      "1185/1185 - 5s - loss: 0.0198 - accuracy: 0.5076 - val_loss: 0.0128 - val_accuracy: 0.8398 - 5s/epoch - 4ms/step\n",
      "Epoch 56/100\n",
      "1185/1185 - 5s - loss: 0.0196 - accuracy: 0.5113 - val_loss: 0.0134 - val_accuracy: 0.7826 - 5s/epoch - 4ms/step\n",
      "Epoch 57/100\n",
      "1185/1185 - 5s - loss: 0.0195 - accuracy: 0.5144 - val_loss: 0.0127 - val_accuracy: 0.8316 - 5s/epoch - 4ms/step\n",
      "Epoch 58/100\n",
      "1185/1185 - 5s - loss: 0.0196 - accuracy: 0.5080 - val_loss: 0.0126 - val_accuracy: 0.8396 - 5s/epoch - 4ms/step\n",
      "Epoch 59/100\n",
      "1185/1185 - 5s - loss: 0.0195 - accuracy: 0.5186 - val_loss: 0.0126 - val_accuracy: 0.8368 - 5s/epoch - 4ms/step\n",
      "Epoch 60/100\n",
      "1185/1185 - 5s - loss: 0.0195 - accuracy: 0.5151 - val_loss: 0.0124 - val_accuracy: 0.8605 - 5s/epoch - 4ms/step\n",
      "Epoch 61/100\n",
      "1185/1185 - 5s - loss: 0.0195 - accuracy: 0.5200 - val_loss: 0.0135 - val_accuracy: 0.7910 - 5s/epoch - 4ms/step\n",
      "Epoch 62/100\n",
      "1185/1185 - 5s - loss: 0.0195 - accuracy: 0.5177 - val_loss: 0.0157 - val_accuracy: 0.6612 - 5s/epoch - 5ms/step\n",
      "Epoch 63/100\n",
      "1185/1185 - 5s - loss: 0.0194 - accuracy: 0.5223 - val_loss: 0.0124 - val_accuracy: 0.8484 - 5s/epoch - 5ms/step\n",
      "Epoch 64/100\n",
      "1185/1185 - 5s - loss: 0.0193 - accuracy: 0.5238 - val_loss: 0.0178 - val_accuracy: 0.6047 - 5s/epoch - 4ms/step\n",
      "Epoch 65/100\n",
      "1185/1185 - 5s - loss: 0.0193 - accuracy: 0.5231 - val_loss: 0.0127 - val_accuracy: 0.8387 - 5s/epoch - 5ms/step\n",
      "Epoch 66/100\n",
      "1185/1185 - 5s - loss: 0.0194 - accuracy: 0.5215 - val_loss: 0.0121 - val_accuracy: 0.8606 - 5s/epoch - 5ms/step\n",
      "Epoch 67/100\n",
      "1185/1185 - 5s - loss: 0.0195 - accuracy: 0.5164 - val_loss: 0.0121 - val_accuracy: 0.8750 - 5s/epoch - 5ms/step\n",
      "Epoch 68/100\n",
      "1185/1185 - 5s - loss: 0.0193 - accuracy: 0.5237 - val_loss: 0.0122 - val_accuracy: 0.8742 - 5s/epoch - 5ms/step\n",
      "Epoch 69/100\n",
      "1185/1185 - 5s - loss: 0.0195 - accuracy: 0.5205 - val_loss: 0.0132 - val_accuracy: 0.8068 - 5s/epoch - 5ms/step\n",
      "Epoch 70/100\n",
      "1185/1185 - 5s - loss: 0.0192 - accuracy: 0.5280 - val_loss: 0.0121 - val_accuracy: 0.8617 - 5s/epoch - 5ms/step\n",
      "Epoch 71/100\n",
      "1185/1185 - 5s - loss: 0.0193 - accuracy: 0.5216 - val_loss: 0.0130 - val_accuracy: 0.8113 - 5s/epoch - 5ms/step\n",
      "Epoch 72/100\n",
      "1185/1185 - 5s - loss: 0.0192 - accuracy: 0.5268 - val_loss: 0.0133 - val_accuracy: 0.7967 - 5s/epoch - 4ms/step\n",
      "Epoch 73/100\n",
      "1185/1185 - 5s - loss: 0.0193 - accuracy: 0.5246 - val_loss: 0.0125 - val_accuracy: 0.8506 - 5s/epoch - 4ms/step\n",
      "Epoch 74/100\n",
      "1185/1185 - 5s - loss: 0.0192 - accuracy: 0.5303 - val_loss: 0.0130 - val_accuracy: 0.8104 - 5s/epoch - 4ms/step\n",
      "Epoch 75/100\n",
      "1185/1185 - 5s - loss: 0.0192 - accuracy: 0.5296 - val_loss: 0.0127 - val_accuracy: 0.8280 - 5s/epoch - 4ms/step\n",
      "Epoch 76/100\n",
      "1185/1185 - 5s - loss: 0.0192 - accuracy: 0.5317 - val_loss: 0.0138 - val_accuracy: 0.7710 - 5s/epoch - 4ms/step\n",
      "Epoch 77/100\n",
      "1185/1185 - 6s - loss: 0.0191 - accuracy: 0.5298 - val_loss: 0.0119 - val_accuracy: 0.8777 - 6s/epoch - 5ms/step\n",
      "Epoch 78/100\n",
      "1185/1185 - 5s - loss: 0.0190 - accuracy: 0.5357 - val_loss: 0.0122 - val_accuracy: 0.8589 - 5s/epoch - 4ms/step\n",
      "Epoch 79/100\n",
      "1185/1185 - 5s - loss: 0.0190 - accuracy: 0.5351 - val_loss: 0.0139 - val_accuracy: 0.7446 - 5s/epoch - 4ms/step\n",
      "Epoch 80/100\n",
      "1185/1185 - 5s - loss: 0.0191 - accuracy: 0.5326 - val_loss: 0.0122 - val_accuracy: 0.8689 - 5s/epoch - 4ms/step\n",
      "Epoch 81/100\n",
      "1185/1185 - 5s - loss: 0.0191 - accuracy: 0.5347 - val_loss: 0.0155 - val_accuracy: 0.6891 - 5s/epoch - 4ms/step\n",
      "Epoch 82/100\n",
      "1185/1185 - 5s - loss: 0.0190 - accuracy: 0.5378 - val_loss: 0.0120 - val_accuracy: 0.8635 - 5s/epoch - 4ms/step\n",
      "Epoch 83/100\n",
      "1185/1185 - 5s - loss: 0.0190 - accuracy: 0.5366 - val_loss: 0.0122 - val_accuracy: 0.8600 - 5s/epoch - 4ms/step\n",
      "Epoch 84/100\n",
      "1185/1185 - 5s - loss: 0.0189 - accuracy: 0.5420 - val_loss: 0.0127 - val_accuracy: 0.8219 - 5s/epoch - 4ms/step\n",
      "Epoch 85/100\n",
      "1185/1185 - 5s - loss: 0.0190 - accuracy: 0.5414 - val_loss: 0.0120 - val_accuracy: 0.8650 - 5s/epoch - 4ms/step\n",
      "Epoch 86/100\n",
      "1185/1185 - 5s - loss: 0.0189 - accuracy: 0.5379 - val_loss: 0.0147 - val_accuracy: 0.7216 - 5s/epoch - 4ms/step\n",
      "Epoch 87/100\n",
      "1185/1185 - 5s - loss: 0.0190 - accuracy: 0.5367 - val_loss: 0.0123 - val_accuracy: 0.8514 - 5s/epoch - 4ms/step\n",
      "Epoch 88/100\n",
      "1185/1185 - 5s - loss: 0.0188 - accuracy: 0.5411 - val_loss: 0.0128 - val_accuracy: 0.8172 - 5s/epoch - 4ms/step\n",
      "Epoch 89/100\n",
      "1185/1185 - 5s - loss: 0.0190 - accuracy: 0.5372 - val_loss: 0.0130 - val_accuracy: 0.8072 - 5s/epoch - 4ms/step\n",
      "Epoch 90/100\n",
      "1185/1185 - 5s - loss: 0.0189 - accuracy: 0.5443 - val_loss: 0.0132 - val_accuracy: 0.7905 - 5s/epoch - 4ms/step\n",
      "Epoch 91/100\n",
      "1185/1185 - 5s - loss: 0.0189 - accuracy: 0.5417 - val_loss: 0.0143 - val_accuracy: 0.7517 - 5s/epoch - 4ms/step\n",
      "Epoch 92/100\n",
      "1185/1185 - 5s - loss: 0.0188 - accuracy: 0.5490 - val_loss: 0.0144 - val_accuracy: 0.7214 - 5s/epoch - 4ms/step\n",
      "Epoch 93/100\n",
      "1185/1185 - 5s - loss: 0.0187 - accuracy: 0.5455 - val_loss: 0.0135 - val_accuracy: 0.7742 - 5s/epoch - 4ms/step\n",
      "Epoch 94/100\n",
      "1185/1185 - 5s - loss: 0.0189 - accuracy: 0.5417 - val_loss: 0.0196 - val_accuracy: 0.5154 - 5s/epoch - 4ms/step\n",
      "Epoch 95/100\n",
      "1185/1185 - 5s - loss: 0.0188 - accuracy: 0.5458 - val_loss: 0.0123 - val_accuracy: 0.8523 - 5s/epoch - 4ms/step\n",
      "Epoch 96/100\n",
      "1185/1185 - 5s - loss: 0.0189 - accuracy: 0.5444 - val_loss: 0.0123 - val_accuracy: 0.8443 - 5s/epoch - 4ms/step\n",
      "Epoch 97/100\n",
      "1185/1185 - 5s - loss: 0.0187 - accuracy: 0.5460 - val_loss: 0.0124 - val_accuracy: 0.8468 - 5s/epoch - 4ms/step\n",
      "Epoch 98/100\n",
      "1185/1185 - 5s - loss: 0.0188 - accuracy: 0.5439 - val_loss: 0.0125 - val_accuracy: 0.8453 - 5s/epoch - 4ms/step\n",
      "Epoch 99/100\n",
      "1185/1185 - 5s - loss: 0.0187 - accuracy: 0.5492 - val_loss: 0.0144 - val_accuracy: 0.7181 - 5s/epoch - 4ms/step\n",
      "Epoch 100/100\n",
      "1185/1185 - 5s - loss: 0.0188 - accuracy: 0.5462 - val_loss: 0.0125 - val_accuracy: 0.8369 - 5s/epoch - 4ms/step\n",
      "Restored model, train accuracy: 85.82%\n",
      "Restored model, valid accuracy: 83.69%\n",
      "Restored model, new_test accuracy: 83.48%\n",
      "Restored model, test accuracy: 65.63%\n"
     ]
    }
   ],
   "source": [
    "network = build_NeuralNetwork()\n",
    "print('Model built.')\n",
    "modelname = 'ann1'\n",
    "checkpointer = ModelCheckpoint(filepath = modelname+'.hdf5', verbose = 0, save_best_only = True)\n",
    "\n",
    "history = network.fit(train_images_array, train_hot_class,\n",
    "    batch_size = 32, #32\n",
    "    epochs = 100, #15\n",
    "    validation_data = (valid_images_array, valid_hot_class),\n",
    "    verbose = 2,\n",
    "    callbacks=[checkpointer],\n",
    "    shuffle = True)\n",
    "\n",
    "network.save('model_'+modelname+'.h5')\n",
    "\n",
    "train_loss, train_acc = network.evaluate(train_images_array, train_hot_class, verbose=0)\n",
    "print('Restored model, train accuracy: {:5.2f}%'.format(100 * train_acc))\n",
    "valid_loss, valid_acc = network.evaluate(valid_images_array, valid_hot_class, verbose=0)\n",
    "print('Restored model, valid accuracy: {:5.2f}%'.format(100 * valid_acc))\n",
    "new_test_loss, new_test_acc = network.evaluate(new_test_images_array, new_test_hot_class, verbose=0)\n",
    "print('Restored model, new_test accuracy: {:5.2f}%'.format(100 * new_test_acc))\n",
    "test_loss, test_acc = network.evaluate(test_images_array, test_hot_class, verbose=0)\n",
    "print('Restored model, test accuracy: {:5.2f}%'.format(100 * test_acc))\n",
    "np.save(modelname+'_history.npy',history.history)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "def build_NeuralNetwork():\n",
    "\n",
    "    #input layer\n",
    "    model = Sequential()\n",
    "    model.add(Input(shape=(100,100,3)))\n",
    "    model.add(Flatten())\n",
    "\n",
    "    #hiddenlayer 1\n",
    "    model.add(Dense(5))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation(activation='tanh'))\n",
    "\n",
    "    #hiddenlayer 2\n",
    "    model.add(Dense(50)) #900\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation(activation='tanh'))\n",
    "    model.add(Dropout(0.5))\n",
    "\n",
    "    #hiddenlayer 3\n",
    "    model.add(Dense(50)) #900\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation(activation='tanh'))\n",
    "    model.add(Dropout(0.5))\n",
    "\n",
    "    #hiddenlayer 4\n",
    "    #model.add(Dense(300)) #900\n",
    "    #model.add(BatchNormalization())\n",
    "    #model.add(Activation(activation='relu'))\n",
    "    #model.add(Dropout(0.25))\n",
    "\n",
    "    #output layer\n",
    "    model.add(Dense(131,activation=\"softmax\"))\n",
    "\n",
    "    model.compile(loss = 'poisson', optimizer = \"adam\", metrics = ['accuracy'])\n",
    "    print('Compiled!')\n",
    "\n",
    "    return model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compiled!\n",
      "Model built.\n",
      "Epoch 1/100\n",
      "1185/1185 - 12s - loss: 0.0359 - accuracy: 0.1136 - val_loss: 0.0291 - val_accuracy: 0.2467 - 12s/epoch - 10ms/step\n",
      "Epoch 2/100\n",
      "1185/1185 - 6s - loss: 0.0272 - accuracy: 0.2859 - val_loss: 0.0220 - val_accuracy: 0.5407 - 6s/epoch - 5ms/step\n",
      "Epoch 3/100\n",
      "1185/1185 - 6s - loss: 0.0238 - accuracy: 0.3843 - val_loss: 0.0208 - val_accuracy: 0.5089 - 6s/epoch - 5ms/step\n",
      "Epoch 4/100\n",
      "1185/1185 - 5s - loss: 0.0222 - accuracy: 0.4288 - val_loss: 0.0165 - val_accuracy: 0.7183 - 5s/epoch - 5ms/step\n",
      "Epoch 5/100\n",
      "1185/1185 - 5s - loss: 0.0212 - accuracy: 0.4610 - val_loss: 0.0162 - val_accuracy: 0.7073 - 5s/epoch - 5ms/step\n",
      "Epoch 6/100\n",
      "1185/1185 - 5s - loss: 0.0208 - accuracy: 0.4730 - val_loss: 0.0198 - val_accuracy: 0.5202 - 5s/epoch - 4ms/step\n",
      "Epoch 7/100\n",
      "1185/1185 - 5s - loss: 0.0202 - accuracy: 0.4923 - val_loss: 0.0140 - val_accuracy: 0.8143 - 5s/epoch - 5ms/step\n",
      "Epoch 8/100\n",
      "1185/1185 - 5s - loss: 0.0198 - accuracy: 0.5104 - val_loss: 0.0167 - val_accuracy: 0.6379 - 5s/epoch - 5ms/step\n",
      "Epoch 9/100\n",
      "1185/1185 - 5s - loss: 0.0195 - accuracy: 0.5176 - val_loss: 0.0168 - val_accuracy: 0.6169 - 5s/epoch - 5ms/step\n",
      "Epoch 10/100\n",
      "1185/1185 - 6s - loss: 0.0193 - accuracy: 0.5231 - val_loss: 0.0158 - val_accuracy: 0.6612 - 6s/epoch - 5ms/step\n",
      "Epoch 11/100\n",
      "1185/1185 - 6s - loss: 0.0191 - accuracy: 0.5311 - val_loss: 0.0134 - val_accuracy: 0.8099 - 6s/epoch - 5ms/step\n",
      "Epoch 12/100\n",
      "1185/1185 - 6s - loss: 0.0189 - accuracy: 0.5343 - val_loss: 0.0154 - val_accuracy: 0.6909 - 6s/epoch - 5ms/step\n",
      "Epoch 13/100\n",
      "1185/1185 - 6s - loss: 0.0187 - accuracy: 0.5429 - val_loss: 0.0132 - val_accuracy: 0.8000 - 6s/epoch - 5ms/step\n",
      "Epoch 14/100\n",
      "1185/1185 - 5s - loss: 0.0186 - accuracy: 0.5490 - val_loss: 0.0155 - val_accuracy: 0.6603 - 5s/epoch - 4ms/step\n",
      "Epoch 15/100\n",
      "1185/1185 - 5s - loss: 0.0183 - accuracy: 0.5599 - val_loss: 0.0137 - val_accuracy: 0.7767 - 5s/epoch - 4ms/step\n",
      "Epoch 16/100\n",
      "1185/1185 - 5s - loss: 0.0183 - accuracy: 0.5586 - val_loss: 0.0155 - val_accuracy: 0.6691 - 5s/epoch - 4ms/step\n",
      "Epoch 17/100\n",
      "1185/1185 - 5s - loss: 0.0182 - accuracy: 0.5632 - val_loss: 0.0123 - val_accuracy: 0.8470 - 5s/epoch - 5ms/step\n",
      "Epoch 18/100\n",
      "1185/1185 - 5s - loss: 0.0180 - accuracy: 0.5711 - val_loss: 0.0123 - val_accuracy: 0.8409 - 5s/epoch - 5ms/step\n",
      "Epoch 19/100\n",
      "1185/1185 - 5s - loss: 0.0181 - accuracy: 0.5684 - val_loss: 0.0151 - val_accuracy: 0.6987 - 5s/epoch - 5ms/step\n",
      "Epoch 20/100\n",
      "1185/1185 - 5s - loss: 0.0179 - accuracy: 0.5770 - val_loss: 0.0141 - val_accuracy: 0.7307 - 5s/epoch - 4ms/step\n",
      "Epoch 21/100\n",
      "1185/1185 - 5s - loss: 0.0178 - accuracy: 0.5791 - val_loss: 0.0152 - val_accuracy: 0.6651 - 5s/epoch - 4ms/step\n",
      "Epoch 22/100\n",
      "1185/1185 - 5s - loss: 0.0177 - accuracy: 0.5791 - val_loss: 0.0123 - val_accuracy: 0.8328 - 5s/epoch - 4ms/step\n",
      "Epoch 23/100\n",
      "1185/1185 - 5s - loss: 0.0176 - accuracy: 0.5852 - val_loss: 0.0147 - val_accuracy: 0.6856 - 5s/epoch - 4ms/step\n",
      "Epoch 24/100\n",
      "1185/1185 - 5s - loss: 0.0176 - accuracy: 0.5852 - val_loss: 0.0161 - val_accuracy: 0.6320 - 5s/epoch - 4ms/step\n",
      "Epoch 25/100\n",
      "1185/1185 - 5s - loss: 0.0176 - accuracy: 0.5884 - val_loss: 0.0158 - val_accuracy: 0.6510 - 5s/epoch - 4ms/step\n",
      "Epoch 26/100\n",
      "1185/1185 - 5s - loss: 0.0174 - accuracy: 0.5931 - val_loss: 0.0187 - val_accuracy: 0.5371 - 5s/epoch - 4ms/step\n",
      "Epoch 27/100\n",
      "1185/1185 - 5s - loss: 0.0175 - accuracy: 0.5906 - val_loss: 0.0140 - val_accuracy: 0.7341 - 5s/epoch - 4ms/step\n",
      "Epoch 28/100\n",
      "1185/1185 - 5s - loss: 0.0173 - accuracy: 0.5930 - val_loss: 0.0127 - val_accuracy: 0.8112 - 5s/epoch - 4ms/step\n",
      "Epoch 29/100\n",
      "1185/1185 - 5s - loss: 0.0173 - accuracy: 0.5974 - val_loss: 0.0158 - val_accuracy: 0.6815 - 5s/epoch - 4ms/step\n",
      "Epoch 30/100\n",
      "1185/1185 - 5s - loss: 0.0173 - accuracy: 0.5967 - val_loss: 0.0118 - val_accuracy: 0.8583 - 5s/epoch - 4ms/step\n",
      "Epoch 31/100\n",
      "1185/1185 - 5s - loss: 0.0172 - accuracy: 0.6021 - val_loss: 0.0117 - val_accuracy: 0.8651 - 5s/epoch - 4ms/step\n",
      "Epoch 32/100\n",
      "1185/1185 - 5s - loss: 0.0172 - accuracy: 0.6004 - val_loss: 0.0131 - val_accuracy: 0.7791 - 5s/epoch - 4ms/step\n",
      "Epoch 33/100\n",
      "1185/1185 - 5s - loss: 0.0171 - accuracy: 0.6052 - val_loss: 0.0133 - val_accuracy: 0.7722 - 5s/epoch - 4ms/step\n",
      "Epoch 34/100\n",
      "1185/1185 - 5s - loss: 0.0170 - accuracy: 0.6098 - val_loss: 0.0120 - val_accuracy: 0.8447 - 5s/epoch - 4ms/step\n",
      "Epoch 35/100\n",
      "1185/1185 - 5s - loss: 0.0171 - accuracy: 0.6065 - val_loss: 0.0172 - val_accuracy: 0.6044 - 5s/epoch - 4ms/step\n",
      "Epoch 36/100\n",
      "1185/1185 - 5s - loss: 0.0170 - accuracy: 0.6090 - val_loss: 0.0158 - val_accuracy: 0.6133 - 5s/epoch - 4ms/step\n",
      "Epoch 37/100\n",
      "1185/1185 - 5s - loss: 0.0170 - accuracy: 0.6071 - val_loss: 0.0157 - val_accuracy: 0.6531 - 5s/epoch - 4ms/step\n",
      "Epoch 38/100\n",
      "1185/1185 - 5s - loss: 0.0169 - accuracy: 0.6117 - val_loss: 0.0169 - val_accuracy: 0.6189 - 5s/epoch - 5ms/step\n",
      "Epoch 39/100\n",
      "1185/1185 - 5s - loss: 0.0168 - accuracy: 0.6166 - val_loss: 0.0125 - val_accuracy: 0.8127 - 5s/epoch - 4ms/step\n",
      "Epoch 40/100\n",
      "1185/1185 - 5s - loss: 0.0167 - accuracy: 0.6170 - val_loss: 0.0134 - val_accuracy: 0.7461 - 5s/epoch - 4ms/step\n",
      "Epoch 41/100\n",
      "1185/1185 - 5s - loss: 0.0168 - accuracy: 0.6163 - val_loss: 0.0146 - val_accuracy: 0.7175 - 5s/epoch - 4ms/step\n",
      "Epoch 42/100\n",
      "1185/1185 - 5s - loss: 0.0168 - accuracy: 0.6176 - val_loss: 0.0138 - val_accuracy: 0.7400 - 5s/epoch - 4ms/step\n",
      "Epoch 43/100\n",
      "1185/1185 - 5s - loss: 0.0167 - accuracy: 0.6210 - val_loss: 0.0127 - val_accuracy: 0.7956 - 5s/epoch - 4ms/step\n",
      "Epoch 44/100\n",
      "1185/1185 - 5s - loss: 0.0167 - accuracy: 0.6220 - val_loss: 0.0120 - val_accuracy: 0.8353 - 5s/epoch - 4ms/step\n",
      "Epoch 45/100\n",
      "1185/1185 - 5s - loss: 0.0168 - accuracy: 0.6185 - val_loss: 0.0117 - val_accuracy: 0.8544 - 5s/epoch - 4ms/step\n",
      "Epoch 46/100\n",
      "1185/1185 - 5s - loss: 0.0166 - accuracy: 0.6233 - val_loss: 0.0124 - val_accuracy: 0.8153 - 5s/epoch - 4ms/step\n",
      "Epoch 47/100\n",
      "1185/1185 - 5s - loss: 0.0167 - accuracy: 0.6196 - val_loss: 0.0134 - val_accuracy: 0.7548 - 5s/epoch - 4ms/step\n",
      "Epoch 48/100\n",
      "1185/1185 - 5s - loss: 0.0166 - accuracy: 0.6238 - val_loss: 0.0178 - val_accuracy: 0.5759 - 5s/epoch - 4ms/step\n",
      "Epoch 49/100\n",
      "1185/1185 - 5s - loss: 0.0166 - accuracy: 0.6251 - val_loss: 0.0122 - val_accuracy: 0.8204 - 5s/epoch - 4ms/step\n",
      "Epoch 50/100\n",
      "1185/1185 - 5s - loss: 0.0165 - accuracy: 0.6302 - val_loss: 0.0167 - val_accuracy: 0.6352 - 5s/epoch - 4ms/step\n",
      "Epoch 51/100\n",
      "1185/1185 - 5s - loss: 0.0166 - accuracy: 0.6276 - val_loss: 0.0155 - val_accuracy: 0.6715 - 5s/epoch - 5ms/step\n",
      "Epoch 52/100\n",
      "1185/1185 - 5s - loss: 0.0165 - accuracy: 0.6286 - val_loss: 0.0120 - val_accuracy: 0.8330 - 5s/epoch - 4ms/step\n",
      "Epoch 53/100\n",
      "1185/1185 - 5s - loss: 0.0165 - accuracy: 0.6302 - val_loss: 0.0136 - val_accuracy: 0.7423 - 5s/epoch - 4ms/step\n",
      "Epoch 54/100\n",
      "1185/1185 - 5s - loss: 0.0163 - accuracy: 0.6378 - val_loss: 0.0113 - val_accuracy: 0.8626 - 5s/epoch - 4ms/step\n",
      "Epoch 55/100\n",
      "1185/1185 - 5s - loss: 0.0163 - accuracy: 0.6359 - val_loss: 0.0113 - val_accuracy: 0.8676 - 5s/epoch - 5ms/step\n",
      "Epoch 56/100\n",
      "1185/1185 - 6s - loss: 0.0164 - accuracy: 0.6315 - val_loss: 0.0112 - val_accuracy: 0.8784 - 6s/epoch - 5ms/step\n",
      "Epoch 57/100\n",
      "1185/1185 - 5s - loss: 0.0163 - accuracy: 0.6377 - val_loss: 0.0123 - val_accuracy: 0.8120 - 5s/epoch - 4ms/step\n",
      "Epoch 58/100\n",
      "1185/1185 - 5s - loss: 0.0163 - accuracy: 0.6354 - val_loss: 0.0187 - val_accuracy: 0.5197 - 5s/epoch - 4ms/step\n",
      "Epoch 59/100\n",
      "1185/1185 - 5s - loss: 0.0163 - accuracy: 0.6395 - val_loss: 0.0125 - val_accuracy: 0.8101 - 5s/epoch - 4ms/step\n",
      "Epoch 60/100\n",
      "1185/1185 - 5s - loss: 0.0161 - accuracy: 0.6426 - val_loss: 0.0158 - val_accuracy: 0.6381 - 5s/epoch - 4ms/step\n",
      "Epoch 61/100\n",
      "1185/1185 - 5s - loss: 0.0162 - accuracy: 0.6440 - val_loss: 0.0120 - val_accuracy: 0.8367 - 5s/epoch - 4ms/step\n",
      "Epoch 62/100\n",
      "1185/1185 - 5s - loss: 0.0161 - accuracy: 0.6415 - val_loss: 0.0156 - val_accuracy: 0.6597 - 5s/epoch - 4ms/step\n",
      "Epoch 63/100\n",
      "1185/1185 - 5s - loss: 0.0161 - accuracy: 0.6430 - val_loss: 0.0118 - val_accuracy: 0.8484 - 5s/epoch - 4ms/step\n",
      "Epoch 64/100\n",
      "1185/1185 - 5s - loss: 0.0162 - accuracy: 0.6378 - val_loss: 0.0139 - val_accuracy: 0.7441 - 5s/epoch - 4ms/step\n",
      "Epoch 65/100\n",
      "1185/1185 - 5s - loss: 0.0162 - accuracy: 0.6377 - val_loss: 0.0145 - val_accuracy: 0.6964 - 5s/epoch - 4ms/step\n",
      "Epoch 66/100\n",
      "1185/1185 - 5s - loss: 0.0161 - accuracy: 0.6425 - val_loss: 0.0144 - val_accuracy: 0.7239 - 5s/epoch - 4ms/step\n",
      "Epoch 67/100\n",
      "1185/1185 - 5s - loss: 0.0162 - accuracy: 0.6401 - val_loss: 0.0117 - val_accuracy: 0.8473 - 5s/epoch - 4ms/step\n",
      "Epoch 68/100\n",
      "1185/1185 - 5s - loss: 0.0160 - accuracy: 0.6462 - val_loss: 0.0165 - val_accuracy: 0.5928 - 5s/epoch - 4ms/step\n",
      "Epoch 69/100\n",
      "1185/1185 - 5s - loss: 0.0161 - accuracy: 0.6421 - val_loss: 0.0138 - val_accuracy: 0.7243 - 5s/epoch - 4ms/step\n",
      "Epoch 70/100\n",
      "1185/1185 - 5s - loss: 0.0161 - accuracy: 0.6445 - val_loss: 0.0161 - val_accuracy: 0.6405 - 5s/epoch - 4ms/step\n",
      "Epoch 71/100\n",
      "1185/1185 - 5s - loss: 0.0160 - accuracy: 0.6511 - val_loss: 0.0150 - val_accuracy: 0.6817 - 5s/epoch - 4ms/step\n",
      "Epoch 72/100\n",
      "1185/1185 - 5s - loss: 0.0162 - accuracy: 0.6400 - val_loss: 0.0135 - val_accuracy: 0.7446 - 5s/epoch - 4ms/step\n",
      "Epoch 73/100\n",
      "1185/1185 - 5s - loss: 0.0160 - accuracy: 0.6434 - val_loss: 0.0165 - val_accuracy: 0.6492 - 5s/epoch - 4ms/step\n",
      "Epoch 74/100\n",
      "1185/1185 - 5s - loss: 0.0160 - accuracy: 0.6483 - val_loss: 0.0119 - val_accuracy: 0.8277 - 5s/epoch - 4ms/step\n",
      "Epoch 75/100\n",
      "1185/1185 - 5s - loss: 0.0160 - accuracy: 0.6498 - val_loss: 0.0119 - val_accuracy: 0.8339 - 5s/epoch - 4ms/step\n",
      "Epoch 76/100\n",
      "1185/1185 - 5s - loss: 0.0158 - accuracy: 0.6577 - val_loss: 0.0145 - val_accuracy: 0.6903 - 5s/epoch - 4ms/step\n",
      "Epoch 77/100\n",
      "1185/1185 - 5s - loss: 0.0158 - accuracy: 0.6541 - val_loss: 0.0123 - val_accuracy: 0.8168 - 5s/epoch - 4ms/step\n",
      "Epoch 78/100\n",
      "1185/1185 - 5s - loss: 0.0160 - accuracy: 0.6495 - val_loss: 0.0113 - val_accuracy: 0.8660 - 5s/epoch - 4ms/step\n",
      "Epoch 79/100\n",
      "1185/1185 - 5s - loss: 0.0159 - accuracy: 0.6531 - val_loss: 0.0122 - val_accuracy: 0.8101 - 5s/epoch - 4ms/step\n",
      "Epoch 80/100\n",
      "1185/1185 - 5s - loss: 0.0159 - accuracy: 0.6497 - val_loss: 0.0122 - val_accuracy: 0.8151 - 5s/epoch - 4ms/step\n",
      "Epoch 81/100\n",
      "1185/1185 - 5s - loss: 0.0157 - accuracy: 0.6559 - val_loss: 0.0122 - val_accuracy: 0.8151 - 5s/epoch - 4ms/step\n",
      "Epoch 82/100\n",
      "1185/1185 - 5s - loss: 0.0158 - accuracy: 0.6570 - val_loss: 0.0154 - val_accuracy: 0.6866 - 5s/epoch - 4ms/step\n",
      "Epoch 83/100\n",
      "1185/1185 - 5s - loss: 0.0158 - accuracy: 0.6556 - val_loss: 0.0129 - val_accuracy: 0.7748 - 5s/epoch - 4ms/step\n",
      "Epoch 84/100\n",
      "1185/1185 - 5s - loss: 0.0158 - accuracy: 0.6537 - val_loss: 0.0134 - val_accuracy: 0.7566 - 5s/epoch - 4ms/step\n",
      "Epoch 85/100\n",
      "1185/1185 - 7s - loss: 0.0158 - accuracy: 0.6571 - val_loss: 0.0141 - val_accuracy: 0.6984 - 7s/epoch - 6ms/step\n",
      "Epoch 86/100\n",
      "1185/1185 - 5s - loss: 0.0157 - accuracy: 0.6606 - val_loss: 0.0124 - val_accuracy: 0.8113 - 5s/epoch - 5ms/step\n",
      "Epoch 87/100\n",
      "1185/1185 - 5s - loss: 0.0156 - accuracy: 0.6592 - val_loss: 0.0194 - val_accuracy: 0.5157 - 5s/epoch - 4ms/step\n",
      "Epoch 88/100\n",
      "1185/1185 - 6s - loss: 0.0158 - accuracy: 0.6578 - val_loss: 0.0131 - val_accuracy: 0.7881 - 6s/epoch - 5ms/step\n",
      "Epoch 89/100\n",
      "1185/1185 - 6s - loss: 0.0158 - accuracy: 0.6572 - val_loss: 0.0150 - val_accuracy: 0.6768 - 6s/epoch - 5ms/step\n",
      "Epoch 90/100\n",
      "1185/1185 - 5s - loss: 0.0157 - accuracy: 0.6602 - val_loss: 0.0140 - val_accuracy: 0.7261 - 5s/epoch - 5ms/step\n",
      "Epoch 91/100\n",
      "1185/1185 - 5s - loss: 0.0156 - accuracy: 0.6624 - val_loss: 0.0126 - val_accuracy: 0.8039 - 5s/epoch - 5ms/step\n",
      "Epoch 92/100\n",
      "1185/1185 - 6s - loss: 0.0157 - accuracy: 0.6610 - val_loss: 0.0108 - val_accuracy: 0.8906 - 6s/epoch - 5ms/step\n",
      "Epoch 93/100\n",
      "1185/1185 - 5s - loss: 0.0157 - accuracy: 0.6617 - val_loss: 0.0138 - val_accuracy: 0.7357 - 5s/epoch - 4ms/step\n",
      "Epoch 94/100\n",
      "1185/1185 - 5s - loss: 0.0155 - accuracy: 0.6654 - val_loss: 0.0118 - val_accuracy: 0.8313 - 5s/epoch - 4ms/step\n",
      "Epoch 95/100\n",
      "1185/1185 - 5s - loss: 0.0156 - accuracy: 0.6657 - val_loss: 0.0113 - val_accuracy: 0.8611 - 5s/epoch - 4ms/step\n",
      "Epoch 96/100\n",
      "1185/1185 - 5s - loss: 0.0155 - accuracy: 0.6682 - val_loss: 0.0138 - val_accuracy: 0.7517 - 5s/epoch - 4ms/step\n",
      "Epoch 97/100\n",
      "1185/1185 - 5s - loss: 0.0157 - accuracy: 0.6614 - val_loss: 0.0128 - val_accuracy: 0.7975 - 5s/epoch - 4ms/step\n",
      "Epoch 98/100\n",
      "1185/1185 - 5s - loss: 0.0156 - accuracy: 0.6619 - val_loss: 0.0129 - val_accuracy: 0.7702 - 5s/epoch - 4ms/step\n",
      "Epoch 99/100\n",
      "1185/1185 - 5s - loss: 0.0156 - accuracy: 0.6676 - val_loss: 0.0166 - val_accuracy: 0.6374 - 5s/epoch - 4ms/step\n",
      "Epoch 100/100\n",
      "1185/1185 - 5s - loss: 0.0156 - accuracy: 0.6618 - val_loss: 0.0124 - val_accuracy: 0.8102 - 5s/epoch - 4ms/step\n",
      "Restored model, train accuracy: 85.24%\n",
      "Restored model, valid accuracy: 81.02%\n",
      "Restored model, new_test accuracy: 80.38%\n",
      "Restored model, test accuracy: 61.42%\n"
     ]
    }
   ],
   "source": [
    "network = build_NeuralNetwork()\n",
    "print('Model built.')\n",
    "modelname = 'ann1'\n",
    "checkpointer = ModelCheckpoint(filepath = modelname+'.hdf5', verbose = 0, save_best_only = True)\n",
    "\n",
    "history = network.fit(train_images_array, train_hot_class,\n",
    "    batch_size = 32, #32\n",
    "    epochs = 100, #15\n",
    "    validation_data = (valid_images_array, valid_hot_class),\n",
    "    verbose = 2,\n",
    "    callbacks=[checkpointer],\n",
    "    shuffle = True)\n",
    "\n",
    "network.save('model_'+modelname+'.h5')\n",
    "\n",
    "train_loss, train_acc = network.evaluate(train_images_array, train_hot_class, verbose=0)\n",
    "print('Restored model, train accuracy: {:5.2f}%'.format(100 * train_acc))\n",
    "valid_loss, valid_acc = network.evaluate(valid_images_array, valid_hot_class, verbose=0)\n",
    "print('Restored model, valid accuracy: {:5.2f}%'.format(100 * valid_acc))\n",
    "new_test_loss, new_test_acc = network.evaluate(new_test_images_array, new_test_hot_class, verbose=0)\n",
    "print('Restored model, new_test accuracy: {:5.2f}%'.format(100 * new_test_acc))\n",
    "test_loss, test_acc = network.evaluate(test_images_array, test_hot_class, verbose=0)\n",
    "print('Restored model, test accuracy: {:5.2f}%'.format(100 * test_acc))\n",
    "np.save(modelname+'_history.npy',history.history)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "def build_NeuralNetwork():\n",
    "\n",
    "    #input layer\n",
    "    model = Sequential()\n",
    "    model.add(Input(shape=(100,100,3)))\n",
    "    model.add(Flatten())\n",
    "\n",
    "    #hiddenlayer 1\n",
    "    model.add(Dense(5))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation(activation='sigmoid'))\n",
    "\n",
    "    #hiddenlayer 2\n",
    "    model.add(Dense(50)) #900\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation(activation='sigmoid'))\n",
    "    model.add(Dropout(0.5))\n",
    "\n",
    "    #hiddenlayer 3\n",
    "    model.add(Dense(50)) #900\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation(activation='sigmoid'))\n",
    "    model.add(Dropout(0.5))\n",
    "\n",
    "    #hiddenlayer 4\n",
    "    #model.add(Dense(300)) #900\n",
    "    #model.add(BatchNormalization())\n",
    "    #model.add(Activation(activation='relu'))\n",
    "    #model.add(Dropout(0.25))\n",
    "\n",
    "    #output layer\n",
    "    model.add(Dense(131,activation=\"softmax\"))\n",
    "\n",
    "    model.compile(loss = 'poisson', optimizer = \"adam\", metrics = ['accuracy'])\n",
    "    print('Compiled!')\n",
    "\n",
    "    return model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compiled!\n",
      "Model built.\n",
      "Epoch 1/100\n",
      "1185/1185 - 8s - loss: 0.0428 - accuracy: 0.0337 - val_loss: 0.0379 - val_accuracy: 0.1030 - 8s/epoch - 7ms/step\n",
      "Epoch 2/100\n",
      "1185/1185 - 5s - loss: 0.0364 - accuracy: 0.0967 - val_loss: 0.0309 - val_accuracy: 0.2861 - 5s/epoch - 5ms/step\n",
      "Epoch 3/100\n",
      "1185/1185 - 5s - loss: 0.0322 - accuracy: 0.1498 - val_loss: 0.0266 - val_accuracy: 0.4181 - 5s/epoch - 4ms/step\n",
      "Epoch 4/100\n",
      "1185/1185 - 5s - loss: 0.0297 - accuracy: 0.1975 - val_loss: 0.0250 - val_accuracy: 0.4219 - 5s/epoch - 4ms/step\n",
      "Epoch 5/100\n",
      "1185/1185 - 5s - loss: 0.0282 - accuracy: 0.2247 - val_loss: 0.0235 - val_accuracy: 0.4402 - 5s/epoch - 5ms/step\n",
      "Epoch 6/100\n",
      "1185/1185 - 5s - loss: 0.0271 - accuracy: 0.2487 - val_loss: 0.0214 - val_accuracy: 0.5558 - 5s/epoch - 5ms/step\n",
      "Epoch 7/100\n",
      "1185/1185 - 6s - loss: 0.0263 - accuracy: 0.2716 - val_loss: 0.0207 - val_accuracy: 0.6028 - 6s/epoch - 5ms/step\n",
      "Epoch 8/100\n",
      "1185/1185 - 5s - loss: 0.0257 - accuracy: 0.2891 - val_loss: 0.0200 - val_accuracy: 0.5842 - 5s/epoch - 5ms/step\n",
      "Epoch 9/100\n",
      "1185/1185 - 5s - loss: 0.0252 - accuracy: 0.3080 - val_loss: 0.0195 - val_accuracy: 0.6041 - 5s/epoch - 5ms/step\n",
      "Epoch 10/100\n",
      "1185/1185 - 5s - loss: 0.0247 - accuracy: 0.3203 - val_loss: 0.0189 - val_accuracy: 0.6105 - 5s/epoch - 5ms/step\n",
      "Epoch 11/100\n",
      "1185/1185 - 5s - loss: 0.0244 - accuracy: 0.3328 - val_loss: 0.0187 - val_accuracy: 0.6085 - 5s/epoch - 5ms/step\n",
      "Epoch 12/100\n",
      "1185/1185 - 5s - loss: 0.0239 - accuracy: 0.3480 - val_loss: 0.0188 - val_accuracy: 0.5926 - 5s/epoch - 4ms/step\n",
      "Epoch 13/100\n",
      "1185/1185 - 5s - loss: 0.0237 - accuracy: 0.3557 - val_loss: 0.0177 - val_accuracy: 0.6437 - 5s/epoch - 4ms/step\n",
      "Epoch 14/100\n",
      "1185/1185 - 5s - loss: 0.0235 - accuracy: 0.3601 - val_loss: 0.0173 - val_accuracy: 0.7125 - 5s/epoch - 4ms/step\n",
      "Epoch 15/100\n",
      "1185/1185 - 5s - loss: 0.0232 - accuracy: 0.3704 - val_loss: 0.0176 - val_accuracy: 0.6685 - 5s/epoch - 4ms/step\n",
      "Epoch 16/100\n",
      "1185/1185 - 5s - loss: 0.0230 - accuracy: 0.3846 - val_loss: 0.0161 - val_accuracy: 0.7640 - 5s/epoch - 4ms/step\n",
      "Epoch 17/100\n",
      "1185/1185 - 5s - loss: 0.0228 - accuracy: 0.3881 - val_loss: 0.0191 - val_accuracy: 0.4926 - 5s/epoch - 4ms/step\n",
      "Epoch 18/100\n",
      "1185/1185 - 5s - loss: 0.0225 - accuracy: 0.4031 - val_loss: 0.0169 - val_accuracy: 0.6803 - 5s/epoch - 4ms/step\n",
      "Epoch 19/100\n",
      "1185/1185 - 5s - loss: 0.0224 - accuracy: 0.4064 - val_loss: 0.0155 - val_accuracy: 0.7675 - 5s/epoch - 4ms/step\n",
      "Epoch 20/100\n",
      "1185/1185 - 5s - loss: 0.0223 - accuracy: 0.4077 - val_loss: 0.0164 - val_accuracy: 0.7016 - 5s/epoch - 4ms/step\n",
      "Epoch 21/100\n",
      "1185/1185 - 5s - loss: 0.0221 - accuracy: 0.4160 - val_loss: 0.0154 - val_accuracy: 0.7748 - 5s/epoch - 4ms/step\n",
      "Epoch 22/100\n",
      "1185/1185 - 5s - loss: 0.0218 - accuracy: 0.4302 - val_loss: 0.0159 - val_accuracy: 0.7282 - 5s/epoch - 4ms/step\n",
      "Epoch 23/100\n",
      "1185/1185 - 5s - loss: 0.0218 - accuracy: 0.4273 - val_loss: 0.0150 - val_accuracy: 0.7847 - 5s/epoch - 4ms/step\n",
      "Epoch 24/100\n",
      "1185/1185 - 5s - loss: 0.0215 - accuracy: 0.4367 - val_loss: 0.0161 - val_accuracy: 0.6890 - 5s/epoch - 4ms/step\n",
      "Epoch 25/100\n",
      "1185/1185 - 5s - loss: 0.0214 - accuracy: 0.4423 - val_loss: 0.0170 - val_accuracy: 0.6293 - 5s/epoch - 4ms/step\n",
      "Epoch 26/100\n",
      "1185/1185 - 5s - loss: 0.0214 - accuracy: 0.4487 - val_loss: 0.0152 - val_accuracy: 0.7496 - 5s/epoch - 4ms/step\n",
      "Epoch 27/100\n",
      "1185/1185 - 6s - loss: 0.0212 - accuracy: 0.4514 - val_loss: 0.0141 - val_accuracy: 0.8194 - 6s/epoch - 5ms/step\n",
      "Epoch 28/100\n",
      "1185/1185 - 5s - loss: 0.0212 - accuracy: 0.4528 - val_loss: 0.0153 - val_accuracy: 0.7461 - 5s/epoch - 4ms/step\n",
      "Epoch 29/100\n",
      "1185/1185 - 5s - loss: 0.0211 - accuracy: 0.4552 - val_loss: 0.0159 - val_accuracy: 0.6841 - 5s/epoch - 4ms/step\n",
      "Epoch 30/100\n",
      "1185/1185 - 5s - loss: 0.0210 - accuracy: 0.4580 - val_loss: 0.0142 - val_accuracy: 0.8083 - 5s/epoch - 4ms/step\n",
      "Epoch 31/100\n",
      "1185/1185 - 5s - loss: 0.0208 - accuracy: 0.4637 - val_loss: 0.0150 - val_accuracy: 0.7451 - 5s/epoch - 4ms/step\n",
      "Epoch 32/100\n",
      "1185/1185 - 5s - loss: 0.0208 - accuracy: 0.4703 - val_loss: 0.0162 - val_accuracy: 0.6525 - 5s/epoch - 4ms/step\n",
      "Epoch 33/100\n",
      "1185/1185 - 5s - loss: 0.0206 - accuracy: 0.4781 - val_loss: 0.0137 - val_accuracy: 0.8411 - 5s/epoch - 4ms/step\n",
      "Epoch 34/100\n",
      "1185/1185 - 5s - loss: 0.0205 - accuracy: 0.4801 - val_loss: 0.0149 - val_accuracy: 0.7334 - 5s/epoch - 4ms/step\n",
      "Epoch 35/100\n",
      "1185/1185 - 5s - loss: 0.0205 - accuracy: 0.4810 - val_loss: 0.0155 - val_accuracy: 0.7029 - 5s/epoch - 4ms/step\n",
      "Epoch 36/100\n",
      "1185/1185 - 5s - loss: 0.0203 - accuracy: 0.4866 - val_loss: 0.0157 - val_accuracy: 0.7059 - 5s/epoch - 4ms/step\n",
      "Epoch 37/100\n",
      "1185/1185 - 5s - loss: 0.0203 - accuracy: 0.4821 - val_loss: 0.0154 - val_accuracy: 0.7196 - 5s/epoch - 4ms/step\n",
      "Epoch 38/100\n",
      "1185/1185 - 5s - loss: 0.0202 - accuracy: 0.4893 - val_loss: 0.0136 - val_accuracy: 0.8057 - 5s/epoch - 4ms/step\n",
      "Epoch 39/100\n",
      "1185/1185 - 5s - loss: 0.0201 - accuracy: 0.4942 - val_loss: 0.0137 - val_accuracy: 0.8017 - 5s/epoch - 4ms/step\n",
      "Epoch 40/100\n",
      "1185/1185 - 5s - loss: 0.0202 - accuracy: 0.4927 - val_loss: 0.0131 - val_accuracy: 0.8551 - 5s/epoch - 4ms/step\n",
      "Epoch 41/100\n",
      "1185/1185 - 5s - loss: 0.0201 - accuracy: 0.4937 - val_loss: 0.0129 - val_accuracy: 0.8523 - 5s/epoch - 4ms/step\n",
      "Epoch 42/100\n",
      "1185/1185 - 5s - loss: 0.0200 - accuracy: 0.4984 - val_loss: 0.0145 - val_accuracy: 0.7631 - 5s/epoch - 4ms/step\n",
      "Epoch 43/100\n",
      "1185/1185 - 5s - loss: 0.0199 - accuracy: 0.5030 - val_loss: 0.0149 - val_accuracy: 0.7106 - 5s/epoch - 4ms/step\n",
      "Epoch 44/100\n",
      "1185/1185 - 5s - loss: 0.0198 - accuracy: 0.5091 - val_loss: 0.0134 - val_accuracy: 0.8223 - 5s/epoch - 4ms/step\n",
      "Epoch 45/100\n",
      "1185/1185 - 5s - loss: 0.0198 - accuracy: 0.5021 - val_loss: 0.0128 - val_accuracy: 0.8578 - 5s/epoch - 4ms/step\n",
      "Epoch 46/100\n",
      "1185/1185 - 6s - loss: 0.0198 - accuracy: 0.5078 - val_loss: 0.0134 - val_accuracy: 0.8302 - 6s/epoch - 5ms/step\n",
      "Epoch 47/100\n",
      "1185/1185 - 5s - loss: 0.0198 - accuracy: 0.5082 - val_loss: 0.0141 - val_accuracy: 0.7695 - 5s/epoch - 5ms/step\n",
      "Epoch 48/100\n",
      "1185/1185 - 5s - loss: 0.0197 - accuracy: 0.5119 - val_loss: 0.0137 - val_accuracy: 0.8094 - 5s/epoch - 5ms/step\n",
      "Epoch 49/100\n",
      "1185/1185 - 5s - loss: 0.0196 - accuracy: 0.5113 - val_loss: 0.0142 - val_accuracy: 0.7676 - 5s/epoch - 5ms/step\n",
      "Epoch 50/100\n",
      "1185/1185 - 5s - loss: 0.0196 - accuracy: 0.5149 - val_loss: 0.0142 - val_accuracy: 0.7681 - 5s/epoch - 5ms/step\n",
      "Epoch 51/100\n",
      "1185/1185 - 5s - loss: 0.0196 - accuracy: 0.5186 - val_loss: 0.0139 - val_accuracy: 0.7988 - 5s/epoch - 4ms/step\n",
      "Epoch 52/100\n",
      "1185/1185 - 5s - loss: 0.0195 - accuracy: 0.5162 - val_loss: 0.0131 - val_accuracy: 0.8307 - 5s/epoch - 4ms/step\n",
      "Epoch 53/100\n",
      "1185/1185 - 5s - loss: 0.0194 - accuracy: 0.5254 - val_loss: 0.0143 - val_accuracy: 0.7516 - 5s/epoch - 4ms/step\n",
      "Epoch 54/100\n",
      "1185/1185 - 5s - loss: 0.0193 - accuracy: 0.5227 - val_loss: 0.0140 - val_accuracy: 0.7802 - 5s/epoch - 4ms/step\n",
      "Epoch 55/100\n",
      "1185/1185 - 5s - loss: 0.0194 - accuracy: 0.5262 - val_loss: 0.0153 - val_accuracy: 0.6964 - 5s/epoch - 4ms/step\n",
      "Epoch 56/100\n",
      "1185/1185 - 5s - loss: 0.0193 - accuracy: 0.5241 - val_loss: 0.0128 - val_accuracy: 0.8676 - 5s/epoch - 5ms/step\n",
      "Epoch 57/100\n",
      "1185/1185 - 5s - loss: 0.0193 - accuracy: 0.5243 - val_loss: 0.0142 - val_accuracy: 0.7575 - 5s/epoch - 4ms/step\n",
      "Epoch 58/100\n",
      "1185/1185 - 5s - loss: 0.0193 - accuracy: 0.5240 - val_loss: 0.0134 - val_accuracy: 0.8101 - 5s/epoch - 4ms/step\n",
      "Epoch 59/100\n",
      "1185/1185 - 5s - loss: 0.0192 - accuracy: 0.5289 - val_loss: 0.0133 - val_accuracy: 0.8201 - 5s/epoch - 4ms/step\n",
      "Epoch 60/100\n",
      "1185/1185 - 5s - loss: 0.0192 - accuracy: 0.5277 - val_loss: 0.0138 - val_accuracy: 0.7675 - 5s/epoch - 4ms/step\n",
      "Epoch 61/100\n",
      "1185/1185 - 5s - loss: 0.0192 - accuracy: 0.5326 - val_loss: 0.0142 - val_accuracy: 0.7621 - 5s/epoch - 4ms/step\n",
      "Epoch 62/100\n",
      "1185/1185 - 5s - loss: 0.0192 - accuracy: 0.5294 - val_loss: 0.0151 - val_accuracy: 0.7043 - 5s/epoch - 4ms/step\n",
      "Epoch 63/100\n",
      "1185/1185 - 5s - loss: 0.0190 - accuracy: 0.5343 - val_loss: 0.0130 - val_accuracy: 0.8190 - 5s/epoch - 4ms/step\n",
      "Epoch 64/100\n",
      "1185/1185 - 6s - loss: 0.0191 - accuracy: 0.5338 - val_loss: 0.0126 - val_accuracy: 0.8533 - 6s/epoch - 5ms/step\n",
      "Epoch 65/100\n",
      "1185/1185 - 5s - loss: 0.0190 - accuracy: 0.5353 - val_loss: 0.0138 - val_accuracy: 0.7842 - 5s/epoch - 5ms/step\n",
      "Epoch 66/100\n",
      "1185/1185 - 5s - loss: 0.0190 - accuracy: 0.5373 - val_loss: 0.0135 - val_accuracy: 0.8016 - 5s/epoch - 5ms/step\n",
      "Epoch 67/100\n",
      "1185/1185 - 5s - loss: 0.0189 - accuracy: 0.5434 - val_loss: 0.0175 - val_accuracy: 0.5760 - 5s/epoch - 4ms/step\n",
      "Epoch 68/100\n",
      "1185/1185 - 5s - loss: 0.0189 - accuracy: 0.5398 - val_loss: 0.0133 - val_accuracy: 0.8146 - 5s/epoch - 4ms/step\n",
      "Epoch 69/100\n",
      "1185/1185 - 5s - loss: 0.0188 - accuracy: 0.5455 - val_loss: 0.0146 - val_accuracy: 0.7383 - 5s/epoch - 4ms/step\n",
      "Epoch 70/100\n",
      "1185/1185 - 5s - loss: 0.0189 - accuracy: 0.5402 - val_loss: 0.0152 - val_accuracy: 0.7208 - 5s/epoch - 4ms/step\n",
      "Epoch 71/100\n",
      "1185/1185 - 5s - loss: 0.0187 - accuracy: 0.5469 - val_loss: 0.0157 - val_accuracy: 0.6716 - 5s/epoch - 4ms/step\n",
      "Epoch 72/100\n",
      "1185/1185 - 5s - loss: 0.0189 - accuracy: 0.5438 - val_loss: 0.0156 - val_accuracy: 0.6942 - 5s/epoch - 4ms/step\n",
      "Epoch 73/100\n",
      "1185/1185 - 5s - loss: 0.0187 - accuracy: 0.5489 - val_loss: 0.0124 - val_accuracy: 0.8529 - 5s/epoch - 4ms/step\n",
      "Epoch 74/100\n",
      "1185/1185 - 6s - loss: 0.0188 - accuracy: 0.5463 - val_loss: 0.0133 - val_accuracy: 0.8082 - 6s/epoch - 5ms/step\n",
      "Epoch 75/100\n",
      "1185/1185 - 5s - loss: 0.0188 - accuracy: 0.5469 - val_loss: 0.0125 - val_accuracy: 0.8540 - 5s/epoch - 4ms/step\n",
      "Epoch 76/100\n",
      "1185/1185 - 5s - loss: 0.0187 - accuracy: 0.5489 - val_loss: 0.0131 - val_accuracy: 0.8143 - 5s/epoch - 4ms/step\n",
      "Epoch 77/100\n",
      "1185/1185 - 5s - loss: 0.0187 - accuracy: 0.5482 - val_loss: 0.0139 - val_accuracy: 0.7635 - 5s/epoch - 4ms/step\n",
      "Epoch 78/100\n",
      "1185/1185 - 5s - loss: 0.0187 - accuracy: 0.5516 - val_loss: 0.0133 - val_accuracy: 0.7954 - 5s/epoch - 5ms/step\n",
      "Epoch 79/100\n",
      "1185/1185 - 5s - loss: 0.0185 - accuracy: 0.5557 - val_loss: 0.0121 - val_accuracy: 0.8811 - 5s/epoch - 5ms/step\n",
      "Epoch 80/100\n",
      "1185/1185 - 5s - loss: 0.0186 - accuracy: 0.5513 - val_loss: 0.0128 - val_accuracy: 0.8284 - 5s/epoch - 4ms/step\n",
      "Epoch 81/100\n",
      "1185/1185 - 5s - loss: 0.0186 - accuracy: 0.5526 - val_loss: 0.0124 - val_accuracy: 0.8490 - 5s/epoch - 4ms/step\n",
      "Epoch 82/100\n",
      "1185/1185 - 5s - loss: 0.0186 - accuracy: 0.5546 - val_loss: 0.0139 - val_accuracy: 0.7803 - 5s/epoch - 4ms/step\n",
      "Epoch 83/100\n",
      "1185/1185 - 5s - loss: 0.0185 - accuracy: 0.5590 - val_loss: 0.0142 - val_accuracy: 0.7510 - 5s/epoch - 4ms/step\n",
      "Epoch 84/100\n",
      "1185/1185 - 5s - loss: 0.0186 - accuracy: 0.5539 - val_loss: 0.0133 - val_accuracy: 0.8027 - 5s/epoch - 4ms/step\n",
      "Epoch 85/100\n",
      "1185/1185 - 5s - loss: 0.0183 - accuracy: 0.5656 - val_loss: 0.0127 - val_accuracy: 0.8368 - 5s/epoch - 4ms/step\n",
      "Epoch 86/100\n",
      "1185/1185 - 5s - loss: 0.0184 - accuracy: 0.5594 - val_loss: 0.0139 - val_accuracy: 0.7579 - 5s/epoch - 4ms/step\n",
      "Epoch 87/100\n",
      "1185/1185 - 5s - loss: 0.0185 - accuracy: 0.5552 - val_loss: 0.0125 - val_accuracy: 0.8520 - 5s/epoch - 4ms/step\n",
      "Epoch 88/100\n",
      "1185/1185 - 6s - loss: 0.0184 - accuracy: 0.5625 - val_loss: 0.0121 - val_accuracy: 0.8777 - 6s/epoch - 5ms/step\n",
      "Epoch 89/100\n",
      "1185/1185 - 6s - loss: 0.0183 - accuracy: 0.5615 - val_loss: 0.0125 - val_accuracy: 0.8548 - 6s/epoch - 5ms/step\n",
      "Epoch 90/100\n",
      "1185/1185 - 5s - loss: 0.0184 - accuracy: 0.5635 - val_loss: 0.0130 - val_accuracy: 0.8196 - 5s/epoch - 5ms/step\n",
      "Epoch 91/100\n",
      "1185/1185 - 6s - loss: 0.0184 - accuracy: 0.5604 - val_loss: 0.0119 - val_accuracy: 0.8827 - 6s/epoch - 5ms/step\n",
      "Epoch 92/100\n",
      "1185/1185 - 5s - loss: 0.0183 - accuracy: 0.5645 - val_loss: 0.0131 - val_accuracy: 0.8172 - 5s/epoch - 5ms/step\n",
      "Epoch 93/100\n",
      "1185/1185 - 5s - loss: 0.0184 - accuracy: 0.5619 - val_loss: 0.0134 - val_accuracy: 0.7895 - 5s/epoch - 5ms/step\n",
      "Epoch 94/100\n",
      "1185/1185 - 5s - loss: 0.0183 - accuracy: 0.5626 - val_loss: 0.0136 - val_accuracy: 0.7766 - 5s/epoch - 4ms/step\n",
      "Epoch 95/100\n",
      "1185/1185 - 5s - loss: 0.0183 - accuracy: 0.5671 - val_loss: 0.0129 - val_accuracy: 0.8175 - 5s/epoch - 4ms/step\n",
      "Epoch 96/100\n",
      "1185/1185 - 5s - loss: 0.0184 - accuracy: 0.5626 - val_loss: 0.0123 - val_accuracy: 0.8637 - 5s/epoch - 4ms/step\n",
      "Epoch 97/100\n",
      "1185/1185 - 5s - loss: 0.0182 - accuracy: 0.5681 - val_loss: 0.0125 - val_accuracy: 0.8332 - 5s/epoch - 4ms/step\n",
      "Epoch 98/100\n",
      "1185/1185 - 5s - loss: 0.0183 - accuracy: 0.5650 - val_loss: 0.0124 - val_accuracy: 0.8462 - 5s/epoch - 5ms/step\n",
      "Epoch 99/100\n",
      "1185/1185 - 5s - loss: 0.0183 - accuracy: 0.5678 - val_loss: 0.0128 - val_accuracy: 0.8232 - 5s/epoch - 5ms/step\n",
      "Epoch 100/100\n",
      "1185/1185 - 5s - loss: 0.0182 - accuracy: 0.5701 - val_loss: 0.0119 - val_accuracy: 0.8798 - 5s/epoch - 5ms/step\n",
      "Restored model, train accuracy: 90.32%\n",
      "Restored model, valid accuracy: 87.98%\n",
      "Restored model, new_test accuracy: 87.95%\n",
      "Restored model, test accuracy: 72.34%\n"
     ]
    }
   ],
   "source": [
    "network = build_NeuralNetwork()\n",
    "print('Model built.')\n",
    "modelname = 'ann1'\n",
    "checkpointer = ModelCheckpoint(filepath = modelname+'.hdf5', verbose = 0, save_best_only = True)\n",
    "\n",
    "history = network.fit(train_images_array, train_hot_class,\n",
    "    batch_size = 32, #32\n",
    "    epochs = 100, #15\n",
    "    validation_data = (valid_images_array, valid_hot_class),\n",
    "    verbose = 2,\n",
    "    callbacks=[checkpointer],\n",
    "    shuffle = True)\n",
    "\n",
    "network.save('model_'+modelname+'.h5')\n",
    "\n",
    "train_loss, train_acc = network.evaluate(train_images_array, train_hot_class, verbose=0)\n",
    "print('Restored model, train accuracy: {:5.2f}%'.format(100 * train_acc))\n",
    "valid_loss, valid_acc = network.evaluate(valid_images_array, valid_hot_class, verbose=0)\n",
    "print('Restored model, valid accuracy: {:5.2f}%'.format(100 * valid_acc))\n",
    "new_test_loss, new_test_acc = network.evaluate(new_test_images_array, new_test_hot_class, verbose=0)\n",
    "print('Restored model, new_test accuracy: {:5.2f}%'.format(100 * new_test_acc))\n",
    "test_loss, test_acc = network.evaluate(test_images_array, test_hot_class, verbose=0)\n",
    "print('Restored model, test accuracy: {:5.2f}%'.format(100 * test_acc))\n",
    "np.save(modelname+'_history.npy',history.history)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "def build_NeuralNetwork():\n",
    "\n",
    "    #input layer\n",
    "    model = Sequential()\n",
    "    model.add(Input(shape=(100,100,3)))\n",
    "    model.add(Flatten())\n",
    "\n",
    "    #hiddenlayer 1\n",
    "    model.add(Dense(5))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation(activation='relu'))\n",
    "\n",
    "    #hiddenlayer 2\n",
    "    model.add(Dense(50)) #900\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation(activation='relu'))\n",
    "    model.add(Dropout(0.25))\n",
    "\n",
    "    #hiddenlayer 3\n",
    "    model.add(Dense(50)) #900\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation(activation='relu'))\n",
    "    model.add(Dropout(0.25))\n",
    "\n",
    "    #hiddenlayer 4\n",
    "    #model.add(Dense(300)) #900\n",
    "    #model.add(BatchNormalization())\n",
    "    #model.add(Activation(activation='relu'))\n",
    "    #model.add(Dropout(0.25))\n",
    "\n",
    "    #output layer\n",
    "    model.add(Dense(131,activation=\"softmax\"))\n",
    "\n",
    "    model.compile(loss = 'poisson', optimizer = \"adam\", metrics = ['accuracy'])\n",
    "    print('Compiled!')\n",
    "\n",
    "    return model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compiled!\n",
      "Model built.\n",
      "Epoch 1/100\n",
      "1185/1185 - 12s - loss: 0.0328 - accuracy: 0.1596 - val_loss: 0.0235 - val_accuracy: 0.4014 - 12s/epoch - 10ms/step\n",
      "Epoch 2/100\n",
      "1185/1185 - 6s - loss: 0.0242 - accuracy: 0.3453 - val_loss: 0.0200 - val_accuracy: 0.5208 - 6s/epoch - 5ms/step\n",
      "Epoch 3/100\n",
      "1185/1185 - 5s - loss: 0.0216 - accuracy: 0.4358 - val_loss: 0.0238 - val_accuracy: 0.3833 - 5s/epoch - 5ms/step\n",
      "Epoch 4/100\n",
      "1185/1185 - 5s - loss: 0.0197 - accuracy: 0.5028 - val_loss: 0.0178 - val_accuracy: 0.5689 - 5s/epoch - 5ms/step\n",
      "Epoch 5/100\n",
      "1185/1185 - 6s - loss: 0.0187 - accuracy: 0.5442 - val_loss: 0.0138 - val_accuracy: 0.7834 - 6s/epoch - 5ms/step\n",
      "Epoch 6/100\n",
      "1185/1185 - 6s - loss: 0.0181 - accuracy: 0.5680 - val_loss: 0.0127 - val_accuracy: 0.8305 - 6s/epoch - 5ms/step\n",
      "Epoch 7/100\n",
      "1185/1185 - 5s - loss: 0.0176 - accuracy: 0.5856 - val_loss: 0.0126 - val_accuracy: 0.8192 - 5s/epoch - 5ms/step\n",
      "Epoch 8/100\n",
      "1185/1185 - 5s - loss: 0.0172 - accuracy: 0.5981 - val_loss: 0.0140 - val_accuracy: 0.7429 - 5s/epoch - 5ms/step\n",
      "Epoch 9/100\n",
      "1185/1185 - 5s - loss: 0.0168 - accuracy: 0.6161 - val_loss: 0.0185 - val_accuracy: 0.5396 - 5s/epoch - 5ms/step\n",
      "Epoch 10/100\n",
      "1185/1185 - 5s - loss: 0.0164 - accuracy: 0.6292 - val_loss: 0.0161 - val_accuracy: 0.6302 - 5s/epoch - 4ms/step\n",
      "Epoch 11/100\n",
      "1185/1185 - 5s - loss: 0.0162 - accuracy: 0.6404 - val_loss: 0.0175 - val_accuracy: 0.5875 - 5s/epoch - 4ms/step\n",
      "Epoch 12/100\n",
      "1185/1185 - 5s - loss: 0.0161 - accuracy: 0.6444 - val_loss: 0.0174 - val_accuracy: 0.5871 - 5s/epoch - 5ms/step\n",
      "Epoch 13/100\n",
      "1185/1185 - 6s - loss: 0.0159 - accuracy: 0.6483 - val_loss: 0.0118 - val_accuracy: 0.8466 - 6s/epoch - 5ms/step\n",
      "Epoch 14/100\n",
      "1185/1185 - 6s - loss: 0.0157 - accuracy: 0.6538 - val_loss: 0.0117 - val_accuracy: 0.8351 - 6s/epoch - 5ms/step\n",
      "Epoch 15/100\n",
      "1185/1185 - 6s - loss: 0.0157 - accuracy: 0.6576 - val_loss: 0.0109 - val_accuracy: 0.8915 - 6s/epoch - 5ms/step\n",
      "Epoch 16/100\n",
      "1185/1185 - 6s - loss: 0.0154 - accuracy: 0.6698 - val_loss: 0.0115 - val_accuracy: 0.8506 - 6s/epoch - 5ms/step\n",
      "Epoch 17/100\n",
      "1185/1185 - 6s - loss: 0.0155 - accuracy: 0.6641 - val_loss: 0.0107 - val_accuracy: 0.8945 - 6s/epoch - 5ms/step\n",
      "Epoch 18/100\n",
      "1185/1185 - 6s - loss: 0.0152 - accuracy: 0.6772 - val_loss: 0.0119 - val_accuracy: 0.8152 - 6s/epoch - 5ms/step\n",
      "Epoch 19/100\n",
      "1185/1185 - 6s - loss: 0.0152 - accuracy: 0.6790 - val_loss: 0.0131 - val_accuracy: 0.7566 - 6s/epoch - 5ms/step\n",
      "Epoch 20/100\n",
      "1185/1185 - 5s - loss: 0.0152 - accuracy: 0.6784 - val_loss: 0.0109 - val_accuracy: 0.8821 - 5s/epoch - 5ms/step\n",
      "Epoch 21/100\n",
      "1185/1185 - 5s - loss: 0.0152 - accuracy: 0.6799 - val_loss: 0.0111 - val_accuracy: 0.8666 - 5s/epoch - 4ms/step\n",
      "Epoch 22/100\n",
      "1185/1185 - 5s - loss: 0.0150 - accuracy: 0.6855 - val_loss: 0.0124 - val_accuracy: 0.8016 - 5s/epoch - 4ms/step\n",
      "Epoch 23/100\n",
      "1185/1185 - 5s - loss: 0.0149 - accuracy: 0.6912 - val_loss: 0.0159 - val_accuracy: 0.6479 - 5s/epoch - 4ms/step\n",
      "Epoch 24/100\n",
      "1185/1185 - 5s - loss: 0.0149 - accuracy: 0.6924 - val_loss: 0.0113 - val_accuracy: 0.8516 - 5s/epoch - 4ms/step\n",
      "Epoch 25/100\n",
      "1185/1185 - 5s - loss: 0.0147 - accuracy: 0.6997 - val_loss: 0.0142 - val_accuracy: 0.7311 - 5s/epoch - 4ms/step\n",
      "Epoch 26/100\n",
      "1185/1185 - 5s - loss: 0.0147 - accuracy: 0.7004 - val_loss: 0.0109 - val_accuracy: 0.8762 - 5s/epoch - 4ms/step\n",
      "Epoch 27/100\n",
      "1185/1185 - 5s - loss: 0.0146 - accuracy: 0.7011 - val_loss: 0.0117 - val_accuracy: 0.8341 - 5s/epoch - 4ms/step\n",
      "Epoch 28/100\n",
      "1185/1185 - 5s - loss: 0.0146 - accuracy: 0.7042 - val_loss: 0.0120 - val_accuracy: 0.8188 - 5s/epoch - 4ms/step\n",
      "Epoch 29/100\n",
      "1185/1185 - 5s - loss: 0.0145 - accuracy: 0.7099 - val_loss: 0.0102 - val_accuracy: 0.9144 - 5s/epoch - 4ms/step\n",
      "Epoch 30/100\n",
      "1185/1185 - 5s - loss: 0.0144 - accuracy: 0.7093 - val_loss: 0.0101 - val_accuracy: 0.9091 - 5s/epoch - 5ms/step\n",
      "Epoch 31/100\n",
      "1185/1185 - 5s - loss: 0.0144 - accuracy: 0.7136 - val_loss: 0.0103 - val_accuracy: 0.9070 - 5s/epoch - 4ms/step\n",
      "Epoch 32/100\n",
      "1185/1185 - 5s - loss: 0.0143 - accuracy: 0.7153 - val_loss: 0.0108 - val_accuracy: 0.8823 - 5s/epoch - 4ms/step\n",
      "Epoch 33/100\n",
      "1185/1185 - 5s - loss: 0.0144 - accuracy: 0.7139 - val_loss: 0.0108 - val_accuracy: 0.8778 - 5s/epoch - 4ms/step\n",
      "Epoch 34/100\n",
      "1185/1185 - 5s - loss: 0.0144 - accuracy: 0.7148 - val_loss: 0.0110 - val_accuracy: 0.8678 - 5s/epoch - 4ms/step\n",
      "Epoch 35/100\n",
      "1185/1185 - 5s - loss: 0.0142 - accuracy: 0.7190 - val_loss: 0.0115 - val_accuracy: 0.8330 - 5s/epoch - 4ms/step\n",
      "Epoch 36/100\n",
      "1185/1185 - 5s - loss: 0.0143 - accuracy: 0.7185 - val_loss: 0.0109 - val_accuracy: 0.8730 - 5s/epoch - 4ms/step\n",
      "Epoch 37/100\n",
      "1185/1185 - 5s - loss: 0.0141 - accuracy: 0.7234 - val_loss: 0.0105 - val_accuracy: 0.8836 - 5s/epoch - 4ms/step\n",
      "Epoch 38/100\n",
      "1185/1185 - 5s - loss: 0.0140 - accuracy: 0.7277 - val_loss: 0.0113 - val_accuracy: 0.8500 - 5s/epoch - 4ms/step\n",
      "Epoch 39/100\n",
      "1185/1185 - 5s - loss: 0.0139 - accuracy: 0.7329 - val_loss: 0.0138 - val_accuracy: 0.7317 - 5s/epoch - 4ms/step\n",
      "Epoch 40/100\n",
      "1185/1185 - 5s - loss: 0.0140 - accuracy: 0.7325 - val_loss: 0.0108 - val_accuracy: 0.8714 - 5s/epoch - 4ms/step\n",
      "Epoch 41/100\n",
      "1185/1185 - 5s - loss: 0.0140 - accuracy: 0.7273 - val_loss: 0.0112 - val_accuracy: 0.8492 - 5s/epoch - 4ms/step\n",
      "Epoch 42/100\n",
      "1185/1185 - 5s - loss: 0.0141 - accuracy: 0.7234 - val_loss: 0.0104 - val_accuracy: 0.8892 - 5s/epoch - 4ms/step\n",
      "Epoch 43/100\n",
      "1185/1185 - 5s - loss: 0.0139 - accuracy: 0.7295 - val_loss: 0.0105 - val_accuracy: 0.8907 - 5s/epoch - 4ms/step\n",
      "Epoch 44/100\n",
      "1185/1185 - 5s - loss: 0.0138 - accuracy: 0.7357 - val_loss: 0.0113 - val_accuracy: 0.8530 - 5s/epoch - 4ms/step\n",
      "Epoch 45/100\n",
      "1185/1185 - 5s - loss: 0.0138 - accuracy: 0.7361 - val_loss: 0.0144 - val_accuracy: 0.7215 - 5s/epoch - 5ms/step\n",
      "Epoch 46/100\n",
      "1185/1185 - 5s - loss: 0.0139 - accuracy: 0.7352 - val_loss: 0.0113 - val_accuracy: 0.8521 - 5s/epoch - 4ms/step\n",
      "Epoch 47/100\n",
      "1185/1185 - 5s - loss: 0.0138 - accuracy: 0.7385 - val_loss: 0.0139 - val_accuracy: 0.7153 - 5s/epoch - 4ms/step\n",
      "Epoch 48/100\n",
      "1185/1185 - 5s - loss: 0.0137 - accuracy: 0.7410 - val_loss: 0.0100 - val_accuracy: 0.9176 - 5s/epoch - 5ms/step\n",
      "Epoch 49/100\n",
      "1185/1185 - 5s - loss: 0.0138 - accuracy: 0.7419 - val_loss: 0.0113 - val_accuracy: 0.8433 - 5s/epoch - 4ms/step\n",
      "Epoch 50/100\n",
      "1185/1185 - 5s - loss: 0.0137 - accuracy: 0.7408 - val_loss: 0.0109 - val_accuracy: 0.8691 - 5s/epoch - 4ms/step\n",
      "Epoch 51/100\n",
      "1185/1185 - 5s - loss: 0.0136 - accuracy: 0.7447 - val_loss: 0.0113 - val_accuracy: 0.8436 - 5s/epoch - 4ms/step\n",
      "Epoch 52/100\n",
      "1185/1185 - 5s - loss: 0.0137 - accuracy: 0.7429 - val_loss: 0.0103 - val_accuracy: 0.8974 - 5s/epoch - 4ms/step\n",
      "Epoch 53/100\n",
      "1185/1185 - 5s - loss: 0.0136 - accuracy: 0.7418 - val_loss: 0.0121 - val_accuracy: 0.8094 - 5s/epoch - 4ms/step\n",
      "Epoch 54/100\n",
      "1185/1185 - 5s - loss: 0.0136 - accuracy: 0.7469 - val_loss: 0.0174 - val_accuracy: 0.5914 - 5s/epoch - 4ms/step\n",
      "Epoch 55/100\n",
      "1185/1185 - 5s - loss: 0.0136 - accuracy: 0.7461 - val_loss: 0.0119 - val_accuracy: 0.8107 - 5s/epoch - 4ms/step\n",
      "Epoch 56/100\n",
      "1185/1185 - 5s - loss: 0.0136 - accuracy: 0.7469 - val_loss: 0.0135 - val_accuracy: 0.7414 - 5s/epoch - 4ms/step\n",
      "Epoch 57/100\n",
      "1185/1185 - 5s - loss: 0.0134 - accuracy: 0.7524 - val_loss: 0.0119 - val_accuracy: 0.8105 - 5s/epoch - 4ms/step\n",
      "Epoch 58/100\n",
      "1185/1185 - 5s - loss: 0.0135 - accuracy: 0.7485 - val_loss: 0.0103 - val_accuracy: 0.8975 - 5s/epoch - 4ms/step\n",
      "Epoch 59/100\n",
      "1185/1185 - 5s - loss: 0.0134 - accuracy: 0.7518 - val_loss: 0.0103 - val_accuracy: 0.8903 - 5s/epoch - 4ms/step\n",
      "Epoch 60/100\n",
      "1185/1185 - 5s - loss: 0.0135 - accuracy: 0.7468 - val_loss: 0.0104 - val_accuracy: 0.8962 - 5s/epoch - 4ms/step\n",
      "Epoch 61/100\n",
      "1185/1185 - 5s - loss: 0.0135 - accuracy: 0.7500 - val_loss: 0.0165 - val_accuracy: 0.6314 - 5s/epoch - 4ms/step\n",
      "Epoch 62/100\n",
      "1185/1185 - 5s - loss: 0.0136 - accuracy: 0.7485 - val_loss: 0.0125 - val_accuracy: 0.7764 - 5s/epoch - 4ms/step\n",
      "Epoch 63/100\n",
      "1185/1185 - 5s - loss: 0.0134 - accuracy: 0.7542 - val_loss: 0.0126 - val_accuracy: 0.7757 - 5s/epoch - 4ms/step\n",
      "Epoch 64/100\n",
      "1185/1185 - 5s - loss: 0.0134 - accuracy: 0.7553 - val_loss: 0.0114 - val_accuracy: 0.8450 - 5s/epoch - 4ms/step\n",
      "Epoch 65/100\n",
      "1185/1185 - 5s - loss: 0.0134 - accuracy: 0.7563 - val_loss: 0.0126 - val_accuracy: 0.7778 - 5s/epoch - 4ms/step\n",
      "Epoch 66/100\n",
      "1185/1185 - 5s - loss: 0.0133 - accuracy: 0.7594 - val_loss: 0.0108 - val_accuracy: 0.8574 - 5s/epoch - 4ms/step\n",
      "Epoch 67/100\n",
      "1185/1185 - 5s - loss: 0.0132 - accuracy: 0.7601 - val_loss: 0.0109 - val_accuracy: 0.8674 - 5s/epoch - 4ms/step\n",
      "Epoch 68/100\n",
      "1185/1185 - 5s - loss: 0.0133 - accuracy: 0.7569 - val_loss: 0.0105 - val_accuracy: 0.8878 - 5s/epoch - 4ms/step\n",
      "Epoch 69/100\n",
      "1185/1185 - 5s - loss: 0.0133 - accuracy: 0.7561 - val_loss: 0.0107 - val_accuracy: 0.8721 - 5s/epoch - 4ms/step\n",
      "Epoch 70/100\n",
      "1185/1185 - 5s - loss: 0.0132 - accuracy: 0.7623 - val_loss: 0.0098 - val_accuracy: 0.9186 - 5s/epoch - 4ms/step\n",
      "Epoch 71/100\n",
      "1185/1185 - 6s - loss: 0.0131 - accuracy: 0.7635 - val_loss: 0.0101 - val_accuracy: 0.9085 - 6s/epoch - 5ms/step\n",
      "Epoch 72/100\n",
      "1185/1185 - 5s - loss: 0.0132 - accuracy: 0.7640 - val_loss: 0.0096 - val_accuracy: 0.9279 - 5s/epoch - 5ms/step\n",
      "Epoch 73/100\n",
      "1185/1185 - 5s - loss: 0.0132 - accuracy: 0.7604 - val_loss: 0.0115 - val_accuracy: 0.8370 - 5s/epoch - 4ms/step\n",
      "Epoch 74/100\n",
      "1185/1185 - 5s - loss: 0.0132 - accuracy: 0.7625 - val_loss: 0.0118 - val_accuracy: 0.8245 - 5s/epoch - 4ms/step\n",
      "Epoch 75/100\n",
      "1185/1185 - 5s - loss: 0.0132 - accuracy: 0.7647 - val_loss: 0.0096 - val_accuracy: 0.9287 - 5s/epoch - 4ms/step\n",
      "Epoch 76/100\n",
      "1185/1185 - 5s - loss: 0.0131 - accuracy: 0.7682 - val_loss: 0.0106 - val_accuracy: 0.8869 - 5s/epoch - 4ms/step\n",
      "Epoch 77/100\n",
      "1185/1185 - 5s - loss: 0.0132 - accuracy: 0.7641 - val_loss: 0.0105 - val_accuracy: 0.8822 - 5s/epoch - 4ms/step\n",
      "Epoch 78/100\n",
      "1185/1185 - 5s - loss: 0.0131 - accuracy: 0.7671 - val_loss: 0.0117 - val_accuracy: 0.8189 - 5s/epoch - 4ms/step\n",
      "Epoch 79/100\n",
      "1185/1185 - 5s - loss: 0.0130 - accuracy: 0.7709 - val_loss: 0.0139 - val_accuracy: 0.7331 - 5s/epoch - 4ms/step\n",
      "Epoch 80/100\n",
      "1185/1185 - 5s - loss: 0.0131 - accuracy: 0.7666 - val_loss: 0.0134 - val_accuracy: 0.7397 - 5s/epoch - 4ms/step\n",
      "Epoch 81/100\n",
      "1185/1185 - 5s - loss: 0.0130 - accuracy: 0.7718 - val_loss: 0.0113 - val_accuracy: 0.8373 - 5s/epoch - 4ms/step\n",
      "Epoch 82/100\n",
      "1185/1185 - 5s - loss: 0.0131 - accuracy: 0.7629 - val_loss: 0.0095 - val_accuracy: 0.9366 - 5s/epoch - 5ms/step\n",
      "Epoch 83/100\n",
      "1185/1185 - 5s - loss: 0.0130 - accuracy: 0.7712 - val_loss: 0.0101 - val_accuracy: 0.9045 - 5s/epoch - 4ms/step\n",
      "Epoch 84/100\n",
      "1185/1185 - 5s - loss: 0.0130 - accuracy: 0.7721 - val_loss: 0.0106 - val_accuracy: 0.8834 - 5s/epoch - 4ms/step\n",
      "Epoch 85/100\n",
      "1185/1185 - 5s - loss: 0.0130 - accuracy: 0.7700 - val_loss: 0.0127 - val_accuracy: 0.7664 - 5s/epoch - 5ms/step\n",
      "Epoch 86/100\n",
      "1185/1185 - 5s - loss: 0.0130 - accuracy: 0.7707 - val_loss: 0.0096 - val_accuracy: 0.9327 - 5s/epoch - 4ms/step\n",
      "Epoch 87/100\n",
      "1185/1185 - 5s - loss: 0.0129 - accuracy: 0.7769 - val_loss: 0.0098 - val_accuracy: 0.9207 - 5s/epoch - 4ms/step\n",
      "Epoch 88/100\n",
      "1185/1185 - 5s - loss: 0.0129 - accuracy: 0.7760 - val_loss: 0.0104 - val_accuracy: 0.8837 - 5s/epoch - 4ms/step\n",
      "Epoch 89/100\n",
      "1185/1185 - 5s - loss: 0.0129 - accuracy: 0.7736 - val_loss: 0.0097 - val_accuracy: 0.9239 - 5s/epoch - 4ms/step\n",
      "Epoch 90/100\n",
      "1185/1185 - 5s - loss: 0.0129 - accuracy: 0.7781 - val_loss: 0.0112 - val_accuracy: 0.8535 - 5s/epoch - 4ms/step\n",
      "Epoch 91/100\n",
      "1185/1185 - 5s - loss: 0.0130 - accuracy: 0.7714 - val_loss: 0.0098 - val_accuracy: 0.9174 - 5s/epoch - 4ms/step\n",
      "Epoch 92/100\n",
      "1185/1185 - 5s - loss: 0.0130 - accuracy: 0.7687 - val_loss: 0.0099 - val_accuracy: 0.9162 - 5s/epoch - 4ms/step\n",
      "Epoch 93/100\n",
      "1185/1185 - 5s - loss: 0.0128 - accuracy: 0.7784 - val_loss: 0.0097 - val_accuracy: 0.9188 - 5s/epoch - 4ms/step\n",
      "Epoch 94/100\n",
      "1185/1185 - 5s - loss: 0.0128 - accuracy: 0.7796 - val_loss: 0.0102 - val_accuracy: 0.8976 - 5s/epoch - 4ms/step\n",
      "Epoch 95/100\n",
      "1185/1185 - 5s - loss: 0.0127 - accuracy: 0.7841 - val_loss: 0.0121 - val_accuracy: 0.8017 - 5s/epoch - 4ms/step\n",
      "Epoch 96/100\n",
      "1185/1185 - 5s - loss: 0.0128 - accuracy: 0.7808 - val_loss: 0.0120 - val_accuracy: 0.8097 - 5s/epoch - 4ms/step\n",
      "Epoch 97/100\n",
      "1185/1185 - 5s - loss: 0.0128 - accuracy: 0.7794 - val_loss: 0.0097 - val_accuracy: 0.9191 - 5s/epoch - 4ms/step\n",
      "Epoch 98/100\n",
      "1185/1185 - 5s - loss: 0.0128 - accuracy: 0.7823 - val_loss: 0.0109 - val_accuracy: 0.8592 - 5s/epoch - 4ms/step\n",
      "Epoch 99/100\n",
      "1185/1185 - 5s - loss: 0.0127 - accuracy: 0.7842 - val_loss: 0.0105 - val_accuracy: 0.8791 - 5s/epoch - 4ms/step\n",
      "Epoch 100/100\n",
      "1185/1185 - 5s - loss: 0.0127 - accuracy: 0.7832 - val_loss: 0.0104 - val_accuracy: 0.8904 - 5s/epoch - 5ms/step\n",
      "Restored model, train accuracy: 91.77%\n",
      "Restored model, valid accuracy: 89.04%\n",
      "Restored model, new_test accuracy: 88.81%\n",
      "Restored model, test accuracy: 68.80%\n"
     ]
    }
   ],
   "source": [
    "network = build_NeuralNetwork()\n",
    "print('Model built.')\n",
    "modelname = 'ann1'\n",
    "checkpointer = ModelCheckpoint(filepath = modelname+'.hdf5', verbose = 0, save_best_only = True)\n",
    "\n",
    "history = network.fit(train_images_array, train_hot_class,\n",
    "    batch_size = 32, #32\n",
    "    epochs = 100, #15\n",
    "    validation_data = (valid_images_array, valid_hot_class),\n",
    "    verbose = 2,\n",
    "    callbacks=[checkpointer],\n",
    "    shuffle = True)\n",
    "\n",
    "network.save('model_'+modelname+'.h5')\n",
    "\n",
    "train_loss, train_acc = network.evaluate(train_images_array, train_hot_class, verbose=0)\n",
    "print('Restored model, train accuracy: {:5.2f}%'.format(100 * train_acc))\n",
    "valid_loss, valid_acc = network.evaluate(valid_images_array, valid_hot_class, verbose=0)\n",
    "print('Restored model, valid accuracy: {:5.2f}%'.format(100 * valid_acc))\n",
    "new_test_loss, new_test_acc = network.evaluate(new_test_images_array, new_test_hot_class, verbose=0)\n",
    "print('Restored model, new_test accuracy: {:5.2f}%'.format(100 * new_test_acc))\n",
    "test_loss, test_acc = network.evaluate(test_images_array, test_hot_class, verbose=0)\n",
    "print('Restored model, test accuracy: {:5.2f}%'.format(100 * test_acc))\n",
    "np.save(modelname+'_history.npy',history.history)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "def build_NeuralNetwork():\n",
    "\n",
    "    #input layer\n",
    "    model = Sequential()\n",
    "    model.add(Input(shape=(100,100,3)))\n",
    "    model.add(Flatten())\n",
    "\n",
    "    #hiddenlayer 1\n",
    "    model.add(Dense(5))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation(activation='tanh'))\n",
    "\n",
    "    #hiddenlayer 2\n",
    "    model.add(Dense(50)) #900\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation(activation='tanh'))\n",
    "    model.add(Dropout(0.25))\n",
    "\n",
    "    #hiddenlayer 3\n",
    "    model.add(Dense(50)) #900\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation(activation='tanh'))\n",
    "    model.add(Dropout(0.25))\n",
    "\n",
    "    #hiddenlayer 4\n",
    "    #model.add(Dense(300)) #900\n",
    "    #model.add(BatchNormalization())\n",
    "    #model.add(Activation(activation='relu'))\n",
    "    #model.add(Dropout(0.25))\n",
    "\n",
    "    #output layer\n",
    "    model.add(Dense(131,activation=\"softmax\"))\n",
    "\n",
    "    model.compile(loss = 'poisson', optimizer = \"adam\", metrics = ['accuracy'])\n",
    "    print('Compiled!')\n",
    "\n",
    "    return model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compiled!\n",
      "Model built.\n",
      "Epoch 1/100\n",
      "1185/1185 - 9s - loss: 0.0310 - accuracy: 0.2620 - val_loss: 0.0219 - val_accuracy: 0.5722 - 9s/epoch - 8ms/step\n",
      "Epoch 2/100\n",
      "1185/1185 - 5s - loss: 0.0211 - accuracy: 0.5142 - val_loss: 0.0198 - val_accuracy: 0.5227 - 5s/epoch - 5ms/step\n",
      "Epoch 3/100\n",
      "1185/1185 - 6s - loss: 0.0183 - accuracy: 0.5906 - val_loss: 0.0172 - val_accuracy: 0.6074 - 6s/epoch - 5ms/step\n",
      "Epoch 4/100\n",
      "1185/1185 - 5s - loss: 0.0171 - accuracy: 0.6258 - val_loss: 0.0136 - val_accuracy: 0.7950 - 5s/epoch - 5ms/step\n",
      "Epoch 5/100\n",
      "1185/1185 - 5s - loss: 0.0165 - accuracy: 0.6425 - val_loss: 0.0174 - val_accuracy: 0.5785 - 5s/epoch - 4ms/step\n",
      "Epoch 6/100\n",
      "1185/1185 - 5s - loss: 0.0161 - accuracy: 0.6514 - val_loss: 0.0120 - val_accuracy: 0.8484 - 5s/epoch - 4ms/step\n",
      "Epoch 7/100\n",
      "1185/1185 - 5s - loss: 0.0156 - accuracy: 0.6710 - val_loss: 0.0130 - val_accuracy: 0.7864 - 5s/epoch - 4ms/step\n",
      "Epoch 8/100\n",
      "1185/1185 - 5s - loss: 0.0154 - accuracy: 0.6796 - val_loss: 0.0159 - val_accuracy: 0.6389 - 5s/epoch - 4ms/step\n",
      "Epoch 9/100\n",
      "1185/1185 - 5s - loss: 0.0151 - accuracy: 0.6891 - val_loss: 0.0197 - val_accuracy: 0.4826 - 5s/epoch - 4ms/step\n",
      "Epoch 10/100\n",
      "1185/1185 - 5s - loss: 0.0151 - accuracy: 0.6881 - val_loss: 0.0111 - val_accuracy: 0.8745 - 5s/epoch - 4ms/step\n",
      "Epoch 11/100\n",
      "1185/1185 - 5s - loss: 0.0148 - accuracy: 0.6997 - val_loss: 0.0150 - val_accuracy: 0.6837 - 5s/epoch - 4ms/step\n",
      "Epoch 12/100\n",
      "1185/1185 - 5s - loss: 0.0148 - accuracy: 0.7001 - val_loss: 0.0122 - val_accuracy: 0.8116 - 5s/epoch - 4ms/step\n",
      "Epoch 13/100\n",
      "1185/1185 - 5s - loss: 0.0147 - accuracy: 0.7036 - val_loss: 0.0147 - val_accuracy: 0.6794 - 5s/epoch - 4ms/step\n",
      "Epoch 14/100\n",
      "1185/1185 - 5s - loss: 0.0145 - accuracy: 0.7103 - val_loss: 0.0116 - val_accuracy: 0.8374 - 5s/epoch - 4ms/step\n",
      "Epoch 15/100\n",
      "1185/1185 - 5s - loss: 0.0144 - accuracy: 0.7134 - val_loss: 0.0113 - val_accuracy: 0.8513 - 5s/epoch - 4ms/step\n",
      "Epoch 16/100\n",
      "1185/1185 - 5s - loss: 0.0144 - accuracy: 0.7173 - val_loss: 0.0181 - val_accuracy: 0.5557 - 5s/epoch - 4ms/step\n",
      "Epoch 17/100\n",
      "1185/1185 - 5s - loss: 0.0142 - accuracy: 0.7227 - val_loss: 0.0128 - val_accuracy: 0.7752 - 5s/epoch - 4ms/step\n",
      "Epoch 18/100\n",
      "1185/1185 - 5s - loss: 0.0142 - accuracy: 0.7239 - val_loss: 0.0112 - val_accuracy: 0.8583 - 5s/epoch - 4ms/step\n",
      "Epoch 19/100\n",
      "1185/1185 - 5s - loss: 0.0141 - accuracy: 0.7293 - val_loss: 0.0111 - val_accuracy: 0.8718 - 5s/epoch - 4ms/step\n",
      "Epoch 20/100\n",
      "1185/1185 - 5s - loss: 0.0140 - accuracy: 0.7292 - val_loss: 0.0132 - val_accuracy: 0.7556 - 5s/epoch - 4ms/step\n",
      "Epoch 21/100\n",
      "1185/1185 - 5s - loss: 0.0139 - accuracy: 0.7353 - val_loss: 0.0103 - val_accuracy: 0.9022 - 5s/epoch - 4ms/step\n",
      "Epoch 22/100\n",
      "1185/1185 - 5s - loss: 0.0139 - accuracy: 0.7359 - val_loss: 0.0116 - val_accuracy: 0.8311 - 5s/epoch - 4ms/step\n",
      "Epoch 23/100\n",
      "1185/1185 - 5s - loss: 0.0138 - accuracy: 0.7398 - val_loss: 0.0146 - val_accuracy: 0.6926 - 5s/epoch - 4ms/step\n",
      "Epoch 24/100\n",
      "1185/1185 - 6s - loss: 0.0138 - accuracy: 0.7393 - val_loss: 0.0139 - val_accuracy: 0.7305 - 6s/epoch - 5ms/step\n",
      "Epoch 25/100\n",
      "1185/1185 - 6s - loss: 0.0137 - accuracy: 0.7445 - val_loss: 0.0146 - val_accuracy: 0.6907 - 6s/epoch - 5ms/step\n",
      "Epoch 26/100\n",
      "1185/1185 - 5s - loss: 0.0138 - accuracy: 0.7381 - val_loss: 0.0112 - val_accuracy: 0.8562 - 5s/epoch - 5ms/step\n",
      "Epoch 27/100\n",
      "1185/1185 - 6s - loss: 0.0136 - accuracy: 0.7458 - val_loss: 0.0141 - val_accuracy: 0.7119 - 6s/epoch - 5ms/step\n",
      "Epoch 28/100\n",
      "1185/1185 - 5s - loss: 0.0135 - accuracy: 0.7497 - val_loss: 0.0188 - val_accuracy: 0.5607 - 5s/epoch - 5ms/step\n",
      "Epoch 29/100\n",
      "1185/1185 - 5s - loss: 0.0134 - accuracy: 0.7542 - val_loss: 0.0182 - val_accuracy: 0.5832 - 5s/epoch - 4ms/step\n",
      "Epoch 30/100\n",
      "1185/1185 - 5s - loss: 0.0134 - accuracy: 0.7559 - val_loss: 0.0116 - val_accuracy: 0.8372 - 5s/epoch - 4ms/step\n",
      "Epoch 31/100\n",
      "1185/1185 - 5s - loss: 0.0134 - accuracy: 0.7572 - val_loss: 0.0123 - val_accuracy: 0.7995 - 5s/epoch - 4ms/step\n",
      "Epoch 32/100\n",
      "1185/1185 - 5s - loss: 0.0133 - accuracy: 0.7626 - val_loss: 0.0105 - val_accuracy: 0.8878 - 5s/epoch - 4ms/step\n",
      "Epoch 33/100\n",
      "1185/1185 - 5s - loss: 0.0134 - accuracy: 0.7594 - val_loss: 0.0171 - val_accuracy: 0.6125 - 5s/epoch - 4ms/step\n",
      "Epoch 34/100\n",
      "1185/1185 - 5s - loss: 0.0133 - accuracy: 0.7602 - val_loss: 0.0112 - val_accuracy: 0.8579 - 5s/epoch - 4ms/step\n",
      "Epoch 35/100\n",
      "1185/1185 - 5s - loss: 0.0133 - accuracy: 0.7620 - val_loss: 0.0121 - val_accuracy: 0.8013 - 5s/epoch - 4ms/step\n",
      "Epoch 36/100\n",
      "1185/1185 - 5s - loss: 0.0133 - accuracy: 0.7589 - val_loss: 0.0161 - val_accuracy: 0.6693 - 5s/epoch - 4ms/step\n",
      "Epoch 37/100\n",
      "1185/1185 - 5s - loss: 0.0132 - accuracy: 0.7662 - val_loss: 0.0118 - val_accuracy: 0.8181 - 5s/epoch - 4ms/step\n",
      "Epoch 38/100\n",
      "1185/1185 - 5s - loss: 0.0131 - accuracy: 0.7708 - val_loss: 0.0112 - val_accuracy: 0.8521 - 5s/epoch - 4ms/step\n",
      "Epoch 39/100\n",
      "1185/1185 - 5s - loss: 0.0132 - accuracy: 0.7642 - val_loss: 0.0104 - val_accuracy: 0.8896 - 5s/epoch - 4ms/step\n",
      "Epoch 40/100\n",
      "1185/1185 - 5s - loss: 0.0130 - accuracy: 0.7689 - val_loss: 0.0102 - val_accuracy: 0.8968 - 5s/epoch - 4ms/step\n",
      "Epoch 41/100\n",
      "1185/1185 - 5s - loss: 0.0131 - accuracy: 0.7694 - val_loss: 0.0106 - val_accuracy: 0.8808 - 5s/epoch - 4ms/step\n",
      "Epoch 42/100\n",
      "1185/1185 - 5s - loss: 0.0129 - accuracy: 0.7762 - val_loss: 0.0100 - val_accuracy: 0.9075 - 5s/epoch - 5ms/step\n",
      "Epoch 43/100\n",
      "1185/1185 - 6s - loss: 0.0129 - accuracy: 0.7744 - val_loss: 0.0122 - val_accuracy: 0.8010 - 6s/epoch - 5ms/step\n",
      "Epoch 44/100\n",
      "1185/1185 - 6s - loss: 0.0128 - accuracy: 0.7832 - val_loss: 0.0105 - val_accuracy: 0.8850 - 6s/epoch - 5ms/step\n",
      "Epoch 45/100\n",
      "1185/1185 - 5s - loss: 0.0129 - accuracy: 0.7782 - val_loss: 0.0148 - val_accuracy: 0.7062 - 5s/epoch - 4ms/step\n",
      "Epoch 46/100\n",
      "1185/1185 - 5s - loss: 0.0128 - accuracy: 0.7792 - val_loss: 0.0112 - val_accuracy: 0.8522 - 5s/epoch - 4ms/step\n",
      "Epoch 47/100\n",
      "1185/1185 - 5s - loss: 0.0129 - accuracy: 0.7784 - val_loss: 0.0143 - val_accuracy: 0.6898 - 5s/epoch - 4ms/step\n",
      "Epoch 48/100\n",
      "1185/1185 - 5s - loss: 0.0129 - accuracy: 0.7790 - val_loss: 0.0111 - val_accuracy: 0.8566 - 5s/epoch - 4ms/step\n",
      "Epoch 49/100\n",
      "1185/1185 - 5s - loss: 0.0128 - accuracy: 0.7785 - val_loss: 0.0116 - val_accuracy: 0.8306 - 5s/epoch - 4ms/step\n",
      "Epoch 50/100\n",
      "1185/1185 - 5s - loss: 0.0128 - accuracy: 0.7792 - val_loss: 0.0098 - val_accuracy: 0.9185 - 5s/epoch - 4ms/step\n",
      "Epoch 51/100\n",
      "1185/1185 - 5s - loss: 0.0127 - accuracy: 0.7868 - val_loss: 0.0155 - val_accuracy: 0.6751 - 5s/epoch - 4ms/step\n",
      "Epoch 52/100\n",
      "1185/1185 - 5s - loss: 0.0127 - accuracy: 0.7842 - val_loss: 0.0186 - val_accuracy: 0.6026 - 5s/epoch - 4ms/step\n",
      "Epoch 53/100\n",
      "1185/1185 - 5s - loss: 0.0127 - accuracy: 0.7850 - val_loss: 0.0105 - val_accuracy: 0.8889 - 5s/epoch - 4ms/step\n",
      "Epoch 54/100\n",
      "1185/1185 - 5s - loss: 0.0126 - accuracy: 0.7917 - val_loss: 0.0110 - val_accuracy: 0.8676 - 5s/epoch - 4ms/step\n",
      "Epoch 55/100\n",
      "1185/1185 - 5s - loss: 0.0126 - accuracy: 0.7875 - val_loss: 0.0105 - val_accuracy: 0.8875 - 5s/epoch - 4ms/step\n",
      "Epoch 56/100\n",
      "1185/1185 - 5s - loss: 0.0127 - accuracy: 0.7865 - val_loss: 0.0113 - val_accuracy: 0.8481 - 5s/epoch - 4ms/step\n",
      "Epoch 57/100\n",
      "1185/1185 - 5s - loss: 0.0126 - accuracy: 0.7911 - val_loss: 0.0127 - val_accuracy: 0.7819 - 5s/epoch - 4ms/step\n",
      "Epoch 58/100\n",
      "1185/1185 - 5s - loss: 0.0126 - accuracy: 0.7879 - val_loss: 0.0109 - val_accuracy: 0.8660 - 5s/epoch - 4ms/step\n",
      "Epoch 59/100\n",
      "1185/1185 - 5s - loss: 0.0126 - accuracy: 0.7895 - val_loss: 0.0127 - val_accuracy: 0.7788 - 5s/epoch - 4ms/step\n",
      "Epoch 60/100\n",
      "1185/1185 - 5s - loss: 0.0125 - accuracy: 0.7921 - val_loss: 0.0099 - val_accuracy: 0.9104 - 5s/epoch - 4ms/step\n",
      "Epoch 61/100\n",
      "1185/1185 - 5s - loss: 0.0124 - accuracy: 0.7978 - val_loss: 0.0157 - val_accuracy: 0.6470 - 5s/epoch - 4ms/step\n",
      "Epoch 62/100\n",
      "1185/1185 - 5s - loss: 0.0124 - accuracy: 0.7978 - val_loss: 0.0124 - val_accuracy: 0.7904 - 5s/epoch - 4ms/step\n",
      "Epoch 63/100\n",
      "1185/1185 - 5s - loss: 0.0124 - accuracy: 0.7943 - val_loss: 0.0098 - val_accuracy: 0.9215 - 5s/epoch - 4ms/step\n",
      "Epoch 64/100\n",
      "1185/1185 - 5s - loss: 0.0124 - accuracy: 0.7966 - val_loss: 0.0101 - val_accuracy: 0.9038 - 5s/epoch - 4ms/step\n",
      "Epoch 65/100\n",
      "1185/1185 - 5s - loss: 0.0124 - accuracy: 0.7969 - val_loss: 0.0105 - val_accuracy: 0.8802 - 5s/epoch - 4ms/step\n",
      "Epoch 66/100\n",
      "1185/1185 - 5s - loss: 0.0124 - accuracy: 0.7963 - val_loss: 0.0096 - val_accuracy: 0.9273 - 5s/epoch - 4ms/step\n",
      "Epoch 67/100\n",
      "1185/1185 - 5s - loss: 0.0125 - accuracy: 0.7940 - val_loss: 0.0153 - val_accuracy: 0.6772 - 5s/epoch - 4ms/step\n",
      "Epoch 68/100\n",
      "1185/1185 - 5s - loss: 0.0124 - accuracy: 0.8003 - val_loss: 0.0099 - val_accuracy: 0.9136 - 5s/epoch - 4ms/step\n",
      "Epoch 69/100\n",
      "1185/1185 - 5s - loss: 0.0124 - accuracy: 0.7990 - val_loss: 0.0132 - val_accuracy: 0.7588 - 5s/epoch - 4ms/step\n",
      "Epoch 70/100\n",
      "1185/1185 - 5s - loss: 0.0123 - accuracy: 0.8012 - val_loss: 0.0106 - val_accuracy: 0.8758 - 5s/epoch - 4ms/step\n",
      "Epoch 71/100\n",
      "1185/1185 - 5s - loss: 0.0124 - accuracy: 0.7969 - val_loss: 0.0100 - val_accuracy: 0.9067 - 5s/epoch - 4ms/step\n",
      "Epoch 72/100\n",
      "1185/1185 - 5s - loss: 0.0123 - accuracy: 0.8010 - val_loss: 0.0129 - val_accuracy: 0.7809 - 5s/epoch - 4ms/step\n",
      "Epoch 73/100\n",
      "1185/1185 - 5s - loss: 0.0123 - accuracy: 0.8053 - val_loss: 0.0109 - val_accuracy: 0.8588 - 5s/epoch - 4ms/step\n",
      "Epoch 74/100\n",
      "1185/1185 - 5s - loss: 0.0123 - accuracy: 0.8027 - val_loss: 0.0143 - val_accuracy: 0.7251 - 5s/epoch - 4ms/step\n",
      "Epoch 75/100\n",
      "1185/1185 - 6s - loss: 0.0123 - accuracy: 0.8016 - val_loss: 0.0121 - val_accuracy: 0.8181 - 6s/epoch - 5ms/step\n",
      "Epoch 76/100\n",
      "1185/1185 - 5s - loss: 0.0122 - accuracy: 0.8075 - val_loss: 0.0180 - val_accuracy: 0.5974 - 5s/epoch - 4ms/step\n",
      "Epoch 77/100\n",
      "1185/1185 - 5s - loss: 0.0122 - accuracy: 0.8048 - val_loss: 0.0127 - val_accuracy: 0.7885 - 5s/epoch - 4ms/step\n",
      "Epoch 78/100\n",
      "1185/1185 - 5s - loss: 0.0122 - accuracy: 0.8081 - val_loss: 0.0108 - val_accuracy: 0.8738 - 5s/epoch - 4ms/step\n",
      "Epoch 79/100\n",
      "1185/1185 - 5s - loss: 0.0122 - accuracy: 0.8042 - val_loss: 0.0106 - val_accuracy: 0.8808 - 5s/epoch - 4ms/step\n",
      "Epoch 80/100\n",
      "1185/1185 - 5s - loss: 0.0122 - accuracy: 0.8054 - val_loss: 0.0140 - val_accuracy: 0.7281 - 5s/epoch - 4ms/step\n",
      "Epoch 81/100\n",
      "1185/1185 - 5s - loss: 0.0121 - accuracy: 0.8087 - val_loss: 0.0141 - val_accuracy: 0.7317 - 5s/epoch - 5ms/step\n",
      "Epoch 82/100\n",
      "1185/1185 - 5s - loss: 0.0121 - accuracy: 0.8112 - val_loss: 0.0109 - val_accuracy: 0.8630 - 5s/epoch - 4ms/step\n",
      "Epoch 83/100\n",
      "1185/1185 - 5s - loss: 0.0122 - accuracy: 0.8074 - val_loss: 0.0100 - val_accuracy: 0.9050 - 5s/epoch - 4ms/step\n",
      "Epoch 84/100\n",
      "1185/1185 - 5s - loss: 0.0121 - accuracy: 0.8096 - val_loss: 0.0100 - val_accuracy: 0.9109 - 5s/epoch - 4ms/step\n",
      "Epoch 85/100\n",
      "1185/1185 - 5s - loss: 0.0122 - accuracy: 0.8069 - val_loss: 0.0100 - val_accuracy: 0.9086 - 5s/epoch - 4ms/step\n",
      "Epoch 86/100\n",
      "1185/1185 - 5s - loss: 0.0121 - accuracy: 0.8121 - val_loss: 0.0115 - val_accuracy: 0.8278 - 5s/epoch - 4ms/step\n",
      "Epoch 87/100\n",
      "1185/1185 - 5s - loss: 0.0121 - accuracy: 0.8089 - val_loss: 0.0151 - val_accuracy: 0.6983 - 5s/epoch - 4ms/step\n",
      "Epoch 88/100\n",
      "1185/1185 - 5s - loss: 0.0121 - accuracy: 0.8085 - val_loss: 0.0117 - val_accuracy: 0.8219 - 5s/epoch - 4ms/step\n",
      "Epoch 89/100\n",
      "1185/1185 - 5s - loss: 0.0122 - accuracy: 0.8043 - val_loss: 0.0105 - val_accuracy: 0.8889 - 5s/epoch - 4ms/step\n",
      "Epoch 90/100\n",
      "1185/1185 - 5s - loss: 0.0121 - accuracy: 0.8104 - val_loss: 0.0117 - val_accuracy: 0.8183 - 5s/epoch - 4ms/step\n",
      "Epoch 91/100\n",
      "1185/1185 - 5s - loss: 0.0121 - accuracy: 0.8125 - val_loss: 0.0100 - val_accuracy: 0.9116 - 5s/epoch - 4ms/step\n",
      "Epoch 92/100\n",
      "1185/1185 - 5s - loss: 0.0120 - accuracy: 0.8157 - val_loss: 0.0107 - val_accuracy: 0.8710 - 5s/epoch - 4ms/step\n",
      "Epoch 93/100\n",
      "1185/1185 - 5s - loss: 0.0119 - accuracy: 0.8176 - val_loss: 0.0106 - val_accuracy: 0.8778 - 5s/epoch - 4ms/step\n",
      "Epoch 94/100\n",
      "1185/1185 - 5s - loss: 0.0121 - accuracy: 0.8078 - val_loss: 0.0112 - val_accuracy: 0.8494 - 5s/epoch - 4ms/step\n",
      "Epoch 95/100\n",
      "1185/1185 - 5s - loss: 0.0121 - accuracy: 0.8125 - val_loss: 0.0113 - val_accuracy: 0.8412 - 5s/epoch - 4ms/step\n",
      "Epoch 96/100\n",
      "1185/1185 - 5s - loss: 0.0120 - accuracy: 0.8148 - val_loss: 0.0096 - val_accuracy: 0.9249 - 5s/epoch - 4ms/step\n",
      "Epoch 97/100\n",
      "1185/1185 - 5s - loss: 0.0119 - accuracy: 0.8182 - val_loss: 0.0104 - val_accuracy: 0.8923 - 5s/epoch - 4ms/step\n",
      "Epoch 98/100\n",
      "1185/1185 - 5s - loss: 0.0120 - accuracy: 0.8178 - val_loss: 0.0126 - val_accuracy: 0.7865 - 5s/epoch - 4ms/step\n",
      "Epoch 99/100\n",
      "1185/1185 - 5s - loss: 0.0119 - accuracy: 0.8220 - val_loss: 0.0104 - val_accuracy: 0.8906 - 5s/epoch - 4ms/step\n",
      "Epoch 100/100\n",
      "1185/1185 - 5s - loss: 0.0119 - accuracy: 0.8171 - val_loss: 0.0172 - val_accuracy: 0.6455 - 5s/epoch - 4ms/step\n",
      "Restored model, train accuracy: 66.03%\n",
      "Restored model, valid accuracy: 64.55%\n",
      "Restored model, new_test accuracy: 63.70%\n",
      "Restored model, test accuracy: 55.69%\n"
     ]
    }
   ],
   "source": [
    "network = build_NeuralNetwork()\n",
    "print('Model built.')\n",
    "modelname = 'ann1'\n",
    "checkpointer = ModelCheckpoint(filepath = modelname+'.hdf5', verbose = 0, save_best_only = True)\n",
    "\n",
    "history = network.fit(train_images_array, train_hot_class,\n",
    "    batch_size = 32, #32\n",
    "    epochs = 100, #15\n",
    "    validation_data = (valid_images_array, valid_hot_class),\n",
    "    verbose = 2,\n",
    "    callbacks=[checkpointer],\n",
    "    shuffle = True)\n",
    "\n",
    "network.save('model_'+modelname+'.h5')\n",
    "\n",
    "train_loss, train_acc = network.evaluate(train_images_array, train_hot_class, verbose=0)\n",
    "print('Restored model, train accuracy: {:5.2f}%'.format(100 * train_acc))\n",
    "valid_loss, valid_acc = network.evaluate(valid_images_array, valid_hot_class, verbose=0)\n",
    "print('Restored model, valid accuracy: {:5.2f}%'.format(100 * valid_acc))\n",
    "new_test_loss, new_test_acc = network.evaluate(new_test_images_array, new_test_hot_class, verbose=0)\n",
    "print('Restored model, new_test accuracy: {:5.2f}%'.format(100 * new_test_acc))\n",
    "test_loss, test_acc = network.evaluate(test_images_array, test_hot_class, verbose=0)\n",
    "print('Restored model, test accuracy: {:5.2f}%'.format(100 * test_acc))\n",
    "np.save(modelname+'_history.npy',history.history)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [
    "def build_NeuralNetwork():\n",
    "\n",
    "    #input layer\n",
    "    model = Sequential()\n",
    "    model.add(Input(shape=(100,100,3)))\n",
    "    model.add(Flatten())\n",
    "\n",
    "    #hiddenlayer 1\n",
    "    model.add(Dense(5))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation(activation='sigmoid'))\n",
    "\n",
    "    #hiddenlayer 2\n",
    "    model.add(Dense(50)) #900\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation(activation='sigmoid'))\n",
    "    model.add(Dropout(0.25))\n",
    "\n",
    "    #hiddenlayer 3\n",
    "    model.add(Dense(50)) #900\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation(activation='sigmoid'))\n",
    "    model.add(Dropout(0.25))\n",
    "\n",
    "    #hiddenlayer 4\n",
    "    #model.add(Dense(300)) #900\n",
    "    #model.add(BatchNormalization())\n",
    "    #model.add(Activation(activation='relu'))\n",
    "    #model.add(Dropout(0.25))\n",
    "\n",
    "    #output layer\n",
    "    model.add(Dense(131,activation=\"softmax\"))\n",
    "\n",
    "    model.compile(loss = 'poisson', optimizer = \"adam\", metrics = ['accuracy'])\n",
    "    print('Compiled!')\n",
    "\n",
    "    return model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compiled!\n",
      "Model built.\n",
      "Epoch 1/100\n",
      "1185/1185 - 9s - loss: 0.0399 - accuracy: 0.0733 - val_loss: 0.0360 - val_accuracy: 0.0956 - 9s/epoch - 8ms/step\n",
      "Epoch 2/100\n",
      "1185/1185 - 5s - loss: 0.0312 - accuracy: 0.2245 - val_loss: 0.0276 - val_accuracy: 0.2932 - 5s/epoch - 5ms/step\n",
      "Epoch 3/100\n",
      "1185/1185 - 6s - loss: 0.0261 - accuracy: 0.3448 - val_loss: 0.0217 - val_accuracy: 0.5902 - 6s/epoch - 5ms/step\n",
      "Epoch 4/100\n",
      "1185/1185 - 6s - loss: 0.0231 - accuracy: 0.4283 - val_loss: 0.0195 - val_accuracy: 0.6176 - 6s/epoch - 5ms/step\n",
      "Epoch 5/100\n",
      "1185/1185 - 5s - loss: 0.0211 - accuracy: 0.4890 - val_loss: 0.0273 - val_accuracy: 0.2688 - 5s/epoch - 5ms/step\n",
      "Epoch 6/100\n",
      "1185/1185 - 6s - loss: 0.0199 - accuracy: 0.5285 - val_loss: 0.0166 - val_accuracy: 0.6859 - 6s/epoch - 5ms/step\n",
      "Epoch 7/100\n",
      "1185/1185 - 5s - loss: 0.0190 - accuracy: 0.5574 - val_loss: 0.0157 - val_accuracy: 0.7210 - 5s/epoch - 5ms/step\n",
      "Epoch 8/100\n",
      "1185/1185 - 5s - loss: 0.0183 - accuracy: 0.5795 - val_loss: 0.0163 - val_accuracy: 0.6780 - 5s/epoch - 5ms/step\n",
      "Epoch 9/100\n",
      "1185/1185 - 5s - loss: 0.0177 - accuracy: 0.6001 - val_loss: 0.0145 - val_accuracy: 0.7554 - 5s/epoch - 5ms/step\n",
      "Epoch 10/100\n",
      "1185/1185 - 6s - loss: 0.0173 - accuracy: 0.6100 - val_loss: 0.0131 - val_accuracy: 0.8469 - 6s/epoch - 5ms/step\n",
      "Epoch 11/100\n",
      "1185/1185 - 5s - loss: 0.0168 - accuracy: 0.6326 - val_loss: 0.0129 - val_accuracy: 0.8428 - 5s/epoch - 5ms/step\n",
      "Epoch 12/100\n",
      "1185/1185 - 5s - loss: 0.0166 - accuracy: 0.6420 - val_loss: 0.0136 - val_accuracy: 0.7800 - 5s/epoch - 5ms/step\n",
      "Epoch 13/100\n",
      "1185/1185 - 5s - loss: 0.0162 - accuracy: 0.6541 - val_loss: 0.0136 - val_accuracy: 0.7910 - 5s/epoch - 5ms/step\n",
      "Epoch 14/100\n",
      "1185/1185 - 5s - loss: 0.0160 - accuracy: 0.6614 - val_loss: 0.0139 - val_accuracy: 0.7480 - 5s/epoch - 5ms/step\n",
      "Epoch 15/100\n",
      "1185/1185 - 5s - loss: 0.0158 - accuracy: 0.6694 - val_loss: 0.0132 - val_accuracy: 0.7855 - 5s/epoch - 4ms/step\n",
      "Epoch 16/100\n",
      "1185/1185 - 6s - loss: 0.0156 - accuracy: 0.6766 - val_loss: 0.0121 - val_accuracy: 0.8551 - 6s/epoch - 5ms/step\n",
      "Epoch 17/100\n",
      "1185/1185 - 6s - loss: 0.0154 - accuracy: 0.6865 - val_loss: 0.0121 - val_accuracy: 0.8552 - 6s/epoch - 5ms/step\n",
      "Epoch 18/100\n",
      "1185/1185 - 6s - loss: 0.0153 - accuracy: 0.6853 - val_loss: 0.0128 - val_accuracy: 0.8092 - 6s/epoch - 5ms/step\n",
      "Epoch 19/100\n",
      "1185/1185 - 6s - loss: 0.0151 - accuracy: 0.6939 - val_loss: 0.0120 - val_accuracy: 0.8463 - 6s/epoch - 5ms/step\n",
      "Epoch 20/100\n",
      "1185/1185 - 6s - loss: 0.0149 - accuracy: 0.6995 - val_loss: 0.0119 - val_accuracy: 0.8472 - 6s/epoch - 5ms/step\n",
      "Epoch 21/100\n",
      "1185/1185 - 6s - loss: 0.0148 - accuracy: 0.7052 - val_loss: 0.0126 - val_accuracy: 0.8071 - 6s/epoch - 5ms/step\n",
      "Epoch 22/100\n",
      "1185/1185 - 5s - loss: 0.0147 - accuracy: 0.7103 - val_loss: 0.0147 - val_accuracy: 0.6985 - 5s/epoch - 5ms/step\n",
      "Epoch 23/100\n",
      "1185/1185 - 5s - loss: 0.0145 - accuracy: 0.7160 - val_loss: 0.0112 - val_accuracy: 0.8858 - 5s/epoch - 5ms/step\n",
      "Epoch 24/100\n",
      "1185/1185 - 5s - loss: 0.0145 - accuracy: 0.7139 - val_loss: 0.0117 - val_accuracy: 0.8555 - 5s/epoch - 5ms/step\n",
      "Epoch 25/100\n",
      "1185/1185 - 5s - loss: 0.0145 - accuracy: 0.7160 - val_loss: 0.0111 - val_accuracy: 0.8835 - 5s/epoch - 5ms/step\n",
      "Epoch 26/100\n",
      "1185/1185 - 5s - loss: 0.0144 - accuracy: 0.7193 - val_loss: 0.0112 - val_accuracy: 0.8800 - 5s/epoch - 5ms/step\n",
      "Epoch 27/100\n",
      "1185/1185 - 6s - loss: 0.0143 - accuracy: 0.7238 - val_loss: 0.0117 - val_accuracy: 0.8482 - 6s/epoch - 5ms/step\n",
      "Epoch 28/100\n",
      "1185/1185 - 6s - loss: 0.0142 - accuracy: 0.7258 - val_loss: 0.0107 - val_accuracy: 0.9032 - 6s/epoch - 5ms/step\n",
      "Epoch 29/100\n",
      "1185/1185 - 5s - loss: 0.0142 - accuracy: 0.7285 - val_loss: 0.0119 - val_accuracy: 0.8284 - 5s/epoch - 5ms/step\n",
      "Epoch 30/100\n",
      "1185/1185 - 5s - loss: 0.0141 - accuracy: 0.7317 - val_loss: 0.0129 - val_accuracy: 0.7708 - 5s/epoch - 5ms/step\n",
      "Epoch 31/100\n",
      "1185/1185 - 5s - loss: 0.0140 - accuracy: 0.7352 - val_loss: 0.0125 - val_accuracy: 0.7974 - 5s/epoch - 5ms/step\n",
      "Epoch 32/100\n",
      "1185/1185 - 5s - loss: 0.0138 - accuracy: 0.7390 - val_loss: 0.0130 - val_accuracy: 0.7742 - 5s/epoch - 5ms/step\n",
      "Epoch 33/100\n",
      "1185/1185 - 5s - loss: 0.0139 - accuracy: 0.7375 - val_loss: 0.0124 - val_accuracy: 0.8049 - 5s/epoch - 4ms/step\n",
      "Epoch 34/100\n",
      "1185/1185 - 5s - loss: 0.0138 - accuracy: 0.7402 - val_loss: 0.0115 - val_accuracy: 0.8483 - 5s/epoch - 5ms/step\n",
      "Epoch 35/100\n",
      "1185/1185 - 6s - loss: 0.0138 - accuracy: 0.7438 - val_loss: 0.0116 - val_accuracy: 0.8425 - 6s/epoch - 5ms/step\n",
      "Epoch 36/100\n",
      "1185/1185 - 5s - loss: 0.0136 - accuracy: 0.7495 - val_loss: 0.0113 - val_accuracy: 0.8585 - 5s/epoch - 5ms/step\n",
      "Epoch 37/100\n",
      "1185/1185 - 5s - loss: 0.0137 - accuracy: 0.7460 - val_loss: 0.0133 - val_accuracy: 0.7626 - 5s/epoch - 4ms/step\n",
      "Epoch 38/100\n",
      "1185/1185 - 5s - loss: 0.0136 - accuracy: 0.7542 - val_loss: 0.0132 - val_accuracy: 0.7577 - 5s/epoch - 5ms/step\n",
      "Epoch 39/100\n",
      "1185/1185 - 5s - loss: 0.0136 - accuracy: 0.7526 - val_loss: 0.0169 - val_accuracy: 0.5963 - 5s/epoch - 5ms/step\n",
      "Epoch 40/100\n",
      "1185/1185 - 5s - loss: 0.0135 - accuracy: 0.7591 - val_loss: 0.0126 - val_accuracy: 0.7774 - 5s/epoch - 5ms/step\n",
      "Epoch 41/100\n",
      "1185/1185 - 5s - loss: 0.0134 - accuracy: 0.7567 - val_loss: 0.0118 - val_accuracy: 0.8293 - 5s/epoch - 4ms/step\n",
      "Epoch 42/100\n",
      "1185/1185 - 5s - loss: 0.0135 - accuracy: 0.7584 - val_loss: 0.0107 - val_accuracy: 0.8874 - 5s/epoch - 5ms/step\n",
      "Epoch 43/100\n",
      "1185/1185 - 5s - loss: 0.0134 - accuracy: 0.7577 - val_loss: 0.0136 - val_accuracy: 0.7329 - 5s/epoch - 4ms/step\n",
      "Epoch 44/100\n",
      "1185/1185 - 5s - loss: 0.0133 - accuracy: 0.7621 - val_loss: 0.0112 - val_accuracy: 0.8573 - 5s/epoch - 4ms/step\n",
      "Epoch 45/100\n",
      "1185/1185 - 5s - loss: 0.0134 - accuracy: 0.7593 - val_loss: 0.0111 - val_accuracy: 0.8625 - 5s/epoch - 5ms/step\n",
      "Epoch 46/100\n",
      "1185/1185 - 5s - loss: 0.0133 - accuracy: 0.7612 - val_loss: 0.0168 - val_accuracy: 0.6325 - 5s/epoch - 4ms/step\n",
      "Epoch 47/100\n",
      "1185/1185 - 5s - loss: 0.0133 - accuracy: 0.7601 - val_loss: 0.0102 - val_accuracy: 0.9087 - 5s/epoch - 5ms/step\n",
      "Epoch 48/100\n",
      "1185/1185 - 5s - loss: 0.0133 - accuracy: 0.7634 - val_loss: 0.0101 - val_accuracy: 0.9138 - 5s/epoch - 5ms/step\n",
      "Epoch 49/100\n",
      "1185/1185 - 5s - loss: 0.0132 - accuracy: 0.7647 - val_loss: 0.0103 - val_accuracy: 0.9044 - 5s/epoch - 5ms/step\n",
      "Epoch 50/100\n",
      "1185/1185 - 5s - loss: 0.0132 - accuracy: 0.7682 - val_loss: 0.0111 - val_accuracy: 0.8630 - 5s/epoch - 5ms/step\n",
      "Epoch 51/100\n",
      "1185/1185 - 5s - loss: 0.0130 - accuracy: 0.7720 - val_loss: 0.0111 - val_accuracy: 0.8670 - 5s/epoch - 4ms/step\n",
      "Epoch 52/100\n",
      "1185/1185 - 5s - loss: 0.0131 - accuracy: 0.7705 - val_loss: 0.0099 - val_accuracy: 0.9243 - 5s/epoch - 5ms/step\n",
      "Epoch 53/100\n",
      "1185/1185 - 5s - loss: 0.0132 - accuracy: 0.7666 - val_loss: 0.0103 - val_accuracy: 0.9072 - 5s/epoch - 5ms/step\n",
      "Epoch 54/100\n",
      "1185/1185 - 5s - loss: 0.0130 - accuracy: 0.7725 - val_loss: 0.0105 - val_accuracy: 0.8883 - 5s/epoch - 5ms/step\n",
      "Epoch 55/100\n",
      "1185/1185 - 5s - loss: 0.0130 - accuracy: 0.7746 - val_loss: 0.0103 - val_accuracy: 0.9043 - 5s/epoch - 5ms/step\n",
      "Epoch 56/100\n",
      "1185/1185 - 5s - loss: 0.0130 - accuracy: 0.7757 - val_loss: 0.0106 - val_accuracy: 0.8844 - 5s/epoch - 4ms/step\n",
      "Epoch 57/100\n",
      "1185/1185 - 5s - loss: 0.0130 - accuracy: 0.7739 - val_loss: 0.0135 - val_accuracy: 0.7495 - 5s/epoch - 5ms/step\n",
      "Epoch 58/100\n",
      "1185/1185 - 5s - loss: 0.0130 - accuracy: 0.7732 - val_loss: 0.0112 - val_accuracy: 0.8562 - 5s/epoch - 5ms/step\n",
      "Epoch 59/100\n",
      "1185/1185 - 5s - loss: 0.0129 - accuracy: 0.7774 - val_loss: 0.0111 - val_accuracy: 0.8560 - 5s/epoch - 5ms/step\n",
      "Epoch 60/100\n",
      "1185/1185 - 5s - loss: 0.0129 - accuracy: 0.7744 - val_loss: 0.0111 - val_accuracy: 0.8625 - 5s/epoch - 4ms/step\n",
      "Epoch 61/100\n",
      "1185/1185 - 5s - loss: 0.0128 - accuracy: 0.7825 - val_loss: 0.0103 - val_accuracy: 0.8964 - 5s/epoch - 5ms/step\n",
      "Epoch 62/100\n",
      "1185/1185 - 5s - loss: 0.0129 - accuracy: 0.7786 - val_loss: 0.0138 - val_accuracy: 0.7433 - 5s/epoch - 5ms/step\n",
      "Epoch 63/100\n",
      "1185/1185 - 5s - loss: 0.0128 - accuracy: 0.7808 - val_loss: 0.0114 - val_accuracy: 0.8465 - 5s/epoch - 4ms/step\n",
      "Epoch 64/100\n",
      "1185/1185 - 5s - loss: 0.0129 - accuracy: 0.7788 - val_loss: 0.0113 - val_accuracy: 0.8493 - 5s/epoch - 5ms/step\n",
      "Epoch 65/100\n",
      "1185/1185 - 5s - loss: 0.0129 - accuracy: 0.7813 - val_loss: 0.0103 - val_accuracy: 0.8968 - 5s/epoch - 4ms/step\n",
      "Epoch 66/100\n",
      "1185/1185 - 5s - loss: 0.0127 - accuracy: 0.7861 - val_loss: 0.0122 - val_accuracy: 0.8111 - 5s/epoch - 5ms/step\n",
      "Epoch 67/100\n",
      "1185/1185 - 5s - loss: 0.0127 - accuracy: 0.7879 - val_loss: 0.0102 - val_accuracy: 0.9045 - 5s/epoch - 5ms/step\n",
      "Epoch 68/100\n",
      "1185/1185 - 5s - loss: 0.0127 - accuracy: 0.7879 - val_loss: 0.0106 - val_accuracy: 0.8854 - 5s/epoch - 5ms/step\n",
      "Epoch 69/100\n",
      "1185/1185 - 8s - loss: 0.0127 - accuracy: 0.7845 - val_loss: 0.0097 - val_accuracy: 0.9271 - 8s/epoch - 6ms/step\n",
      "Epoch 70/100\n",
      "1185/1185 - 7s - loss: 0.0127 - accuracy: 0.7861 - val_loss: 0.0104 - val_accuracy: 0.8962 - 7s/epoch - 6ms/step\n",
      "Epoch 71/100\n",
      "1185/1185 - 6s - loss: 0.0128 - accuracy: 0.7816 - val_loss: 0.0101 - val_accuracy: 0.9075 - 6s/epoch - 5ms/step\n",
      "Epoch 72/100\n",
      "1185/1185 - 6s - loss: 0.0126 - accuracy: 0.7908 - val_loss: 0.0117 - val_accuracy: 0.8274 - 6s/epoch - 5ms/step\n",
      "Epoch 73/100\n",
      "1185/1185 - 6s - loss: 0.0126 - accuracy: 0.7859 - val_loss: 0.0097 - val_accuracy: 0.9244 - 6s/epoch - 5ms/step\n",
      "Epoch 74/100\n",
      "1185/1185 - 6s - loss: 0.0127 - accuracy: 0.7882 - val_loss: 0.0155 - val_accuracy: 0.6727 - 6s/epoch - 5ms/step\n",
      "Epoch 75/100\n",
      "1185/1185 - 7s - loss: 0.0126 - accuracy: 0.7872 - val_loss: 0.0102 - val_accuracy: 0.9027 - 7s/epoch - 6ms/step\n",
      "Epoch 76/100\n",
      "1185/1185 - 6s - loss: 0.0126 - accuracy: 0.7897 - val_loss: 0.0110 - val_accuracy: 0.8570 - 6s/epoch - 5ms/step\n",
      "Epoch 77/100\n",
      "1185/1185 - 6s - loss: 0.0126 - accuracy: 0.7924 - val_loss: 0.0107 - val_accuracy: 0.8820 - 6s/epoch - 5ms/step\n",
      "Epoch 78/100\n",
      "1185/1185 - 6s - loss: 0.0126 - accuracy: 0.7889 - val_loss: 0.0112 - val_accuracy: 0.8447 - 6s/epoch - 5ms/step\n",
      "Epoch 79/100\n",
      "1185/1185 - 6s - loss: 0.0126 - accuracy: 0.7910 - val_loss: 0.0105 - val_accuracy: 0.8874 - 6s/epoch - 5ms/step\n",
      "Epoch 80/100\n",
      "1185/1185 - 6s - loss: 0.0125 - accuracy: 0.7938 - val_loss: 0.0101 - val_accuracy: 0.9056 - 6s/epoch - 5ms/step\n",
      "Epoch 81/100\n",
      "1185/1185 - 6s - loss: 0.0125 - accuracy: 0.7911 - val_loss: 0.0107 - val_accuracy: 0.8736 - 6s/epoch - 5ms/step\n",
      "Epoch 82/100\n",
      "1185/1185 - 5s - loss: 0.0126 - accuracy: 0.7920 - val_loss: 0.0159 - val_accuracy: 0.6582 - 5s/epoch - 5ms/step\n",
      "Epoch 83/100\n",
      "1185/1185 - 5s - loss: 0.0124 - accuracy: 0.7971 - val_loss: 0.0101 - val_accuracy: 0.9152 - 5s/epoch - 5ms/step\n",
      "Epoch 84/100\n",
      "1185/1185 - 5s - loss: 0.0124 - accuracy: 0.7952 - val_loss: 0.0101 - val_accuracy: 0.9014 - 5s/epoch - 5ms/step\n",
      "Epoch 85/100\n",
      "1185/1185 - 5s - loss: 0.0125 - accuracy: 0.7952 - val_loss: 0.0107 - val_accuracy: 0.8763 - 5s/epoch - 5ms/step\n",
      "Epoch 86/100\n",
      "1185/1185 - 5s - loss: 0.0124 - accuracy: 0.7997 - val_loss: 0.0104 - val_accuracy: 0.8861 - 5s/epoch - 5ms/step\n",
      "Epoch 87/100\n",
      "1185/1185 - 5s - loss: 0.0124 - accuracy: 0.7985 - val_loss: 0.0107 - val_accuracy: 0.8720 - 5s/epoch - 5ms/step\n",
      "Epoch 88/100\n",
      "1185/1185 - 6s - loss: 0.0125 - accuracy: 0.7965 - val_loss: 0.0098 - val_accuracy: 0.9195 - 6s/epoch - 5ms/step\n",
      "Epoch 89/100\n",
      "1185/1185 - 6s - loss: 0.0125 - accuracy: 0.7951 - val_loss: 0.0200 - val_accuracy: 0.5346 - 6s/epoch - 5ms/step\n",
      "Epoch 90/100\n",
      "1185/1185 - 6s - loss: 0.0123 - accuracy: 0.8006 - val_loss: 0.0109 - val_accuracy: 0.8629 - 6s/epoch - 5ms/step\n",
      "Epoch 91/100\n",
      "1185/1185 - 5s - loss: 0.0124 - accuracy: 0.7953 - val_loss: 0.0137 - val_accuracy: 0.7305 - 5s/epoch - 5ms/step\n",
      "Epoch 92/100\n",
      "1185/1185 - 5s - loss: 0.0123 - accuracy: 0.7997 - val_loss: 0.0120 - val_accuracy: 0.8000 - 5s/epoch - 5ms/step\n",
      "Epoch 93/100\n",
      "1185/1185 - 5s - loss: 0.0123 - accuracy: 0.8009 - val_loss: 0.0116 - val_accuracy: 0.8246 - 5s/epoch - 5ms/step\n",
      "Epoch 94/100\n",
      "1185/1185 - 5s - loss: 0.0123 - accuracy: 0.8025 - val_loss: 0.0119 - val_accuracy: 0.8115 - 5s/epoch - 5ms/step\n",
      "Epoch 95/100\n",
      "1185/1185 - 5s - loss: 0.0123 - accuracy: 0.8032 - val_loss: 0.0102 - val_accuracy: 0.8954 - 5s/epoch - 5ms/step\n",
      "Epoch 96/100\n",
      "1185/1185 - 5s - loss: 0.0123 - accuracy: 0.8006 - val_loss: 0.0099 - val_accuracy: 0.9184 - 5s/epoch - 5ms/step\n",
      "Epoch 97/100\n",
      "1185/1185 - 5s - loss: 0.0124 - accuracy: 0.8008 - val_loss: 0.0114 - val_accuracy: 0.8402 - 5s/epoch - 5ms/step\n",
      "Epoch 98/100\n",
      "1185/1185 - 5s - loss: 0.0122 - accuracy: 0.8036 - val_loss: 0.0106 - val_accuracy: 0.8834 - 5s/epoch - 5ms/step\n",
      "Epoch 99/100\n",
      "1185/1185 - 5s - loss: 0.0123 - accuracy: 0.8035 - val_loss: 0.0102 - val_accuracy: 0.8964 - 5s/epoch - 5ms/step\n",
      "Epoch 100/100\n",
      "1185/1185 - 5s - loss: 0.0123 - accuracy: 0.8041 - val_loss: 0.0099 - val_accuracy: 0.9146 - 5s/epoch - 5ms/step\n",
      "Restored model, train accuracy: 94.81%\n",
      "Restored model, valid accuracy: 91.46%\n",
      "Restored model, new_test accuracy: 91.81%\n",
      "Restored model, test accuracy: 73.68%\n"
     ]
    }
   ],
   "source": [
    "network = build_NeuralNetwork()\n",
    "print('Model built.')\n",
    "modelname = 'ann1'\n",
    "checkpointer = ModelCheckpoint(filepath = modelname+'.hdf5', verbose = 0, save_best_only = True)\n",
    "\n",
    "history = network.fit(train_images_array, train_hot_class,\n",
    "    batch_size = 32, #32\n",
    "    epochs = 100, #15\n",
    "    validation_data = (valid_images_array, valid_hot_class),\n",
    "    verbose = 2,\n",
    "    callbacks=[checkpointer],\n",
    "    shuffle = True)\n",
    "\n",
    "network.save('model_'+modelname+'.h5')\n",
    "\n",
    "train_loss, train_acc = network.evaluate(train_images_array, train_hot_class, verbose=0)\n",
    "print('Restored model, train accuracy: {:5.2f}%'.format(100 * train_acc))\n",
    "valid_loss, valid_acc = network.evaluate(valid_images_array, valid_hot_class, verbose=0)\n",
    "print('Restored model, valid accuracy: {:5.2f}%'.format(100 * valid_acc))\n",
    "new_test_loss, new_test_acc = network.evaluate(new_test_images_array, new_test_hot_class, verbose=0)\n",
    "print('Restored model, new_test accuracy: {:5.2f}%'.format(100 * new_test_acc))\n",
    "test_loss, test_acc = network.evaluate(test_images_array, test_hot_class, verbose=0)\n",
    "print('Restored model, test accuracy: {:5.2f}%'.format(100 * test_acc))\n",
    "np.save(modelname+'_history.npy',history.history)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "train_hot_class = np_utils.to_categorical(intclass_train, n_classes)\n",
    "test_hot_class = np_utils.to_categorical(intclass_test, n_classes)\n",
    "\n",
    "train_images_array = np.array(convert_image_to_array(names_train))\n",
    "test_images_array = np.array(convert_image_to_array(names_test))\n",
    "\n",
    "train_images_array = train_images_array.astype('float32')/255\n",
    "test_images_array = test_images_array.astype('float32')/255\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "#split training into another training and test (to reduce computation resources/time)\n",
    "train_images_array, new_test_images_array, train_hot_class, new_test_hot_class = train_test_split(train_images_array, train_hot_class, test_size = 0.3, random_state = 42)\n",
    "\n",
    "train_images_array, valid_images_array, train_hot_class, valid_hot_class = train_test_split(train_images_array, train_hot_class, test_size = 0.2)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def build_NeuralNetwork():\n",
    "\n",
    "    #input layer\n",
    "    model = Sequential()\n",
    "    model.add(Input(shape=(100,100,3)))\n",
    "    model.add(Flatten())\n",
    "\n",
    "    #hiddenlayer 1\n",
    "    model.add(Dense(5))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation(activation='relu'))\n",
    "\n",
    "    #hiddenlayer 2\n",
    "    model.add(Dense(50)) #900\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation(activation='relu'))\n",
    "    #model.add(Dropout(0.25))\n",
    "\n",
    "    #hiddenlayer 3\n",
    "    model.add(Dense(50)) #900\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation(activation='relu'))\n",
    "    #model.add(Dropout(0.25))\n",
    "\n",
    "    #hiddenlayer 4\n",
    "    #model.add(Dense(300)) #900\n",
    "    #model.add(BatchNormalization())\n",
    "    #model.add(Activation(activation='relu'))\n",
    "    #model.add(Dropout(0.25))\n",
    "\n",
    "    #output layer\n",
    "    model.add(Dense(131,activation=\"softmax\"))\n",
    "\n",
    "    model.compile(loss = 'poisson', optimizer = \"adam\", metrics = ['accuracy'])\n",
    "    print('Compiled!')\n",
    "\n",
    "    return model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "network = build_NeuralNetwork()\n",
    "print('Model built.')\n",
    "modelname = 'ann1'\n",
    "checkpointer = ModelCheckpoint(filepath = modelname+'.hdf5', verbose = 0, save_best_only = True)\n",
    "\n",
    "history = network.fit(train_images_array, train_hot_class,\n",
    "    batch_size = 32, #32\n",
    "    epochs = 100, #15\n",
    "    validation_data = (valid_images_array, valid_hot_class),\n",
    "    verbose = 2,\n",
    "    callbacks=[checkpointer],\n",
    "    shuffle = True)\n",
    "\n",
    "network.save('model_'+modelname+'.h5')\n",
    "\n",
    "train_loss, train_acc = network.evaluate(train_images_array, train_hot_class, verbose=0)\n",
    "print('Restored model, train accuracy: {:5.2f}%'.format(100 * train_acc))\n",
    "valid_loss, valid_acc = network.evaluate(valid_images_array, valid_hot_class, verbose=0)\n",
    "print('Restored model, valid accuracy: {:5.2f}%'.format(100 * valid_acc))\n",
    "new_test_loss, new_test_acc = network.evaluate(new_test_images_array, new_test_hot_class, verbose=0)\n",
    "print('Restored model, new_test accuracy: {:5.2f}%'.format(100 * new_test_acc))\n",
    "test_loss, test_acc = network.evaluate(test_images_array, test_hot_class, verbose=0)\n",
    "print('Restored model, test accuracy: {:5.2f}%'.format(100 * test_acc))\n",
    "np.save(modelname+'_history.npy',history.history)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def build_NeuralNetwork():\n",
    "\n",
    "    #input layer\n",
    "    model = Sequential()\n",
    "    model.add(Input(shape=(100,100,3)))\n",
    "    model.add(Flatten())\n",
    "\n",
    "    #hiddenlayer 1\n",
    "    model.add(Dense(5))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation(activation='tanh'))\n",
    "\n",
    "    #hiddenlayer 2\n",
    "    model.add(Dense(50)) #900\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation(activation='tanh'))\n",
    "    #model.add(Dropout(0.25))\n",
    "\n",
    "    #hiddenlayer 3\n",
    "    model.add(Dense(50)) #900\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation(activation='tanh'))\n",
    "    #model.add(Dropout(0.25))\n",
    "\n",
    "    #hiddenlayer 4\n",
    "    #model.add(Dense(300)) #900\n",
    "    #model.add(BatchNormalization())\n",
    "    #model.add(Activation(activation='relu'))\n",
    "    #model.add(Dropout(0.25))\n",
    "\n",
    "    #output layer\n",
    "    model.add(Dense(131,activation=\"softmax\"))\n",
    "\n",
    "    model.compile(loss = 'poisson', optimizer = \"adam\", metrics = ['accuracy'])\n",
    "    print('Compiled!')\n",
    "\n",
    "    return model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "network = build_NeuralNetwork()\n",
    "print('Model built.')\n",
    "modelname = 'ann1'\n",
    "checkpointer = ModelCheckpoint(filepath = modelname+'.hdf5', verbose = 0, save_best_only = True)\n",
    "\n",
    "history = network.fit(train_images_array, train_hot_class,\n",
    "    batch_size = 32, #32\n",
    "    epochs = 100, #15\n",
    "    validation_data = (valid_images_array, valid_hot_class),\n",
    "    verbose = 2,\n",
    "    callbacks=[checkpointer],\n",
    "    shuffle = True)\n",
    "\n",
    "network.save('model_'+modelname+'.h5')\n",
    "\n",
    "train_loss, train_acc = network.evaluate(train_images_array, train_hot_class, verbose=0)\n",
    "print('Restored model, train accuracy: {:5.2f}%'.format(100 * train_acc))\n",
    "valid_loss, valid_acc = network.evaluate(valid_images_array, valid_hot_class, verbose=0)\n",
    "print('Restored model, valid accuracy: {:5.2f}%'.format(100 * valid_acc))\n",
    "new_test_loss, new_test_acc = network.evaluate(new_test_images_array, new_test_hot_class, verbose=0)\n",
    "print('Restored model, new_test accuracy: {:5.2f}%'.format(100 * new_test_acc))\n",
    "test_loss, test_acc = network.evaluate(test_images_array, test_hot_class, verbose=0)\n",
    "print('Restored model, test accuracy: {:5.2f}%'.format(100 * test_acc))\n",
    "np.save(modelname+'_history.npy',history.history)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def build_NeuralNetwork():\n",
    "\n",
    "    #input layer\n",
    "    model = Sequential()\n",
    "    model.add(Input(shape=(100,100,3)))\n",
    "    model.add(Flatten())\n",
    "\n",
    "    #hiddenlayer 1\n",
    "    model.add(Dense(5))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation(activation='sigmoid'))\n",
    "\n",
    "    #hiddenlayer 2\n",
    "    model.add(Dense(50)) #900\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation(activation='sigmoid'))\n",
    "    #model.add(Dropout(0.25))\n",
    "\n",
    "    #hiddenlayer 3\n",
    "    model.add(Dense(50)) #900\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation(activation='sigmoid'))\n",
    "    #model.add(Dropout(0.25))\n",
    "\n",
    "    #hiddenlayer 4\n",
    "    #model.add(Dense(300)) #900\n",
    "    #model.add(BatchNormalization())\n",
    "    #model.add(Activation(activation='relu'))\n",
    "    #model.add(Dropout(0.25))\n",
    "\n",
    "    #output layer\n",
    "    model.add(Dense(131,activation=\"softmax\"))\n",
    "\n",
    "    model.compile(loss = 'poisson', optimizer = \"adam\", metrics = ['accuracy'])\n",
    "    print('Compiled!')\n",
    "\n",
    "    return model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "network = build_NeuralNetwork()\n",
    "print('Model built.')\n",
    "modelname = 'ann1'\n",
    "checkpointer = ModelCheckpoint(filepath = modelname+'.hdf5', verbose = 0, save_best_only = True)\n",
    "\n",
    "history = network.fit(train_images_array, train_hot_class,\n",
    "    batch_size = 32, #32\n",
    "    epochs = 100, #15\n",
    "    validation_data = (valid_images_array, valid_hot_class),\n",
    "    verbose = 2,\n",
    "    callbacks=[checkpointer],\n",
    "    shuffle = True)\n",
    "\n",
    "network.save('model_'+modelname+'.h5')\n",
    "\n",
    "train_loss, train_acc = network.evaluate(train_images_array, train_hot_class, verbose=0)\n",
    "print('Restored model, train accuracy: {:5.2f}%'.format(100 * train_acc))\n",
    "valid_loss, valid_acc = network.evaluate(valid_images_array, valid_hot_class, verbose=0)\n",
    "print('Restored model, valid accuracy: {:5.2f}%'.format(100 * valid_acc))\n",
    "new_test_loss, new_test_acc = network.evaluate(new_test_images_array, new_test_hot_class, verbose=0)\n",
    "print('Restored model, new_test accuracy: {:5.2f}%'.format(100 * new_test_acc))\n",
    "test_loss, test_acc = network.evaluate(test_images_array, test_hot_class, verbose=0)\n",
    "print('Restored model, test accuracy: {:5.2f}%'.format(100 * test_acc))\n",
    "np.save(modelname+'_history.npy',history.history)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def build_NeuralNetwork():\n",
    "\n",
    "    #input layer\n",
    "    model = Sequential()\n",
    "    model.add(Input(shape=(100,100,3)))\n",
    "    model.add(Flatten())\n",
    "\n",
    "    #hiddenlayer 1\n",
    "    model.add(Dense(5))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation(activation='relu'))\n",
    "\n",
    "    #hiddenlayer 2\n",
    "    model.add(Dense(50)) #900\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation(activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "\n",
    "    #hiddenlayer 3\n",
    "    model.add(Dense(50)) #900\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation(activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "\n",
    "    #hiddenlayer 4\n",
    "    #model.add(Dense(300)) #900\n",
    "    #model.add(BatchNormalization())\n",
    "    #model.add(Activation(activation='relu'))\n",
    "    #model.add(Dropout(0.25))\n",
    "\n",
    "    #output layer\n",
    "    model.add(Dense(131,activation=\"softmax\"))\n",
    "\n",
    "    model.compile(loss = 'poisson', optimizer = \"adam\", metrics = ['accuracy'])\n",
    "    print('Compiled!')\n",
    "\n",
    "    return model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "network = build_NeuralNetwork()\n",
    "print('Model built.')\n",
    "modelname = 'ann1'\n",
    "checkpointer = ModelCheckpoint(filepath = modelname+'.hdf5', verbose = 0, save_best_only = True)\n",
    "\n",
    "history = network.fit(train_images_array, train_hot_class,\n",
    "    batch_size = 32, #32\n",
    "    epochs = 100, #15\n",
    "    validation_data = (valid_images_array, valid_hot_class),\n",
    "    verbose = 2,\n",
    "    callbacks=[checkpointer],\n",
    "    shuffle = True)\n",
    "\n",
    "network.save('model_'+modelname+'.h5')\n",
    "\n",
    "train_loss, train_acc = network.evaluate(train_images_array, train_hot_class, verbose=0)\n",
    "print('Restored model, train accuracy: {:5.2f}%'.format(100 * train_acc))\n",
    "valid_loss, valid_acc = network.evaluate(valid_images_array, valid_hot_class, verbose=0)\n",
    "print('Restored model, valid accuracy: {:5.2f}%'.format(100 * valid_acc))\n",
    "new_test_loss, new_test_acc = network.evaluate(new_test_images_array, new_test_hot_class, verbose=0)\n",
    "print('Restored model, new_test accuracy: {:5.2f}%'.format(100 * new_test_acc))\n",
    "test_loss, test_acc = network.evaluate(test_images_array, test_hot_class, verbose=0)\n",
    "print('Restored model, test accuracy: {:5.2f}%'.format(100 * test_acc))\n",
    "np.save(modelname+'_history.npy',history.history)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def build_NeuralNetwork():\n",
    "\n",
    "    #input layer\n",
    "    model = Sequential()\n",
    "    model.add(Input(shape=(100,100,3)))\n",
    "    model.add(Flatten())\n",
    "\n",
    "    #hiddenlayer 1\n",
    "    model.add(Dense(5))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation(activation='tanh'))\n",
    "\n",
    "    #hiddenlayer 2\n",
    "    model.add(Dense(50)) #900\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation(activation='tanh'))\n",
    "    model.add(Dropout(0.5))\n",
    "\n",
    "    #hiddenlayer 3\n",
    "    model.add(Dense(50)) #900\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation(activation='tanh'))\n",
    "    model.add(Dropout(0.5))\n",
    "\n",
    "    #hiddenlayer 4\n",
    "    #model.add(Dense(300)) #900\n",
    "    #model.add(BatchNormalization())\n",
    "    #model.add(Activation(activation='relu'))\n",
    "    #model.add(Dropout(0.25))\n",
    "\n",
    "    #output layer\n",
    "    model.add(Dense(131,activation=\"softmax\"))\n",
    "\n",
    "    model.compile(loss = 'poisson', optimizer = \"adam\", metrics = ['accuracy'])\n",
    "    print('Compiled!')\n",
    "\n",
    "    return model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "network = build_NeuralNetwork()\n",
    "print('Model built.')\n",
    "modelname = 'ann1'\n",
    "checkpointer = ModelCheckpoint(filepath = modelname+'.hdf5', verbose = 0, save_best_only = True)\n",
    "\n",
    "history = network.fit(train_images_array, train_hot_class,\n",
    "    batch_size = 32, #32\n",
    "    epochs = 100, #15\n",
    "    validation_data = (valid_images_array, valid_hot_class),\n",
    "    verbose = 2,\n",
    "    callbacks=[checkpointer],\n",
    "    shuffle = True)\n",
    "\n",
    "network.save('model_'+modelname+'.h5')\n",
    "\n",
    "train_loss, train_acc = network.evaluate(train_images_array, train_hot_class, verbose=0)\n",
    "print('Restored model, train accuracy: {:5.2f}%'.format(100 * train_acc))\n",
    "valid_loss, valid_acc = network.evaluate(valid_images_array, valid_hot_class, verbose=0)\n",
    "print('Restored model, valid accuracy: {:5.2f}%'.format(100 * valid_acc))\n",
    "new_test_loss, new_test_acc = network.evaluate(new_test_images_array, new_test_hot_class, verbose=0)\n",
    "print('Restored model, new_test accuracy: {:5.2f}%'.format(100 * new_test_acc))\n",
    "test_loss, test_acc = network.evaluate(test_images_array, test_hot_class, verbose=0)\n",
    "print('Restored model, test accuracy: {:5.2f}%'.format(100 * test_acc))\n",
    "np.save(modelname+'_history.npy',history.history)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def build_NeuralNetwork():\n",
    "\n",
    "    #input layer\n",
    "    model = Sequential()\n",
    "    model.add(Input(shape=(100,100,3)))\n",
    "    model.add(Flatten())\n",
    "\n",
    "    #hiddenlayer 1\n",
    "    model.add(Dense(5))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation(activation='sigmoid'))\n",
    "\n",
    "    #hiddenlayer 2\n",
    "    model.add(Dense(50)) #900\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation(activation='sigmoid'))\n",
    "    model.add(Dropout(0.5))\n",
    "\n",
    "    #hiddenlayer 3\n",
    "    model.add(Dense(50)) #900\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation(activation='sigmoid'))\n",
    "    model.add(Dropout(0.5))\n",
    "\n",
    "    #hiddenlayer 4\n",
    "    #model.add(Dense(300)) #900\n",
    "    #model.add(BatchNormalization())\n",
    "    #model.add(Activation(activation='relu'))\n",
    "    #model.add(Dropout(0.25))\n",
    "\n",
    "    #output layer\n",
    "    model.add(Dense(131,activation=\"softmax\"))\n",
    "\n",
    "    model.compile(loss = 'poisson', optimizer = \"adam\", metrics = ['accuracy'])\n",
    "    print('Compiled!')\n",
    "\n",
    "    return model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "network = build_NeuralNetwork()\n",
    "print('Model built.')\n",
    "modelname = 'ann1'\n",
    "checkpointer = ModelCheckpoint(filepath = modelname+'.hdf5', verbose = 0, save_best_only = True)\n",
    "\n",
    "history = network.fit(train_images_array, train_hot_class,\n",
    "    batch_size = 32, #32\n",
    "    epochs = 100, #15\n",
    "    validation_data = (valid_images_array, valid_hot_class),\n",
    "    verbose = 2,\n",
    "    callbacks=[checkpointer],\n",
    "    shuffle = True)\n",
    "\n",
    "network.save('model_'+modelname+'.h5')\n",
    "\n",
    "train_loss, train_acc = network.evaluate(train_images_array, train_hot_class, verbose=0)\n",
    "print('Restored model, train accuracy: {:5.2f}%'.format(100 * train_acc))\n",
    "valid_loss, valid_acc = network.evaluate(valid_images_array, valid_hot_class, verbose=0)\n",
    "print('Restored model, valid accuracy: {:5.2f}%'.format(100 * valid_acc))\n",
    "new_test_loss, new_test_acc = network.evaluate(new_test_images_array, new_test_hot_class, verbose=0)\n",
    "print('Restored model, new_test accuracy: {:5.2f}%'.format(100 * new_test_acc))\n",
    "test_loss, test_acc = network.evaluate(test_images_array, test_hot_class, verbose=0)\n",
    "print('Restored model, test accuracy: {:5.2f}%'.format(100 * test_acc))\n",
    "np.save(modelname+'_history.npy',history.history)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def build_NeuralNetwork():\n",
    "\n",
    "    #input layer\n",
    "    model = Sequential()\n",
    "    model.add(Input(shape=(100,100,3)))\n",
    "    model.add(Flatten())\n",
    "\n",
    "    #hiddenlayer 1\n",
    "    model.add(Dense(5))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation(activation='relu'))\n",
    "\n",
    "    #hiddenlayer 2\n",
    "    model.add(Dense(50)) #900\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation(activation='relu'))\n",
    "    model.add(Dropout(0.25))\n",
    "\n",
    "    #hiddenlayer 3\n",
    "    model.add(Dense(50)) #900\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation(activation='relu'))\n",
    "    model.add(Dropout(0.25))\n",
    "\n",
    "    #hiddenlayer 4\n",
    "    #model.add(Dense(300)) #900\n",
    "    #model.add(BatchNormalization())\n",
    "    #model.add(Activation(activation='relu'))\n",
    "    #model.add(Dropout(0.25))\n",
    "\n",
    "    #output layer\n",
    "    model.add(Dense(131,activation=\"softmax\"))\n",
    "\n",
    "    model.compile(loss = 'poisson', optimizer = \"adam\", metrics = ['accuracy'])\n",
    "    print('Compiled!')\n",
    "\n",
    "    return model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "network = build_NeuralNetwork()\n",
    "print('Model built.')\n",
    "modelname = 'ann1'\n",
    "checkpointer = ModelCheckpoint(filepath = modelname+'.hdf5', verbose = 0, save_best_only = True)\n",
    "\n",
    "history = network.fit(train_images_array, train_hot_class,\n",
    "    batch_size = 32, #32\n",
    "    epochs = 100, #15\n",
    "    validation_data = (valid_images_array, valid_hot_class),\n",
    "    verbose = 2,\n",
    "    callbacks=[checkpointer],\n",
    "    shuffle = True)\n",
    "\n",
    "network.save('model_'+modelname+'.h5')\n",
    "\n",
    "train_loss, train_acc = network.evaluate(train_images_array, train_hot_class, verbose=0)\n",
    "print('Restored model, train accuracy: {:5.2f}%'.format(100 * train_acc))\n",
    "valid_loss, valid_acc = network.evaluate(valid_images_array, valid_hot_class, verbose=0)\n",
    "print('Restored model, valid accuracy: {:5.2f}%'.format(100 * valid_acc))\n",
    "new_test_loss, new_test_acc = network.evaluate(new_test_images_array, new_test_hot_class, verbose=0)\n",
    "print('Restored model, new_test accuracy: {:5.2f}%'.format(100 * new_test_acc))\n",
    "test_loss, test_acc = network.evaluate(test_images_array, test_hot_class, verbose=0)\n",
    "print('Restored model, test accuracy: {:5.2f}%'.format(100 * test_acc))\n",
    "np.save(modelname+'_history.npy',history.history)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def build_NeuralNetwork():\n",
    "\n",
    "    #input layer\n",
    "    model = Sequential()\n",
    "    model.add(Input(shape=(100,100,3)))\n",
    "    model.add(Flatten())\n",
    "\n",
    "    #hiddenlayer 1\n",
    "    model.add(Dense(5))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation(activation='tanh'))\n",
    "\n",
    "    #hiddenlayer 2\n",
    "    model.add(Dense(50)) #900\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation(activation='tanh'))\n",
    "    model.add(Dropout(0.25))\n",
    "\n",
    "    #hiddenlayer 3\n",
    "    model.add(Dense(50)) #900\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation(activation='tanh'))\n",
    "    model.add(Dropout(0.25))\n",
    "\n",
    "    #hiddenlayer 4\n",
    "    #model.add(Dense(300)) #900\n",
    "    #model.add(BatchNormalization())\n",
    "    #model.add(Activation(activation='relu'))\n",
    "    #model.add(Dropout(0.25))\n",
    "\n",
    "    #output layer\n",
    "    model.add(Dense(131,activation=\"softmax\"))\n",
    "\n",
    "    model.compile(loss = 'poisson', optimizer = \"adam\", metrics = ['accuracy'])\n",
    "    print('Compiled!')\n",
    "\n",
    "    return model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "network = build_NeuralNetwork()\n",
    "print('Model built.')\n",
    "modelname = 'ann1'\n",
    "checkpointer = ModelCheckpoint(filepath = modelname+'.hdf5', verbose = 0, save_best_only = True)\n",
    "\n",
    "history = network.fit(train_images_array, train_hot_class,\n",
    "    batch_size = 32, #32\n",
    "    epochs = 100, #15\n",
    "    validation_data = (valid_images_array, valid_hot_class),\n",
    "    verbose = 2,\n",
    "    callbacks=[checkpointer],\n",
    "    shuffle = True)\n",
    "\n",
    "network.save('model_'+modelname+'.h5')\n",
    "\n",
    "train_loss, train_acc = network.evaluate(train_images_array, train_hot_class, verbose=0)\n",
    "print('Restored model, train accuracy: {:5.2f}%'.format(100 * train_acc))\n",
    "valid_loss, valid_acc = network.evaluate(valid_images_array, valid_hot_class, verbose=0)\n",
    "print('Restored model, valid accuracy: {:5.2f}%'.format(100 * valid_acc))\n",
    "new_test_loss, new_test_acc = network.evaluate(new_test_images_array, new_test_hot_class, verbose=0)\n",
    "print('Restored model, new_test accuracy: {:5.2f}%'.format(100 * new_test_acc))\n",
    "test_loss, test_acc = network.evaluate(test_images_array, test_hot_class, verbose=0)\n",
    "print('Restored model, test accuracy: {:5.2f}%'.format(100 * test_acc))\n",
    "np.save(modelname+'_history.npy',history.history)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def build_NeuralNetwork():\n",
    "\n",
    "    #input layer\n",
    "    model = Sequential()\n",
    "    model.add(Input(shape=(100,100,3)))\n",
    "    model.add(Flatten())\n",
    "\n",
    "    #hiddenlayer 1\n",
    "    model.add(Dense(5))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation(activation='sigmoid'))\n",
    "\n",
    "    #hiddenlayer 2\n",
    "    model.add(Dense(50)) #900\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation(activation='sigmoid'))\n",
    "    model.add(Dropout(0.25))\n",
    "\n",
    "    #hiddenlayer 3\n",
    "    model.add(Dense(50)) #900\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation(activation='sigmoid'))\n",
    "    model.add(Dropout(0.25))\n",
    "\n",
    "    #hiddenlayer 4\n",
    "    #model.add(Dense(300)) #900\n",
    "    #model.add(BatchNormalization())\n",
    "    #model.add(Activation(activation='relu'))\n",
    "    #model.add(Dropout(0.25))\n",
    "\n",
    "    #output layer\n",
    "    model.add(Dense(131,activation=\"softmax\"))\n",
    "\n",
    "    model.compile(loss = 'poisson', optimizer = \"adam\", metrics = ['accuracy'])\n",
    "    print('Compiled!')\n",
    "\n",
    "    return model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "network = build_NeuralNetwork()\n",
    "print('Model built.')\n",
    "modelname = 'ann1'\n",
    "checkpointer = ModelCheckpoint(filepath = modelname+'.hdf5', verbose = 0, save_best_only = True)\n",
    "\n",
    "history = network.fit(train_images_array, train_hot_class,\n",
    "    batch_size = 32, #32\n",
    "    epochs = 100, #15\n",
    "    validation_data = (valid_images_array, valid_hot_class),\n",
    "    verbose = 2,\n",
    "    callbacks=[checkpointer],\n",
    "    shuffle = True)\n",
    "\n",
    "network.save('model_'+modelname+'.h5')\n",
    "\n",
    "train_loss, train_acc = network.evaluate(train_images_array, train_hot_class, verbose=0)\n",
    "print('Restored model, train accuracy: {:5.2f}%'.format(100 * train_acc))\n",
    "valid_loss, valid_acc = network.evaluate(valid_images_array, valid_hot_class, verbose=0)\n",
    "print('Restored model, valid accuracy: {:5.2f}%'.format(100 * valid_acc))\n",
    "new_test_loss, new_test_acc = network.evaluate(new_test_images_array, new_test_hot_class, verbose=0)\n",
    "print('Restored model, new_test accuracy: {:5.2f}%'.format(100 * new_test_acc))\n",
    "test_loss, test_acc = network.evaluate(test_images_array, test_hot_class, verbose=0)\n",
    "print('Restored model, test accuracy: {:5.2f}%'.format(100 * test_acc))\n",
    "np.save(modelname+'_history.npy',history.history)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "history2=np.load('my_history.npy',allow_pickle='TRUE').item()\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plt.plot(history2['accuracy'])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "new_model = tf.keras.models.load_model('model_ann1.h5')\n",
    "new_model.summary()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Model accuracy"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plt.figure(figsize = (6, 5))\n",
    "plt.plot(history.history['accuracy'], color = 'r')\n",
    "plt.plot(history.history['val_accuracy'], color = 'b')\n",
    "plt.title('Model Accuracy', weight = 'bold', fontsize = 16)\n",
    "plt.ylabel('accuracy', weight = 'bold', fontsize = 14)\n",
    "plt.xlabel('epoch', weight = 'bold', fontsize = 14)\n",
    "plt.ylim(0.6, 1.1)\n",
    "plt.xticks(weight = 'bold', fontsize = 12)\n",
    "plt.yticks(weight = 'bold', fontsize = 12)\n",
    "plt.legend(['train', 'val'], loc = 'lower right', prop = {'size': 14})\n",
    "plt.grid(color = 'y', linewidth = '0.5')\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Show prediction."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt \n",
    "plt.figure(1)  \n",
    "   \n",
    " # summarize history for accuracy  \n",
    "   \n",
    "plt.subplot(211)  \n",
    "plt.plot(history.history['accuracy'])  \n",
    "plt.plot(history.history['val_accuracy'])  \n",
    "plt.title('model accuracy')  \n",
    "plt.ylabel('accuracy')  \n",
    "plt.xlabel('epoch')  \n",
    "plt.legend(['train', 'validation'], loc = 'lower right')\n",
    "   \n",
    " # summarize history for loss  \n",
    "   \n",
    "plt.subplot(212)  \n",
    "plt.plot(history.history['loss'])  \n",
    "plt.plot(history.history['val_loss'])  \n",
    "plt.title('model loss')  \n",
    "plt.ylabel('loss')  \n",
    "plt.xlabel('epoch')  \n",
    "plt.legend(['train', 'validation'], loc = 'upper right')\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ]
}