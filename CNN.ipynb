{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": [],
   "collapsed_sections": []
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "accelerator": "GPU"
 },
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "### 1. Import needed packages and clone the dataset"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from sklearn.datasets import load_files\n",
    "from keras.utils import np_utils, array_to_img, img_to_array, load_img\n",
    "from tensorflow.keras.models import Sequential\n",
    "from keras.layers import Input, Dense, Dropout, Activation, Flatten, BatchNormalization\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "print('You are using numpy version:', np.__version__)\n",
    "\n",
    "!git clone https://github.com/Horea94/Fruit-Images-Dataset"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#import sklearn\n",
    "#print(sklearn.__version__)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Set the path directory to the cloned test and train data.\n",
    "load_dataset() returns the filenames, integer classes and string classes that are stored in file directory.\n",
    "\n",
    "\n",
    "1.   names_train is a vector that contains the filepath of all images from the training set\n",
    "2.   names_test is a vector that contains the filepath of all images from the test set\n",
    "3.   intclass_train is a vector containing the int class values (1-131) of all images from the training set\n",
    "4.   intclass_test is a vector containing the int class values (1-131) of all images from the test set\n",
    "5.   stringclass_train is a vector containing the string label of class of all images from the training set\n",
    "6.   stringclass_test is a vector containing the string label of class of all images from the test set\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "train_dir = 'C:/Users/crysi/Private Dokumente/Papers & wissenschaftl. Arbeiten/Master/Foundations of Machine Learning/First Project/Pycharm/Fruit-Images-Dataset/Training/'\n",
    "test_dir = 'C:/Users/crysi/Private Dokumente/Papers & wissenschaftl. Arbeiten/Master/Foundations of Machine Learning/First Project/Pycharm/Fruit-Images-Dataset/Test/'\n",
    "\n",
    "def load_dataset(path):\n",
    "    data = load_files(path)\n",
    "    files = np.array(data['filenames'])\n",
    "    targets = np.array(data['target'])\n",
    "    target_labels = np.array(data['target_names'])\n",
    "    return files, targets, target_labels\n",
    "    \n",
    "names_train, intclass_train, stringclass_train = load_dataset(train_dir)\n",
    "names_test, intclass_test, stringclass_test = load_dataset(test_dir)\n",
    "\n",
    "print('Loading complete!')\n",
    "print('Training set size : ',  names_train.shape[0])\n",
    "print('Testing set size : ', names_test.shape[0])\n",
    "print(stringclass_train)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Show distribution of images to the different classes."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "(intclass, counts) = np.unique(intclass_train, return_counts=True)\n",
    "plt.bar(intclass, counts)\n",
    "plt.title('distribution of full training and test data')\n",
    "full_train_frequencies = np.asarray((intclass, counts)).T\n",
    "\n",
    "(intclass, counts) = np.unique(intclass_test, return_counts=True)\n",
    "plt.bar(intclass, counts)\n",
    "full_test_frequencies = np.asarray((intclass, counts)).T"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Show example file paths and their class label"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "i = 0\n",
    "while i < 3:\n",
    "  print('Path to image : ', names_train[i])\n",
    "  print('Class label of image: ', intclass_train[i])\n",
    "  i+=1"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "n_classes = len(np.unique(intclass_test))\n",
    "print('Training set size :',  names_train.shape[0])\n",
    "print('Testing set size :', names_test.shape[0])\n",
    "print('Number of unique classes:', n_classes)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Categorized matrix (0 or 1) for class of each image.\n",
    "\n",
    "\n",
    "1.   train_hot_class is a list containing (length of train images) arrays containing a list each (131 elements) where the i th element is 1, when the image is classified as intclass i (otherwise 0)\n",
    "2.   test_hot_class is a list containing (length of test images) arrays containing a list each (131 elements) where the i th element is 1, when the image is classified as intclass i (otherwise 0)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "train_hot_class = np_utils.to_categorical(intclass_train, n_classes)\n",
    "test_hot_class = np_utils.to_categorical(intclass_test, n_classes)\n",
    "train_hot_class[0]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Change name of image to actual pixel array.\n",
    "The _images_array are the inputs (100x100 pixels with 3 color channels).\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def convert_image_to_array(files):\n",
    "    images_as_array=[]\n",
    "    for file in files:\n",
    "        # Convert to Numpy Array\n",
    "        images_as_array.append(img_to_array(load_img(file)))\n",
    "    return images_as_array\n",
    "\n",
    "train_images_array = np.array(convert_image_to_array(names_train))\n",
    "print('Training set shape : ', train_images_array.shape)\n",
    "\n",
    "test_images_array = np.array(convert_image_to_array(names_test))\n",
    "print('Test set shape : ', test_images_array.shape)\n",
    "\n",
    "print('1st training image shape ',train_images_array[0].shape)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Pixel arrays of one image (100x100 pixels, 3 color channels)."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print('1st training image as array',test_images_array[0])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Rescale pixel values from 0-255 range to 0-1.\n",
    "\n",
    "\n",
    "1.   train_images_array is an array containing the normalized pixel values of the train images.\n",
    "2.   test_images_array is an array containing the normalized pixel values of the test images.\n",
    "3.   valid_images_array is an array containing the normalized pixel values of the validation images.\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "train_images_array = train_images_array.astype('float32')/255\n",
    "test_images_array = test_images_array.astype('float32')/255"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Split the train datasets into a train dataset and a validation dataset (~75/25).\n",
    "\n",
    "\n",
    "1.   names_train is a list of names of the first half of the train dataset (actual training dataset)\n",
    "2.   names_valid is a list of names of the second half of the train dataset (validation dataset)\n",
    "3.   train_hot_class is the first half of train_hot_class (actual training categorial classes)\n",
    "4.   valid_hot_class is the second half of train_hot_class (validation categorial classes)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train_images_array, valid_images_array, train_hot_class, valid_hot_class = train_test_split(train_images_array, train_hot_class, test_size = 0.1, random_state=42)\n",
    "\n",
    "print('Vaildation structure of pixels : ', valid_images_array.shape)\n",
    "print('Vaildation structure of categorial classes :', valid_hot_class.shape)\n",
    "print('Train structure of images: ', train_images_array.shape)\n",
    "print('Train structure of categorial classes : ', train_hot_class.shape)\n",
    "print('Test structure of images: ', test_images_array.shape)\n",
    "print('Test structure of categorial classes : ', test_hot_class.shape)\n",
    "\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Show 10 images."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig = plt.figure(figsize =(30,5))\n",
    "for i in range(10):\n",
    "    ax = fig.add_subplot(2,5,i+1,xticks=[],yticks=[])\n",
    "    ax.imshow(np.squeeze(train_images_array[i]))\n",
    "    print(names_train[i])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig = plt.figure(figsize =(30,5))\n",
    "for i in range(10):\n",
    "    ax = fig.add_subplot(2,5,i+1,xticks=[],yticks=[])\n",
    "    ax.imshow(np.squeeze(test_images_array[i]))\n",
    "    print(names_test[i])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "build neural network model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def build_NeuralNetwork():\n",
    "\n",
    "    #input layer\n",
    "    model = Sequential()\n",
    "    model.add(Input(shape=(100,100,3)))\n",
    "    model.add(Flatten())\n",
    "\n",
    "    #hiddenlayer 1\n",
    "    model.add(Dense(10))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation(activation='relu'))\n",
    "\n",
    "    #hiddenlayer 2\n",
    "    model.add(Dense(300)) #900\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation(activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "\n",
    "    #hiddenlayer 3\n",
    "    #model.add(Dense(1000)) #900\n",
    "    #model.add(BatchNormalization())\n",
    "    #model.add(Activation(activation='relu'))\n",
    "    #model.add(Dropout(0.5))\n",
    "\n",
    "    #hiddenlayer 4\n",
    "    #model.add(Dense(1000)) #900\n",
    "    #model.add(BatchNormalization())\n",
    "    #model.add(Activation(activation='relu'))\n",
    "    #model.add(Dropout(0.5))\n",
    "\n",
    "    #output layer\n",
    "    model.add(Dense(131,activation=\"softmax\"))\n",
    "\n",
    "    model.compile(loss = 'categorical_crossentropy', optimizer = \"adam\", metrics = ['accuracy'])\n",
    "    print('Compiled!')\n",
    "\n",
    "    return model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "network = build_NeuralNetwork()\n",
    "network.summary()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "checkpointer = ModelCheckpoint(filepath = 'ann.hdf5', verbose = 2, save_best_only = True)\n",
    "#filename='firstANN.csv'\n",
    "#history_logger=tf.keras.callbacks.CSVLogger(filename, separator=\",\", append=True)\n",
    "history = network.fit(train_images_array, train_hot_class,\n",
    "    batch_size = 32, #32\n",
    "    epochs = 25, #15\n",
    "    validation_data = (test_images_array, test_hot_class),\n",
    "    verbose = 2,\n",
    "    callbacks=[checkpointer], shuffle = True)\n",
    "network.save('ann.h5')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "new_model = tf.keras.models.load_model('ann.h5')\n",
    "loss, acc = new_model.evaluate(valid_images_array, valid_hot_class, verbose=2)\n",
    "print('Restored model, accuracy: {:5.2f}%'.format(100 * acc))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "loss, acc = new_model.evaluate(test_images_array, test_hot_class, verbose=2)\n",
    "print('Restored model, accuracy: {:5.2f}%'.format(100 * acc))\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model.load_weights('ann.hdf5')\n",
    "score = model.evaluate(test_images_array, test_hot_class, verbose = 0)\n",
    "print('\\n', 'Test accuracy:', score[1])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from keras.models import Model\n",
    "layer_outputs = [layer.output for layer in model.layers]\n",
    "activation_model = Model(inputs=model.input, outputs=layer_outputs)\n",
    "activations = activation_model.predict(train_images_array[10].reshape(1,100,100,1))\n",
    " \n",
    "def display_activation(activations, col_size, row_size, act_index): \n",
    "    activation = activations[act_index]\n",
    "    activation_index=0\n",
    "    fig, ax = plt.subplots(row_size, col_size, figsize=(row_size*2.5,col_size*1.5))\n",
    "    for row in range(0,row_size):\n",
    "        for col in range(0,col_size):\n",
    "            ax[row][col].imshow(activation[0, :, :, activation_index], cmap='gray')\n",
    "            activation_index += 1"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "history.model.weights"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "y_pred = model.predict(test_images_array)\n",
    "\n",
    "fig = plt.figure(figsize=(32, 30))\n",
    "for i, idx in enumerate(np.random.choice(test_images_array.shape[0], size = 32, replace = False)):\n",
    "    ax = fig.add_subplot(8, 6, i + 1, xticks = [], yticks = [])\n",
    "    ax.imshow(np.squeeze(test_images_array[idx]))\n",
    "    pred_idx = np.argmax(y_pred[idx])\n",
    "    true_idx = np.argmax(test_hot_class[idx])\n",
    "    ax.set_title(\"{} ({})\".format(stringclass_test[pred_idx], stringclass_test[true_idx]),\n",
    "                 color = (\"green\" if pred_idx == true_idx else \"red\"))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Model accuracy"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plt.figure(figsize = (6, 5))\n",
    "plt.plot(history.history['accuracy'], color = 'r')\n",
    "plt.plot(history.history['val_accuracy'], color = 'b')\n",
    "plt.title('Model Accuracy', weight = 'bold', fontsize = 16)\n",
    "plt.ylabel('accuracy', weight = 'bold', fontsize = 14)\n",
    "plt.xlabel('epoch', weight = 'bold', fontsize = 14)\n",
    "plt.ylim(0.4, 1)\n",
    "plt.xticks(weight = 'bold', fontsize = 12)\n",
    "plt.yticks(weight = 'bold', fontsize = 12)\n",
    "plt.legend(['train', 'val'], loc = 'lower right', prop = {'size': 14})\n",
    "plt.grid(color = 'y', linewidth = '0.5')\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Show prediction."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt \n",
    "plt.figure(1)  \n",
    "   \n",
    " # summarize history for accuracy  \n",
    "   \n",
    "plt.subplot(211)  \n",
    "plt.plot(history.history['accuracy'])  \n",
    "plt.plot(history.history['val_accuracy'])  \n",
    "plt.title('model accuracy')  \n",
    "plt.ylabel('accuracy')  \n",
    "plt.xlabel('epoch')  \n",
    "plt.legend(['train', 'validation'], loc = 'lower right')\n",
    "   \n",
    " # summarize history for loss  \n",
    "   \n",
    "plt.subplot(212)  \n",
    "plt.plot(history.history['loss'])  \n",
    "plt.plot(history.history['val_loss'])  \n",
    "plt.title('model loss')  \n",
    "plt.ylabel('loss')  \n",
    "plt.xlabel('epoch')  \n",
    "plt.legend(['train', 'validation'], loc = 'upper right')\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ]
}